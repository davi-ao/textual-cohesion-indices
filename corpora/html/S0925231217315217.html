<div class="Body u-font-serif" id="body"><div><section id="sec0001"><h2 id="sectt0003" class="u-h3 u-margin-l-top u-margin-xs-bottom">1. Introduction</h2><p id="para0001"><span>With fast technological growth, the ability to solve complex problems has increased. More and more data continuously generated by social media and various IT systems require more complex, accurate and efficient methods and algorithms so as to provide valuable insight. The tools of <a href="/topics/computer-science/big-data-analytics" title="Learn more about Big Data Analytics from ScienceDirect's AI-generated Topic Pages" class="topic-link">Big Data Analytics</a> and </span><a href="/topics/computer-science/high-performance-computing" title="Learn more about High Performance Computing from ScienceDirect's AI-generated Topic Pages" class="topic-link">High Performance Computing</a> accessible to all enable us to face these challenges but simultaneously raise a wide variety of new questions and problems which can only be addressed by scientists.</p><p id="para0002"><span>There are many aspects that must be taken into account while processing large amounts of data. One of them concerns the general problem of knowledge representation for complex structures. Textual, multimedia or networked content has an unstructured nature that is unsuited to the application of most known analytic methods. Recently, most of the data sets have come from texts derived from social media, and they are directly impacted by the complexity of <a href="/topics/computer-science/natural-languages" title="Learn more about natural languages from ScienceDirect's AI-generated Topic Pages" class="topic-link">natural languages</a>. Transforming </span><a href="/topics/computer-science/big-data" title="Learn more about big data from ScienceDirect's AI-generated Topic Pages" class="topic-link">big data</a> of such a kind into big knowledge still remains a great challenge. An obvious and commonly performed step in such a transformation is structuring. However, how should we transform the complex nature of natural language into a structured form?</p><p id="para0003">Overall, there are two main knowledge sources for the lexical semantics of a natural language that have practical importance for automated processing: (1) text corpora and (2) wordnets. A wordnet is a lexico-semantic network whose construction originates from the ideas first exemplified in the Princeton WordNet <a name="bbib0001" href="#bib0001" class="workspace-trigger">[1]</a><span>, a large language resource describing <a href="/topics/computer-science/lexical-meaning" title="Learn more about lexical meanings from ScienceDirect's AI-generated Topic Pages" class="topic-link">lexical meanings</a> of English by means of the various lexico-semantic relations. A wordnet provides a partial description of the lexical meanings – we know only constraints expressed by the instances of the lexico-semantic relations – but many wordnets are big enough to provide coverage of practical importance. Many wordnets were built manually with every piece of the structure verified by linguists. That is the case of WordNet and also plWordNet </span><a name="bbib0002" href="#bib0002" class="workspace-trigger">[2]</a> – a large wordnet of Polish, the largest world wordnet. In a wordnet, lexical meanings are enumerated and grouped into sets called <em>synsets</em>, i.e. sets of synonyms. A synset can be interpreted as representing a concept (called also <em>a lexicalised concept</em><span>) present in the interpretation of all its members. Synsets are linked by <a href="/topics/computer-science/semantic-relation" title="Learn more about semantic relations from ScienceDirect's AI-generated Topic Pages" class="topic-link">semantic relations</a> derived from lexical semantics such as hypernymy or meronymy. Direct relations between lexical meanings, e.g. antonymy or derivational relations, are also described in wordnets. The former are called conceptual relations and the latter lexical relations</span><a name="bfn0001" href="#fn0001" class="workspace-trigger"><sup>1</sup></a><span>. A large wordnet includes a great deal of infrequent words, many expressing specific meanings, that are often difficult to be found even in large corpora. Such words were added by its editors in order to complete selected semantic subfields. A wordnet also describes many specific meanings, which in corpora may either not exist or be dominated by more popular meanings. WordNet itself possesses a&nbsp;complex <a href="/topics/computer-science/network-structure" title="Learn more about network structure from ScienceDirect's AI-generated Topic Pages" class="topic-link">network structure</a>, which is&nbsp;inappropriate for commonly used analytic and reasoning methods.</span></p><p id="para0004">Extraction of lexico-semantic knowledge from corpora heavily depends on the statistical information concerning word co-occurrences, n-gramms or lexico-syntactic dependencies. The extracted knowledge mostly takes the form of word-to-word similarity measures or word semantic clusters. Most extraction techniques require large frequencies of words to be well described (&gt;100) that are difficult to be achieved for more specific and infrequent words even in large corpora. In contrast to corpus-based methods, a wordnet provides descriptions for many rarely used words.</p><p id="para0005">However, wordnets are based on limited sets of relations and do not cover many semantic distinctions that can be discovered in corpus-based similarity measures.</p><p id="para0006">The main problem addressed in this paper is how to find a method for the transformation of the complex network structure of the whole WordNet, as a description of the lexico-semantic system, into a simple structured form, that is to say vectors that are suitable for further processing by means of known methods. In particular, the transformation should encapsulate the position of each word in the WordNet network related to all other words in WordNet to represent the meaning of the term as it is constrained by the WordNet relations.</p><p id="para0007">We propose a new method, called <em>WordNet2Vec</em>, for textual data representation in a vector space that is able to satisfy the above-mentioned requirements. Based on the network of words from WordNet, we build a word representation in the vector space using its distance from any other word in the network. In order to present the pair-wise word distance, the method calculates the all-pair shortest paths in WordNet. Thanks to that, any list of vectors – list of words - also reflect the complex nature of the whole language encoded within these vectors.</p><p id="para0008"><span>To demonstrate the usefulness of the proposed <a href="/topics/computer-science/vectorization" title="Learn more about vectorization from ScienceDirect's AI-generated Topic Pages" class="topic-link">vectorization</a> method, we suggest a use case in which any textual document is transformed into a list of vectors from </span><em>WordNet2Vec</em><span>. Next, this representation is applied to the classification problem, namely <a href="/topics/computer-science/sentiment-analysis" title="Learn more about sentiment analysis from ScienceDirect's AI-generated Topic Pages" class="topic-link">sentiment analysis</a><span> and assignment. Finally, we compare the effectiveness of the <a href="/topics/computer-science/baseline-method" title="Learn more about baseline method from ScienceDirect's AI-generated Topic Pages" class="topic-link">baseline method</a> and some recently emerging and very popular approaches such as Doc2Vec </span></span><a name="bbib0003" href="#bib0003" class="workspace-trigger">[3]</a><span>. Since we derive knowledge from a general <a href="/topics/computer-science/database-languages" title="Learn more about language database from ScienceDirect's AI-generated Topic Pages" class="topic-link">language database</a><span> – WordNet, our method enables us to build more robust knowledge representation models and to achieve a very high level of efficiency, <a href="/topics/computer-science/generalization" title="Learn more about generalization from ScienceDirect's AI-generated Topic Pages" class="topic-link">generalization</a> and stability, especially if applied to transfer learning scenarios.</span></span></p><p id="para0009">In the experimental part of our research, the proposed <em>WordNet2Vec</em> vectorization method was utilized for sentiment analysis in the Amazon product review dataset. In general, sentiment analysis of texts means assigning a measure of how positive, neutral or negative the text is. Using <em>WordNet2Vec</em> representation and a supervised learning approach, the sentiment is assigned to the document according to its content. In other words, sentiment analysis is the process of determining the attitudes, opinions and emotions expressed within a text <a name="bbib0004" href="#bib0004" class="workspace-trigger">[4]</a>.</p><p id="para0010">The rest of this paper is organized as follows: in <a name="bsec0002" href="#sec0002" class="workspace-trigger">Section&nbsp;2</a> related work is presented. Then, the new <em>WordNet2Vec</em> method and other comparable methods are described in <a name="bsec0008" href="#sec0008" class="workspace-trigger">Section&nbsp;3</a>. The experimental design and results are discussed in <a name="bsec0015" href="#sec0015" class="workspace-trigger">Section&nbsp;6</a>. Finally, the ideas presented are summed up and future work directions are sketched out in <a name="bsec0024" href="#sec0024" class="workspace-trigger">Section&nbsp;9</a>.</p></section><section id="sec0002"><h2 id="sectt0004" class="u-h3 u-margin-l-top u-margin-xs-bottom">2. Related work</h2><p id="para0011"><span>Representation of knowledge is an area of <a href="/topics/computer-science/artificial-intelligence" title="Learn more about artificial intelligence from ScienceDirect's AI-generated Topic Pages" class="topic-link">artificial intelligence</a> concerned with how knowledge can be represented symbolically and manipulated in an automated way </span><a name="bbib0005" href="#bib0005" class="workspace-trigger">[5]</a>. Textual documents are intrinsically unstructured and in order to process them robustly one needs to employ various methodologies such as resolving, aggregating, integrating and abstracting. The derived knowledge can be represented in various structures including semantic nets, frames, rules, and ontologies <a name="bbib0006" href="#bib0006" class="workspace-trigger">[6]</a><span>. Due to the fact that the majority of <a href="/topics/computer-science/machine-learning" title="Learn more about machine learning from ScienceDirect's AI-generated Topic Pages" class="topic-link">machine learning</a> and supervised learning approaches operate in a vector space, the text representation should also be located within a vector space.</span></p><p id="para0012">Recent achievements in textual data representation are briefly presented further on in <a name="bsec0003" href="#sec0003" class="workspace-trigger">Section&nbsp;2.1</a><span><span> with a special focus on <a href="/topics/computer-science/word-embeddings" title="Learn more about word embedding from ScienceDirect's AI-generated Topic Pages" class="topic-link">word embedding</a><span> methods based on language corpora. Then, a wordnet which is a language resource representing the lexico-semantic system is briefly described from the perspective of its application in the <a href="/topics/computer-science/vectorization" title="Learn more about vectorization from ScienceDirect's AI-generated Topic Pages" class="topic-link">vectorization</a> method proposed in the paper. In addition, some insights into complex network All-pairs Shortest Paths (APSP) computation are discussed. Finally, an introduction to </span></span><a href="/topics/computer-science/sentiment-analysis" title="Learn more about sentiment analysis from ScienceDirect's AI-generated Topic Pages" class="topic-link">sentiment analysis</a> is provided due to its employment in the use case, </span><a name="bsec0010" href="#sec0010" class="workspace-trigger">Section&nbsp;5</a>.</p><section id="sec0003"><h3 id="sectt0005" class="u-h4 u-margin-m-top u-margin-xs-bottom">2.1. Word embedding techniques</h3><p id="para0013"><em>Word embedding</em> is the generous name given to a collection of language modeling and feature learning techniques where words from the vocabulary are mapped to vectors of real numbers. Word embedding can be equally called <em>a word vectorization method</em><span>. The mapping is usually done in a low-dimensional space, but depends relatively on the vocabulary size. Historically, word embedding was related to statistical processing of big corpora and introduced to derive latent <a href="/topics/computer-science/semantic-feature" title="Learn more about semantic features from ScienceDirect's AI-generated Topic Pages" class="topic-link">semantic features</a> from word co-occurrence in the documents.</span></p><p id="para0014">In general, word embedding techniques can be dived into two main groups. The first is based on a probabilistic prediction approach. Such methods are used to train a model, based on a context window composed of words from a corpus, generalizing the results into a reduced <em>n</em> dimensional space (<em>n</em> is chosen arbitrarily). Then a word is represented as a vector in the space and preserves a context property, so words that are located close to each other in this space frequently co-occur in the corpus. <em>Word2Vec</em> (Word-2-Vector) <a name="bbib0007" href="#bib0007" class="workspace-trigger">[7]</a>, <a name="bbib0008" href="#bib0008" class="workspace-trigger">[8]</a> is the best known method in this group. It is based on skip-grams and continuous bags of words (CBOW). Given the neighboring words in the window, the CBOW model is used to predict a particular word <em>w</em>. In contrast, given a window size of <em>n</em> words around a word <em>w</em>, the skip-gram model predicts the neighboring words given the current word.</p><p id="para0015"><span>There have been other deep and recurrent <a href="/topics/computer-science/neural-networks" title="Learn more about neural network from ScienceDirect's AI-generated Topic Pages" class="topic-link">neural network</a> architectures proposed for learning word representation in vector space before, i.e. </span><a name="bbib0009" href="#bib0009" class="workspace-trigger">[9]</a>, <a name="bbib0010" href="#bib0010" class="workspace-trigger">[10]</a>, but Word2Vec is one of the best and most commonly studied methods.</p><p id="para0016">Count-based models constitute the second group of word embedding techniques. The GloVe algorithm, presented by Pennington et&nbsp;al. <a name="bbib0011" href="#bib0011" class="workspace-trigger">[11]</a><span>, is one of them. In count-based models the vectors are based on the word co-occurrence frequency matrix. In order to shrink the size of word vectors dimensionality <a href="/topics/computer-science/reduction-algorithm" title="Learn more about reduction algorithms from ScienceDirect's AI-generated Topic Pages" class="topic-link">reduction algorithms</a><span> are applied. The main intuition for the GloVe model is the simple observation that ratios of word-to-word co-occurrence probabilities can be utilized to represent some aspects of the meaning of the <a href="/topics/computer-science/natural-languages" title="Learn more about natural language from ScienceDirect's AI-generated Topic Pages" class="topic-link">natural language</a> concerned. Word vectors produced by the GloVe method perform very well as a solution for word similarity tasks, and are similar to the Word2Vec approach. Lebret and Collobert </span></span><a name="bbib0012" href="#bib0012" class="workspace-trigger">[12]</a> and Dhillon et&nbsp;al. <a name="bbib0013" href="#bib0013" class="workspace-trigger">[13]</a> proposed another version of count-based models. Lebret presented a method that simplifies word embedding computation through a Hellinger PCA of the word co-occurrence matrix. Dhillon used a new spectral method based on CCA (canonical correlation analysis), Two Step CCA (TSCCA), to learn an eigenword dictionary. This procedure computes two set of CCAs: the first one between the left and right contexts of the given word and the second one between the projections resulting from this CCA and the word itself. Lebret and Collobert <a name="bbib0014" href="#bib0014" class="workspace-trigger">[14]</a><span> proposed an alternative model based on counts. They used the Hellinger distance to extract <a href="/topics/computer-science/semantic-representation" title="Learn more about semantic representations from ScienceDirect's AI-generated Topic Pages" class="topic-link">semantic representations</a> from the word co-occurrence statistics in a large text corpus.</span></p><p id="para0017"><span>In conclusion, Word2Vec is a <a href="/topics/computer-science/predictive-model" title="Learn more about predictive model from ScienceDirect's AI-generated Topic Pages" class="topic-link">predictive model</a>, whereas GloVe is a count-based model </span><a name="bbib0015" href="#bib0015" class="workspace-trigger">[15]</a>. However, there is no qualitative difference between predictive models and count-based models. They use different computational methods that produce a very similar type of semantic model <a name="bbib0016" href="#bib0016" class="workspace-trigger">[16]</a>, <a name="bbib0017" href="#bib0017" class="workspace-trigger">[17]</a>.</p></section><section id="sec0004"><h3 id="sectt0006" class="u-h4 u-margin-m-top u-margin-xs-bottom">2.2. WordNet</h3><p id="para0018">A wordnet is&nbsp;a&nbsp;large lexico-semantic database of natural language. Following the seminal Princeton WordNet for English <a name="bbib0001" href="#bib0001" class="workspace-trigger">[1]</a>, <a name="bbib0018" href="#bib0018" class="workspace-trigger">[18]</a>, wordnets for many different languages have been built<a name="bfn0002" href="#fn0002" class="workspace-trigger"><sup>2</sup></a>. Nouns, verbs, adjectives and adverbs are grouped into synsets, vaguely defined as sets of synonyms such that they express some lexicalized concept that is common for synset members called <em>senses</em><span> (i.e. word senses) representing particular <a href="/topics/computer-science/lexical-meaning" title="Learn more about lexical meanings from ScienceDirect's AI-generated Topic Pages" class="topic-link">lexical meanings</a>. Synsets are linked by </span><em>conceptual relations</em> that were inspired by linguistic lexico-semantic relations such as hyper/hyponymy or holo/meronymy. In addition, senses (i.e. synset members, e.g. <em>man 1</em>) are linked by <em>lexical relations</em>. Most of them are well known lexico-semantic relations including antonymy or morpho-semantic relations.</p><p id="para0019">Various types of links can be found in&nbsp;WordNet:<dl class="list"><dt class="list-label">•</dt><dd class="list-description"><p id="para0020">There are 285,348 semantic links between synsets:<dl class="list"><dt class="list-label">–</dt><dd class="list-description"><p id="para0021">178,323 both hypernyms and hyponyms,</p></dd><dt class="list-label">–</dt><dd class="list-description"><p id="para0022">21,434 similarity,</p></dd><dt class="list-label">–</dt><dd class="list-description"><p id="para0023">18,215 both holonyms and meronyms,</p></dd><dt class="list-label">–</dt><dd class="list-description"><p id="para0024">67,376 other connections.</p></dd></dl></p></dd><dt class="list-label">•</dt><dd class="list-description"><p id="para0025">There are 92,508 lexical links between all words:<dl class="list"><dt class="list-label">–</dt><dd class="list-description"><p id="para0026">74,656 derivations,</p></dd><dt class="list-label">–</dt><dd class="list-description"><p id="para0027">7981 antonyms,</p></dd><dt class="list-label">–</dt><dd class="list-description"><p id="para0028">9871 other connections.</p></dd></dl></p></dd></dl></p><p id="para0029">WordNet is freely and publicly available for download on a licence similar to BSD. Its stable structure means that it provides a comprehensive representation of the whole lexico-semantic system of the natural language concerned, which can be applied in several methods of <a href="/topics/computer-science/computational-linguistics" title="Learn more about Computational Linguistics from ScienceDirect's AI-generated Topic Pages" class="topic-link">Computational Linguistics</a><span> and <a href="/topics/computer-science/natural-language-processing" title="Learn more about Natural Language Processing from ScienceDirect's AI-generated Topic Pages" class="topic-link">Natural Language Processing</a>.</span></p><p id="para0030">In our work, we assume that WordNet can be treated as an approximate representation of the whole lexico-semantic system. In other words, existing connections between synsets and therefore between words (via senses) give a reasonably good representation of the lexical meanings, according to open debate in the language processing community, e.g. <a name="bbib0019" href="#bib0019" class="workspace-trigger">[19]</a>. This allows us to create a robust representation of words on the basis of the WordNet structure.</p></section><section id="sec0005"><h3 id="sectt0007" class="u-h4 u-margin-m-top u-margin-xs-bottom">2.3. All-pairs shortest paths</h3><p id="para0031">Computation of All-pairs Shortest Paths (APSP) is one of the most fundamental problems in graph theory. The objective is to calculate distances between all pairs of vertices in the graph. Multiple algorithms have been proposed to solve this problem for various graph types including directed, undirected, weighted, unweighted once. Their complexity can vary, depending on the type of graph. One of the most commonly used solutions for the problem has been proposed by Floyd <a name="bbib0020" href="#bib0020" class="workspace-trigger">[20]</a>. A simple geometrical optimization allowed a decrease in complexity to <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-13-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>O</mi><mo stretchy=&quot;true&quot; is=&quot;true&quot;>(</mo><mfrac is=&quot;true&quot;><msup is=&quot;true&quot;><mi is=&quot;true&quot;>n</mi><mn is=&quot;true&quot;>3</mn></msup><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>l</mi><mi is=&quot;true&quot;>o</mi><mi is=&quot;true&quot;>g</mi><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>n</mi><mo is=&quot;true&quot;>)</mo></mrow></mfrac><mo stretchy=&quot;true&quot; is=&quot;true&quot;>)</mo></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="9.727ex" height="4.549ex" viewBox="0 -1217.1 4188.1 1958.7" role="img" focusable="false" style="vertical-align: -1.722ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-4F"></use></g><use xlink:href="#MJSZ2-28" is="true" x="763" y="-1"></use><g is="true" transform="translate(1361,0)"><g transform="translate(120,0)"><rect stroke="none" width="1989" height="60" x="0" y="220"></rect><g is="true" transform="translate(622,417)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-6E"></use></g><g is="true" transform="translate(424,256)"><use transform="scale(0.5)" xlink:href="#MJMAIN-33"></use></g></g><g is="true" transform="translate(60,-441)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-6C"></use></g><g is="true" transform="translate(211,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6F"></use></g><g is="true" transform="translate(554,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-67"></use></g><g is="true" transform="translate(894,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(1169,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6E"></use></g><g is="true" transform="translate(1594,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-29"></use></g></g></g></g><use xlink:href="#MJSZ2-29" is="true" x="3590" y="-1"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">O</mi><mo stretchy="true" is="true">(</mo><mfrac is="true"><msup is="true"><mi is="true">n</mi><mn is="true">3</mn></msup><mrow is="true"><mi is="true">l</mi><mi is="true">o</mi><mi is="true">g</mi><mo is="true">(</mo><mi is="true">n</mi><mo is="true">)</mo></mrow></mfrac><mo stretchy="true" is="true">)</mo></mrow></math></span></span><script type="math/mml" id="MathJax-Element-13"><math><mrow is="true"><mi is="true">O</mi><mo stretchy="true" is="true">(</mo><mfrac is="true"><msup is="true"><mi is="true">n</mi><mn is="true">3</mn></msup><mrow is="true"><mi is="true">l</mi><mi is="true">o</mi><mi is="true">g</mi><mo is="true">(</mo><mi is="true">n</mi><mo is="true">)</mo></mrow></mfrac><mo stretchy="true" is="true">)</mo></mrow></math></script></span> <a name="bbib0021" href="#bib0021" class="workspace-trigger">[21]</a>. Work by Yijie Han <a name="bbib0022" href="#bib0022" class="workspace-trigger">[22]</a> with a complexity of <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-14-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>O</mi><mo stretchy=&quot;true&quot; is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>n</mi><msup is=&quot;true&quot;><mrow is=&quot;true&quot; /><mn is=&quot;true&quot;>3</mn></msup><mo stretchy=&quot;true&quot; is=&quot;true&quot;>(</mo><mfrac is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>l</mi><mi is=&quot;true&quot;>o</mi><mi is=&quot;true&quot;>g</mi><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>l</mi><mi is=&quot;true&quot;>o</mi><mi is=&quot;true&quot;>g</mi><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>n</mi><mo is=&quot;true&quot;>)</mo><mo is=&quot;true&quot;>)</mo></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>l</mi><mi is=&quot;true&quot;>o</mi><mi is=&quot;true&quot;>g</mi><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>n</mi><mo is=&quot;true&quot;>)</mo></mrow></mfrac><mo stretchy=&quot;true&quot; is=&quot;true&quot;>)</mo><msup is=&quot;true&quot;><mrow is=&quot;true&quot; /><mfrac is=&quot;true&quot;><mn is=&quot;true&quot;>5</mn><mn is=&quot;true&quot;>4</mn></mfrac></msup><mo stretchy=&quot;true&quot; is=&quot;true&quot;>)</mo></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="19.957ex" height="4.549ex" viewBox="0 -1217.1 8592.7 1958.7" role="img" focusable="false" style="vertical-align: -1.722ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-4F"></use></g><use xlink:href="#MJSZ2-28" is="true" x="763" y="-1"></use><g is="true" transform="translate(1361,0)"><use xlink:href="#MJMATHI-6E"></use></g><g is="true" transform="translate(1961,0)"><g is="true"></g><g is="true" transform="translate(0,362)"><use transform="scale(0.707)" xlink:href="#MJMAIN-33"></use></g></g><use xlink:href="#MJSZ2-28" is="true" x="2415" y="-1"></use><g is="true" transform="translate(3012,0)"><g transform="translate(120,0)"><rect stroke="none" width="3434" height="60" x="0" y="220"></rect><g is="true" transform="translate(60,586)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-6C"></use></g><g is="true" transform="translate(211,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6F"></use></g><g is="true" transform="translate(554,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-67"></use></g><g is="true" transform="translate(894,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(1169,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6C"></use></g><g is="true" transform="translate(1380,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6F"></use></g><g is="true" transform="translate(1723,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-67"></use></g><g is="true" transform="translate(2063,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(2339,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6E"></use></g><g is="true" transform="translate(2763,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-29"></use></g><g is="true" transform="translate(3039,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-29"></use></g></g><g is="true" transform="translate(782,-441)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-6C"></use></g><g is="true" transform="translate(211,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6F"></use></g><g is="true" transform="translate(554,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-67"></use></g><g is="true" transform="translate(894,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(1169,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6E"></use></g><g is="true" transform="translate(1594,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-29"></use></g></g></g></g><use xlink:href="#MJSZ2-29" is="true" x="6687" y="-1"></use><g is="true" transform="translate(7284,0)"><g is="true"></g><g is="true" transform="translate(0,429)"><g transform="translate(120,0)"><rect stroke="none" width="370" height="60" x="0" y="146"></rect><g is="true" transform="translate(60,347)"><use transform="scale(0.5)" xlink:href="#MJMAIN-35"></use></g><g is="true" transform="translate(60,-322)"><use transform="scale(0.5)" xlink:href="#MJMAIN-34"></use></g></g></g></g><use xlink:href="#MJSZ2-29" is="true" x="7995" y="-1"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">O</mi><mo stretchy="true" is="true">(</mo><mi is="true">n</mi><msup is="true"><mrow is="true"></mrow><mn is="true">3</mn></msup><mo stretchy="true" is="true">(</mo><mfrac is="true"><mrow is="true"><mi is="true">l</mi><mi is="true">o</mi><mi is="true">g</mi><mo is="true">(</mo><mi is="true">l</mi><mi is="true">o</mi><mi is="true">g</mi><mo is="true">(</mo><mi is="true">n</mi><mo is="true">)</mo><mo is="true">)</mo></mrow><mrow is="true"><mi is="true">l</mi><mi is="true">o</mi><mi is="true">g</mi><mo is="true">(</mo><mi is="true">n</mi><mo is="true">)</mo></mrow></mfrac><mo stretchy="true" is="true">)</mo><msup is="true"><mrow is="true"></mrow><mfrac is="true"><mn is="true">5</mn><mn is="true">4</mn></mfrac></msup><mo stretchy="true" is="true">)</mo></mrow></math></span></span><script type="math/mml" id="MathJax-Element-14"><math><mrow is="true"><mi is="true">O</mi><mo stretchy="true" is="true">(</mo><mi is="true">n</mi><msup is="true"><mrow is="true"></mrow><mn is="true">3</mn></msup><mo stretchy="true" is="true">(</mo><mfrac is="true"><mrow is="true"><mi is="true">l</mi><mi is="true">o</mi><mi is="true">g</mi><mo is="true">(</mo><mi is="true">l</mi><mi is="true">o</mi><mi is="true">g</mi><mo is="true">(</mo><mi is="true">n</mi><mo is="true">)</mo><mo is="true">)</mo></mrow><mrow is="true"><mi is="true">l</mi><mi is="true">o</mi><mi is="true">g</mi><mo is="true">(</mo><mi is="true">n</mi><mo is="true">)</mo></mrow></mfrac><mo stretchy="true" is="true">)</mo><msup is="true"><mrow is="true"></mrow><mfrac is="true"><mn is="true">5</mn><mn is="true">4</mn></mfrac></msup><mo stretchy="true" is="true">)</mo></mrow></math></script></span> is currently the best score. Besides this, the method proposed by Floyd can also be distributed in a very easy way which facilitates its application to large datasets.</p></section><section id="sec0006"><h3 id="sectt0008" class="u-h4 u-margin-m-top u-margin-xs-bottom">2.4. Sentiment analysis</h3><p id="para0032"><span>Sentiment analysis means the assignment of a measure as to what extent a text is positive, neutral or negative. Nowadays, the most commonly used methods for sentiment analysis are <a href="/topics/computer-science/classification" title="Learn more about classification from ScienceDirect's AI-generated Topic Pages" class="topic-link">classification</a><span> approaches with <a href="/topics/computer-science/classification-machine-learning" title="Learn more about classifiers from ScienceDirect's AI-generated Topic Pages" class="topic-link">classifiers</a> such as Naive Bayes </span></span><a name="bbib0023" href="#bib0023" class="workspace-trigger">[23]</a>, <a name="bbib0024" href="#bib0024" class="workspace-trigger">[24]</a>, <a name="bbib0025" href="#bib0025" class="workspace-trigger">[25]</a><span>, <a href="/topics/computer-science/support-vector-machine" title="Learn more about Support Vector Machines from ScienceDirect's AI-generated Topic Pages" class="topic-link">Support Vector Machines</a> (SVM) </span><a name="bbib0026" href="#bib0026" class="workspace-trigger">[26]</a>, <a name="bbib0027" href="#bib0027" class="workspace-trigger">[27]</a>, <a name="bbib0028" href="#bib0028" class="workspace-trigger">[28]</a>, Decision Tree <a name="bbib0029" href="#bib0029" class="workspace-trigger">[29]</a>, <a name="bbib0030" href="#bib0030" class="workspace-trigger">[30]</a><span>, <a href="/topics/computer-science/random-decision-forest" title="Learn more about Random Forest from ScienceDirect's AI-generated Topic Pages" class="topic-link">Random Forest</a> </span><a name="bbib0031" href="#bib0031" class="workspace-trigger">[31]</a><span> or <a href="/topics/computer-science/logistic-regression" title="Learn more about Logistic Regression from ScienceDirect's AI-generated Topic Pages" class="topic-link">Logistic Regression</a> </span><a name="bbib0030" href="#bib0030" class="workspace-trigger">[30]</a><span>. In addition, feature selection can improve <a href="/topics/computer-science/classification-accuracy" title="Learn more about classification accuracy from ScienceDirect's AI-generated Topic Pages" class="topic-link">classification accuracy</a> by reducing high-dimensionality to low-dimensionality of the feature space. Yousefpour et&nbsp;al. </span><a name="bbib0032" href="#bib0032" class="workspace-trigger">[32]</a> proposed a hybrid method and two meta-heuristic algorithms are employed to find an optimal feature subset.</p><p id="para0033">Another family of solutions available for sentiment analysis are neural network based approaches. Socher et&nbsp;al. <a name="bbib0033" href="#bib0033" class="workspace-trigger">[33]</a> proposed a recursive deep model for sentiment analysis using a treebank structure of sentences (i.e. sentences with meta-data describing their syntactic structures). Zhang and LeCun <a name="bbib0034" href="#bib0034" class="workspace-trigger">[34]</a><span> used deep learning for text understanding from character-level inputs all the way up to abstract text concepts, using temporal <a href="/topics/computer-science/convolutional-network" title="Learn more about convolutional networks from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolutional networks</a> (ConvNets). What is more, some systems leverage both hand-crafted features and word level embedding features, such as Do2Vec, with the use of classifiers such as SVM </span><a name="bbib0035" href="#bib0035" class="workspace-trigger">[35]</a>.</p></section><section id="sec0007"><h3 id="sectt0009" class="u-h4 u-margin-m-top u-margin-xs-bottom">2.5. Transfer learning</h3><p id="para0034">Transfer learning makes use of system ability to recognize and apply knowledge extraction (learned in previous tasks) to novel tasks (in new domains) <a name="bbib0036" href="#bib0036" class="workspace-trigger">[36]</a>. Interestingly, it has been inspired by human learning behavior. We can often transfer knowledge learned in one situation and adapt it to a new one. Yoshida et&nbsp;al. <a name="bbib0037" href="#bib0037" class="workspace-trigger">[37]</a> proposed a model where each word is associated with three factors: domain label, domain dependence/independence and word polarity. The major part of their method includes Gibbs sampling for inferring the parameters of the model, from both labeled and unlabeled texts. Moreover, the method proposed by them may also determine whether each word's polarity is domain-dependent or domain-independent. Zhou et&nbsp;al. <a name="bbib0038" href="#bib0038" class="workspace-trigger">[38]</a><span> developed a solution to cross-domain sentiment classification for <a href="/topics/computer-science/unlabeled-data" title="Learn more about unlabeled data from ScienceDirect's AI-generated Topic Pages" class="topic-link">unlabeled data</a>. To bridge the gap between domains, they proposed an algorithm called topical correspondence transfer (TCT). TCT is achieved by learning domain-specific information from different areas and applying it to unified topics.</span></p></section></section><section id="sec0008"><h2 id="sectt0010" class="u-h3 u-margin-l-top u-margin-xs-bottom">3. WordNet2Vec: wordNet-based natural language representation in&nbsp;the vector space – word vectors</h2><div><p id="para0035">The general idea of the WordNet2Vec method is to transfer knowledge about the lexico-semantic system which is encapsulated in the WordNet relation network into word-based vector structures suitable for further processing. Its main steps are presented in <a name="bfig0001" href="#fig0001" class="workspace-trigger">Fig.&nbsp;1</a>.</p><figure class="figure text-xs" id="fig0001"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr1.jpg" height="789" alt="Fig. 1" aria-describedby="cap0001"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr1_lrg.jpg" target="_blank" download="" title="Download high-res image (658KB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (658KB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr1.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0001"><p id="spara0004"><span class="label">Fig. 1</span>. Architecture of the WordNet2Vec method.</p></span></span></figure></div><p id="para0036"><span>A wordnet consists of many synsets and words grouped in them, as well as even more numerous instances of lexical and conceptual relations linking them. Several large wordnets have been built manually by linguists for a&nbsp;given language, e.g. WordNet, plWordNet and GermaNet. If a wordnet is large enough, more than a hundred thousand synsets, it may be treated as a reliable and comprehensive representation of the <a href="/topics/computer-science/lexical-meaning" title="Learn more about lexical meanings from ScienceDirect's AI-generated Topic Pages" class="topic-link">lexical meanings</a> of the given language. Most of the meanings are drawn from the general stylistic register, but there are typically many other meanings from other registers such as popular, colloquial, vulgar and even specialist. Wordnet has a complex </span><a href="/topics/computer-science/network-structure" title="Learn more about network structure from ScienceDirect's AI-generated Topic Pages" class="topic-link">network structure</a><span> and it is hardly suitable for commonly used analytic methods such as <a href="/topics/computer-science/machine-learning" title="Learn more about machine learning from ScienceDirect's AI-generated Topic Pages" class="topic-link">machine learning</a> reasoning.</span></p><p id="para0037">To overcome this limitation, we propose the WordNet2Vec method that provides a set of word vectors embedding a large part of the lexical knowledge stored in the wordnet. The processing starts with a mapping of the wordnet structure onto a simplified graph with only words as nodes and one type of links. A relation between two word lemmas in the simplified graph exists if (1) there exists a direct lexical relation between words in the original wordnet, (2) there exists any <a href="/topics/computer-science/semantic-relation" title="Learn more about semantic relation from ScienceDirect's AI-generated Topic Pages" class="topic-link">semantic relation</a> between two synsets containing the two considered words, (3) both words belong to one synset – are synonyms.</p><p id="para0038">It is worth remembering that a wordnet is a multiplex with multiple types of connections between multiple types of nodes - a multimodal network. In our approach, all kinds of existing relationships are flattened to achieve a uniplex. This can obviously cause some loss of information. On the other hand, it is not possible to achieve a compact shortest paths representation for each of the layers because in the vast majority of cases they are very sparse and consist of multiple separate components. As a result, the shortest paths matrix would be highly sparse. This could make the representation space improper and with weak potential for <a href="/topics/computer-science/generalization" title="Learn more about generalization from ScienceDirect's AI-generated Topic Pages" class="topic-link">generalization</a>. Moreover, the calculation of shortest paths in multiplexes is a separate research problem.</p><div><p id="para0039">In the next step, a structural measure is applied to evaluate the distance from a given node-word to any other node-word in the simplified graph. We decided to utilize shortest paths for that purpose. It means that we had to compute all-pair shortest paths. The distribution of all pairs shortest paths is depicted in <a name="bfig0002" href="#fig0002" class="workspace-trigger">Fig.&nbsp;2</a>.</p><figure class="figure text-xs" id="fig0002"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr2.jpg" height="300" alt="Fig. 2" aria-describedby="cap0002"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr2_lrg.jpg" target="_blank" download="" title="Download high-res image (176KB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (176KB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr2.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0002"><p id="spara0005"><span class="label">Fig. 2</span>. WordNet shortest paths length distribution.</p></span></span></figure></div><p id="para0040">Finally, for each word – node in the simplified network – a separate vector is created. Its coordinates correspond to shortest path lengths to all other nodes so the word vector reflects a position of a given word towards all other words in the language. The set of such word vectors comprises the output of the method and can be used for further processing. Such word vector sets express a kind of projection from a lexico-semantic system into a vector space. In particular, the representation constructed provides insights into the semantic relations between words<a name="bfn0003" href="#fn0003" class="workspace-trigger"><sup>3</sup></a>.</p></section><section id="sec0009"><h2 id="sectt0011" class="u-h3 u-margin-l-top u-margin-xs-bottom">4. WordNet2Vec implementation – distributed calculation of all-pairs shortest paths in&nbsp;the simplified WordNet graph</h2><p id="para0041">To demonstrate the WordNet2Vec method, it was applied to the English WordNet <a name="bbib0001" href="#bib0001" class="workspace-trigger">[1]</a>. We have created a simplified (flattened) network based on semantic and lexical relations present in WordNet. Hence, we received a graph composed of 147,478 words interconnected by 1,695,623 links.</p><p id="para0042">The simplified network was utilized to compute all-pair shortest paths in this network, so we obtained 147, 478<sup>2</sup>, in other words over 21 billion path lengths.</p><p id="para0043">Wordnet is a multiplex with multiple types of connections between pairs of nodes. In our approach, all kinds of existing relationships are flattened to achieve a uniplex. Such graph aggregation can apparently cause some loss of information, especially regarding connection semantics. On the other hand, layers in all available wordnets are sparse. It would not be possible to achieve a shortest paths representation based only on each layer separately. It makes the representation improper and with weak potential for <a href="/topics/computer-science/generalization" title="Learn more about generalization from ScienceDirect's AI-generated Topic Pages" class="topic-link">generalization</a>. Moreover, the calculation of shortest paths in multiplexes constitutes an entirely new research problem.</p><p id="para0044">Because of the size of the simplified network as well as computational and memory complexity of the path calculation task, we decided to use a heterogeneous computational cluster as an environment for our experiments. Nevertheless, further optimization had to be done. In our approach, we used distributed implementation of the Dijkistra <a name="bbib0039" href="#bib0039" class="workspace-trigger">[39]</a> algorithm available in our SparklingGraph library <a name="bbib0040" href="#bib0040" class="workspace-trigger">[40]</a>. Most of the known solutions for the all-pair shortest paths (APSP) problem have a memory complexity of <em>O</em>(<em>n</em><sup>3</sup>), where <em>n</em> is the number of nodes in the graph <a name="bbib0020" href="#bib0020" class="workspace-trigger">[20]</a><span>. Because of that, we had to do the computations in an iterative way. We used a divide and conquer approach in order to split APSP into smaller problems that can be computed efficiently on our cluster. In each iteration, we computed the shortest paths for 1000 vertices to all vertices in the simplified graph. Afterwards, the results were gathered into a coherent set of word vectors that represented distances between words in terms of <a href="/topics/computer-science/topology-graph" title="Learn more about graph topology from ScienceDirect's AI-generated Topic Pages" class="topic-link">graph topology</a>.</span></p><p id="para0045">As a result, the computed WordNet2Vec matrix for the current version of WordNet had a size of 147,478 * 147,478. While being stored in dense CSV format, it had a size of 41.8GB. It is worth emphasizing, that the computation of the matrix needs to be performed only once for a particular version of Wordnet. Although a matrix of such size might be uncomfortable for storing in memory on low performance computers, it can be easily organized in any lasting structure, for example <a href="/topics/computer-science/relational-database" title="Learn more about relational database from ScienceDirect's AI-generated Topic Pages" class="topic-link">relational database</a> or  &lt; key,value &gt;  pairs.</p></section><section id="sec0010"><h2 id="sectt0012" class="u-h3 u-margin-l-top u-margin-xs-bottom">5. Use case: WordNet2Vec application to sentiment analysis</h2><div><p id="para0046"><span>The <a href="/topics/computer-science/sentiment-analysis" title="Learn more about sentiment analysis from ScienceDirect's AI-generated Topic Pages" class="topic-link">sentiment analysis</a><span><span> use case is presented as one of the possible application areas. The WordNet2Vec method was applied to build a representation of words from a given document and associated opinion. All such vectors were aggregated into a single one, which in turn was utilized as a single case for learning the <a href="/topics/computer-science/classification-machine-learning" title="Learn more about classifier from ScienceDirect's AI-generated Topic Pages" class="topic-link">classifier</a> in a supervised learning scenario. The same was done for a new document to achieve its vector representation. Then, the </span><a href="/topics/computer-science/sentiment-orientation" title="Learn more about sentiment orientation from ScienceDirect's AI-generated Topic Pages" class="topic-link">sentiment orientation</a> of the new document is predicted by the trained model, see </span></span><a name="bfig0003" href="#fig0003" class="workspace-trigger">Fig.&nbsp;3</a>.</p><figure class="figure text-xs" id="fig0003"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr3.jpg" height="591" alt="Fig. 3" aria-describedby="cap0003"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr3_lrg.jpg" target="_blank" download="" title="Download high-res image (440KB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (440KB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr3.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0003"><p id="spara0006"><span class="label">Fig. 3</span>. Exemplary application of WordNet2Vec method to <a href="/topics/computer-science/sentiment-analysis" title="Learn more about Sentiment Analysis from ScienceDirect's AI-generated Topic Pages" class="topic-link">Sentiment Analysis</a> problem.</p></span></span></figure></div><p id="para0047">In detail, sentiment analysis can be performed with an appropriate sequence of processing steps that include text segmentation and lemmatization, vector look-up in the WordNet2Vec matrix for each word in the document, aggregation of vectors for all words within documents, training and testing the dataset split, and finally classifier learning and testing (for example within the same domain or across domains - transfer learning). In order to perform the learning and testing phase properly we should have some sentiment classes assigned to all documents. The overall flow of the sentiment assignment is presented in <a name="bfig0003" href="#fig0003" class="workspace-trigger">Fig&nbsp;3</a> and all of the steps are discussed below.</p><section id="sec0011"><h3 id="sectt0013" class="u-h4 u-margin-m-top u-margin-xs-bottom">5.1. Text segmentation and lemmatization</h3><p id="para0048">In the first step, some basic <a href="/topics/computer-science/natural-language-processing" title="Learn more about natural language processing from ScienceDirect's AI-generated Topic Pages" class="topic-link">natural language processing</a> methods, namely segmentation and lemmatization, were applied. In order to process each document, it has to be segmented into words. Due to the fact that the WordNet2Vec matrix is configured for words in their lemma form, each word from each document must be lemmatized. It needs to be emphasized here that the method is limited only to words that are included in a wordnet. However, due to the fact that a large wordnet, such as WordNet or plWordNet, is a reliable representation of the lexico-semantic system, our method may be suitable for a very large number of application domains.</p></section><section id="sec0012"><h3 id="sectt0014" class="u-h4 u-margin-m-top u-margin-xs-bottom">5.2. Vector look-up in&nbsp;the WordNet2Vec matrix for a&nbsp;word</h3><p id="para0049"><span>The method for word <a href="/topics/computer-science/vectorization" title="Learn more about vectorization from ScienceDirect's AI-generated Topic Pages" class="topic-link">vectorization</a> proposed in the paper provides a pre-computed WordNet2Vec Matrix. It contains a vector representation for each word from WordNet. In the next step of the flow, vectors for all words in documents are retrieved from the matrix in </span><em>O</em>(1) time.</p></section><section id="sec0013"><h3 id="sectt0015" class="u-h4 u-margin-m-top u-margin-xs-bottom">5.3. Aggregation of vectors for all words within documents</h3><p id="para0050">As sentiment assignment is performed for documents and not for single words, we have to aggregate all the document words. Any aggregation method can be applied including averaging or weighting. However, for the purpose of this use case we applied a simple vector sum, see <a name="beq0001" href="#eq0001" class="workspace-trigger">Eq.&nbsp;1</a>),<span class="display"><span id="eq0001" class="formula"><span class="label">(1)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-15-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mover accent=&quot;true&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>v</mi><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>d</mi><mo is=&quot;true&quot;>)</mo></mrow><mo is=&quot;true&quot;>&amp;#x2192;</mo></mover><mo is=&quot;true&quot;>=</mo><munderover is=&quot;true&quot;><mo is=&quot;true&quot;>&amp;#x2211;</mo><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>i</mi><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>1</mn></mrow><mrow is=&quot;true&quot;><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>|</mo></mrow><msub is=&quot;true&quot;><mi is=&quot;true&quot;>L</mi><mi is=&quot;true&quot;>d</mi></msub><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>|</mo></mrow></mrow></munderover><mover accent=&quot;true&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>v</mi><mo is=&quot;true&quot;>(</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>l</mi><mi is=&quot;true&quot;>i</mi></msub><mo is=&quot;true&quot;>)</mo></mrow><mo is=&quot;true&quot;>&amp;#x2192;</mo></mover></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="17.821ex" height="4.304ex" viewBox="0 -1481.2 7672.7 1853" role="img" focusable="false" style="vertical-align: -0.864ex; margin-top: -0.295ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true" transform="translate(28,0)"><g is="true"><use xlink:href="#MJMATHI-76"></use></g><g is="true" transform="translate(485,0)"><use xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(875,0)"><use xlink:href="#MJMATHI-64"></use></g><g is="true" transform="translate(1398,0)"><use xlink:href="#MJMAIN-29"></use></g></g><g is="true" transform="translate(0,842)"><use xlink:href="#MJMAIN-2212" x="-85" y="0"></use><g transform="translate(378.2704918032787,0) scale(0.9672131147540983,1)"><use xlink:href="#MJMAIN-2212"></use></g><use xlink:href="#MJMAIN-2192" x="843" y="0"></use></g></g><g is="true" transform="translate(2121,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(3178,0)"><g is="true"><use xlink:href="#MJSZ1-2211"></use></g><g is="true" transform="translate(1056,521)"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-7C"></use></g></g><g is="true" transform="translate(196,0)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-4C"></use></g><g is="true" transform="translate(481,-107)"><use transform="scale(0.5)" xlink:href="#MJMATHI-64"></use></g></g><g is="true" transform="translate(1011,0)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-7C"></use></g></g></g><g is="true" transform="translate(1056,-308)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(244,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(794,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g></g></g><g is="true" transform="translate(5709,0)"><g is="true" transform="translate(28,0)"><g is="true"><use xlink:href="#MJMATHI-76"></use></g><g is="true" transform="translate(485,0)"><use xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(875,0)"><g is="true"><use xlink:href="#MJMATHI-6C"></use></g><g is="true" transform="translate(298,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g></g><g is="true" transform="translate(1517,0)"><use xlink:href="#MJMAIN-29"></use></g></g><g is="true" transform="translate(0,842)"><use xlink:href="#MJMAIN-2212" x="-85" y="0"></use><g transform="translate(361.74376114746565,0) scale(1.162795726065495,1)"><use xlink:href="#MJMAIN-2212"></use></g><use xlink:href="#MJMAIN-2192" x="962" y="0"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mover accent="true" is="true"><mrow is="true"><mi is="true">v</mi><mo is="true">(</mo><mi is="true">d</mi><mo is="true">)</mo></mrow><mo is="true">→</mo></mover><mo is="true">=</mo><munderover is="true"><mo is="true">∑</mo><mrow is="true"><mi is="true">i</mi><mo is="true">=</mo><mn is="true">1</mn></mrow><mrow is="true"><mrow is="true"><mo is="true">|</mo></mrow><msub is="true"><mi is="true">L</mi><mi is="true">d</mi></msub><mrow is="true"><mo is="true">|</mo></mrow></mrow></munderover><mover accent="true" is="true"><mrow is="true"><mi is="true">v</mi><mo is="true">(</mo><msub is="true"><mi is="true">l</mi><mi is="true">i</mi></msub><mo is="true">)</mo></mrow><mo is="true">→</mo></mover></mrow></math></span></span><script type="math/mml" id="MathJax-Element-15"><math><mrow is="true"><mover accent="true" is="true"><mrow is="true"><mi is="true">v</mi><mo is="true">(</mo><mi is="true">d</mi><mo is="true">)</mo></mrow><mo is="true">→</mo></mover><mo is="true">=</mo><munderover is="true"><mo is="true">∑</mo><mrow is="true"><mi is="true">i</mi><mo is="true">=</mo><mn is="true">1</mn></mrow><mrow is="true"><mrow is="true"><mo is="true">|</mo></mrow><msub is="true"><mi is="true">L</mi><mi is="true">d</mi></msub><mrow is="true"><mo is="true">|</mo></mrow></mrow></munderover><mover accent="true" is="true"><mrow is="true"><mi is="true">v</mi><mo is="true">(</mo><msub is="true"><mi is="true">l</mi><mi is="true">i</mi></msub><mo is="true">)</mo></mrow><mo is="true">→</mo></mover></mrow></math></script></span></span></span> where<dl class="list"><dd class="list-description"><p id="para0051"><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-16-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mover accent=&quot;true&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>v</mi><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>d</mi><mo is=&quot;true&quot;>)</mo></mrow><mo is=&quot;true&quot;>&amp;#x2192;</mo></mover></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.283ex" height="4.295ex" viewBox="0 -1530.9 1844 1849.2" role="img" focusable="false" style="vertical-align: -0.739ex; margin-top: -0.411ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true" transform="translate(28,0)"><g is="true"><use xlink:href="#MJMATHI-76"></use></g><g is="true" transform="translate(485,0)"><use xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(875,0)"><use xlink:href="#MJMATHI-64"></use></g><g is="true" transform="translate(1398,0)"><use xlink:href="#MJMAIN-29"></use></g></g><g is="true" transform="translate(0,842)"><use xlink:href="#MJMAIN-2212" x="-85" y="0"></use><g transform="translate(378.2704918032787,0) scale(0.9672131147540983,1)"><use xlink:href="#MJMAIN-2212"></use></g><use xlink:href="#MJMAIN-2192" x="843" y="0"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true" is="true"><mrow is="true"><mi is="true">v</mi><mo is="true">(</mo><mi is="true">d</mi><mo is="true">)</mo></mrow><mo is="true">→</mo></mover></math></span></span><script type="math/mml" id="MathJax-Element-16"><math><mover accent="true" is="true"><mrow is="true"><mi is="true">v</mi><mo is="true">(</mo><mi is="true">d</mi><mo is="true">)</mo></mrow><mo is="true">→</mo></mover></math></script></span> is the WordNet2Vec aggregated representation of document <em>d</em>,</p></dd><dd class="list-description"><p id="para0052">|<em>L<sub>d</sub></em>| denotes the list of lemmas extracted from document <em>d</em>,</p></dd><dd class="list-description"><p id="para0053"><em>l<sub>i</sub></em> is the <em>i</em>th lemma from document <em>d, l<sub>i</sub></em> ∈ <em>L<sub>d</sub></em></p></dd><dd class="list-description"><p id="para0054"><em>v</em>(<em>l<sub>i</sub></em>) is the <em>i</em>th Wordnet2Vec vector corresponding to lemma <em>l<sub>i</sub></em>.</p></dd></dl></p></section><section id="sec0014"><h3 id="sectt0016" class="u-h4 u-margin-m-top u-margin-xs-bottom">5.4. Dataset split, classifier learning and testing</h3><p id="para0055">Once all the documents possess a single vector representation, they form a dataset appropriate for training and testing classifiers. In order to examine the <a href="/topics/computer-science/generalization-ability" title="Learn more about generalization abilities from ScienceDirect's AI-generated Topic Pages" class="topic-link">generalization abilities</a> of the classifiers, two distinct scenarios were designed: learning and testing within the same domain or corpus of texts (the same type of documents) and transfer learning, learning on one domain and testing on another one.</p></section></section><section id="sec0015"><h2 id="sectt0017" class="u-h3 u-margin-l-top u-margin-xs-bottom">6. Experimental setup</h2><p id="para0056">Following the scenario presented in the <a name="bsec0010" href="#sec0010" class="workspace-trigger">Section&nbsp;5</a>, we performed validity tests by examining a sentiment assignment task. In the following sections, we describe the data that were utilized, the details of the experiments and the received results.</p><section id="sec0016"><h3 id="sectt0018" class="u-h4 u-margin-m-top u-margin-xs-bottom">6.1. Datasets</h3><div><p id="para0057">We chose data from one data source - the Amazon e-commerce platform <a name="bbib0041" href="#bib0041" class="workspace-trigger">[41]</a>. The data spans a period of 18 years, including 35 million reviews up to March 2013. Reviews include product and user information, ratings, and a plain text review. Some basic statistical information about the dataset is presented in <a name="btbl0001" href="#tbl0001" class="workspace-trigger">Table&nbsp;1</a>.</p><div class="tables rowsep-0 colsep-0 frame-topbot" id="tbl0001"><span class="captions"><span id="cap0011"><p id="spara0014"><span class="label">Table 1</span>. Statistics of the whole Amazon reviews dataset.</p></span></span><div class="groups"><table><tbody><tr><th class="align-left valign-top" scope="row">Number of reviews</th><th class="align-left valign-top" scope="row">34,686,770</th></tr><tr><td class="align-left valign-top">Number of users</td><td class="align-left valign-top">6,643,669</td></tr><tr><td class="align-left valign-top">Number of products</td><td class="align-left valign-top">2,441,053</td></tr><tr><td class="align-left valign-top">Users with  &gt;  50 reviews</td><td class="align-left valign-top">56,772</td></tr><tr><td class="align-left valign-top">Median no. of words per review</td><td class="align-left valign-top">82</td></tr><tr><td class="align-left valign-top">Time span</td><td class="align-left valign-top">Jun 1995 - Mar 2013</td></tr></tbody></table></div></div></div><div><p id="para0058"><span>The whole experiment was conducted on a selected part of the Amazon data that consisted of 7 domains, namely: Automotive, Sports &amp; Outdoors, Books, Health, Video Games, Toys &amp; Games, Movies &amp; TV. Due to the fact that the distribution of classes is important while interpreting the results of <a href="/topics/computer-science/classification" title="Learn more about classification from ScienceDirect's AI-generated Topic Pages" class="topic-link">classification</a> validation, the proper histogram is presented in </span><a name="bfig0004" href="#fig0004" class="workspace-trigger">Fig.&nbsp;4</a>. The domains of the review dataset that were chosen for the experiment are listed in <a name="btbl0002" href="#tbl0002" class="workspace-trigger">Table&nbsp;2</a>).</p><figure class="figure text-xs" id="fig0004"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr4.jpg" height="381" alt="Fig. 4" aria-describedby="cap0004"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr4_lrg.jpg" target="_blank" download="" title="Download high-res image (223KB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (223KB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr4.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0004"><p id="spara0007"><span class="label">Fig. 4</span>. Distribution of original scores expressed in&nbsp;stars over domains in&nbsp;the&nbsp;Amazon Dataset.</p></span></span></figure><div class="tables rowsep-0 colsep-0 frame-topbot" id="tbl0002"><span class="captions"><span id="cap0012"><p id="spara0015"><span class="label">Table 2</span>. Dataset domains used in&nbsp;the&nbsp;experiment.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="row" class="align-left valign-top">Domain</th><th scope="row" class="align-left valign-top">Number of reviews</th></tr></thead><tbody><tr><td class="align-left valign-top">Automotive</td><td class="align-left valign-top">174,414</td></tr><tr><td class="align-left valign-top">Book</td><td class="align-left valign-top">697,225</td></tr><tr><td class="align-left valign-top">Health</td><td class="align-left valign-top">428,781</td></tr><tr><td class="align-left valign-top">Movie TV</td><td class="align-left valign-top">765,961</td></tr><tr><td class="align-left valign-top">Sports Outdoor</td><td class="align-left valign-top">504,773</td></tr><tr><td class="align-left valign-top">Toy Game</td><td class="align-left valign-top">389,221</td></tr><tr><td class="align-left valign-top">Video Game</td><td class="align-left valign-top">364,206</td></tr></tbody></table></div></div></div><div><p id="para0059"><span>In order to check the accuracy of the proposed methods, we extracted the <a href="/topics/computer-science/sentiment-orientation" title="Learn more about sentiment orientation from ScienceDirect's AI-generated Topic Pages" class="topic-link">sentiment orientation</a> from ratings expressed with stars. Ratings were mapped to the following classes: positive, neutral and negative, using 1 and 2 stars, 3 stars, 4 and 5 stars respectively, see </span><a name="btbl0003" href="#tbl0003" class="workspace-trigger">Table&nbsp;3</a>.</p><div class="tables rowsep-0 colsep-0 frame-topbot" id="tbl0003"><span class="captions"><span id="cap0013"><p id="spara0016"><span class="label">Table 3</span>. Star rating mapping to sentiment classes.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="row" class="align-left valign-top">Star Score</th><th scope="row" class="align-left valign-top">Sentiment Class</th></tr></thead><tbody><tr><td class="align-left valign-top"><figure class="inline-figure"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-fx4.jpg" height="10" alt="Image 2"></figure></td><td class="align-left valign-top">Negative</td></tr><tr><td class="align-left valign-top"><figure class="inline-figure"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-fx4.jpg" height="10" alt="Image 2"></figure><figure class="inline-figure"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-fx4.jpg" height="10" alt="Image 2"></figure></td><td class="align-left valign-top">Negative<br></td></tr><tr><td class="align-left valign-top"><figure class="inline-figure"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-fx4.jpg" height="10" alt="Image 2"></figure><figure class="inline-figure"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-fx4.jpg" height="10" alt="Image 2"></figure><figure class="inline-figure"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-fx4.jpg" height="10" alt="Image 2"></figure></td><td class="align-left valign-top">Neutral<br></td></tr><tr><td class="align-left valign-top"><figure class="inline-figure"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-fx4.jpg" height="10" alt="Image 2"></figure><figure class="inline-figure"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-fx4.jpg" height="10" alt="Image 2"></figure><figure class="inline-figure"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-fx4.jpg" height="10" alt="Image 2"></figure><figure class="inline-figure"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-fx4.jpg" height="10" alt="Image 2"></figure></td><td class="align-left valign-top">Positive</td></tr><tr><td class="align-left valign-top"><figure class="inline-figure"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-fx4.jpg" height="10" alt="Image 2"></figure><figure class="inline-figure"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-fx4.jpg" height="10" alt="Image 2"></figure><figure class="inline-figure"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-fx4.jpg" height="10" alt="Image 2"></figure><figure class="inline-figure"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-fx4.jpg" height="10" alt="Image 2"></figure><figure class="inline-figure"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-fx4.jpg" height="10" alt="Image 2"></figure></td><td class="align-left valign-top">Positive</td></tr></tbody></table></div></div></div></section><section id="sec0017"><h3 id="sectt0019" class="u-h4 u-margin-m-top u-margin-xs-bottom">6.2. Distributed environment</h3><p id="para0060">In our experiments, we utilized a computational cluster that consists of 12 nodes with 24 cores and 60GB of RAM each. <a href="/topics/computer-science/apache-spark" title="Learn more about Apache Spark from ScienceDirect's AI-generated Topic Pages" class="topic-link">Apache Spark</a> 1.5 and our SparklingGraph 0.0.5 were used for distributed computations.</p></section><section id="sec0018"><h3 id="sectt0020" class="u-h4 u-margin-m-top u-margin-xs-bottom">6.3. Methods</h3><p id="para0061"><span>Our experiments were divided into two distinct groups. The first of them consisted of a classic <a href="/topics/computer-science/machine-learning" title="Learn more about machine learning from ScienceDirect's AI-generated Topic Pages" class="topic-link">machine learning</a> evaluation using a 10 times randomly repeated train/test 50:50 split performed on each of the seven mentioned datasets. In the second group of experiments, we used a one versus all transfer learning evaluation. Whenever one domain was used as a training set, it was evaluated on the rest of the domains. Thanks to both scenarios, we examined the quality of a classic </span><a href="/topics/computer-science/sentiment-analysis" title="Learn more about sentiment analysis from ScienceDirect's AI-generated Topic Pages" class="topic-link">sentiment analysis</a><span> within one dataset domain, and between different domains. In both experimental groups, we used two methods of text <a href="/topics/computer-science/vectorization" title="Learn more about vectorization from ScienceDirect's AI-generated Topic Pages" class="topic-link">vectorization</a>: WordNet2Vec proposed by us and Doc2Vec as a reference.</span></p><p id="para0062"><span>Doc2Vec expresses a <a href="/topics/computer-science/generalization" title="Learn more about generalization from ScienceDirect's AI-generated Topic Pages" class="topic-link">generalization</a> of the Word2Vec algorithm on the document level. The Word2Vec model shows how a word is usually used in a window context according to other words (how words co-occur with each other). The procedure of counting Doc2Vec is very similar to Word2Vec, except it generalizes the model by adding a document vector. There are two methods used in Doc2Vec: Distributed Memory (DM) and Distributed Bag of Words (DBOW). The first one attempts to predict a word given its previous words and a paragraph vector. Even though the context window moves across the text, the paragraph vector does not (hence distributed memory) and allows for some word order to be captured. On the other hand, DBOW predicts a random group of words in a paragraph given only its paragraph vector. In our experiments, we used the Distributed Memory method trained on the Amazon SNAP (see </span><a name="bsec0016" href="#sec0016" class="workspace-trigger">Section&nbsp;6.1</a>) review dataset. A separate model was trained for each domain and length of a vector equal to 400.</p><p id="para0063">In order to evaluate the standard classification approach we also provided a baseline <em>F</em>1<sub><em>weighted</em></sub><span> value that would be achieved if we were to use a <a href="/topics/computer-science/classification-machine-learning" title="Learn more about classifier from ScienceDirect's AI-generated Topic Pages" class="topic-link">classifier</a> that always returned a major class.</span></p><p id="para0064"><span><a href="/topics/computer-science/logistic-regression" title="Learn more about Logistic regression from ScienceDirect's AI-generated Topic Pages" class="topic-link">Logistic regression</a> was selected as a supervised learning model and in order to train it we used a limited memory BFGS algorithm </span><a name="bbib0042" href="#bib0042" class="workspace-trigger">[42]</a>. There was a computational trade-off for vectorized documents in the space size dependent on the Wordnet2Vec Matrix size. Due to the fact that datasets used in the experiments are imbalanced, see <a name="bfig0004" href="#fig0004" class="workspace-trigger">Fig.&nbsp;4</a>), we used a weighted F1 score for the evaluation of the results that properly handle imbalanced class distributions. The weighting was based on the size of each class, see <a name="beq0002" href="#eq0002" class="workspace-trigger">Eq. (2)</a>.<span class="display"><span id="eq0002" class="formula"><span class="label">(2)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-17-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtable displaystyle=&quot;true&quot; is=&quot;true&quot;><mtr is=&quot;true&quot;><mtd columnalign=&quot;right&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>F</mi><msub is=&quot;true&quot;><mn is=&quot;true&quot;>1</mn><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>g</mi><mi is=&quot;true&quot;>h</mi><mi is=&quot;true&quot;>t</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>d</mi></mrow></msub></mrow></mtd><mtd is=&quot;true&quot;><mo is=&quot;true&quot;>=</mo></mtd><mtd columnalign=&quot;left&quot; is=&quot;true&quot;><mfrac is=&quot;true&quot;><mrow is=&quot;true&quot;><msubsup is=&quot;true&quot;><mo is=&quot;true&quot;>&amp;#x2211;</mo><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>i</mi></mrow><mi is=&quot;true&quot;>k</mi></msubsup><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>|</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>C</mi><mi is=&quot;true&quot;>i</mi></msub><mo is=&quot;true&quot;>|</mo></mrow><mo is=&quot;true&quot;>&amp;#xB7;</mo><mi is=&quot;true&quot;>F</mi><msub is=&quot;true&quot;><mn is=&quot;true&quot;>1</mn><msub is=&quot;true&quot;><mi is=&quot;true&quot;>C</mi><mi is=&quot;true&quot;>i</mi></msub></msub></mrow><mrow is=&quot;true&quot;><msubsup is=&quot;true&quot;><mo is=&quot;true&quot;>&amp;#x2211;</mo><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>k</mi></msubsup><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>|</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>C</mi><mi is=&quot;true&quot;>i</mi></msub><mo is=&quot;true&quot;>|</mo></mrow></mrow></mfrac></mtd></mtr></mtable></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="30.944ex" height="7.249ex" viewBox="0 -1798.2 13323.3 3120.9" role="img" focusable="false" style="vertical-align: -3.072ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true" transform="translate(167,0)"><g transform="translate(-15,0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-46"></use></g><g is="true" transform="translate(749,0)"><g is="true"><use xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(500,-150)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(506,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(836,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(1080,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-67"></use></g><g is="true" transform="translate(1420,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-68"></use></g><g is="true" transform="translate(1828,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-74"></use></g><g is="true" transform="translate(2083,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(2413,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-64"></use></g></g></g></g></g></g><g transform="translate(4919,0)"><g is="true"><g is="true"><use xlink:href="#MJMAIN-3D"></use></g></g></g><g transform="translate(6498,0)"><g is="true"><g is="true"><g transform="translate(120,0)"><rect stroke="none" width="6251" height="60" x="0" y="220"></rect><g is="true" transform="translate(60,766)"><g is="true"><g is="true"><use xlink:href="#MJSZ1-2211"></use></g><g is="true" transform="translate(1056,477)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6B"></use></g><g is="true" transform="translate(1056,-287)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g></g></g><g is="true" transform="translate(1691,0)"><g is="true"><use xlink:href="#MJMAIN-7C"></use></g><g is="true" transform="translate(278,0)"><g is="true"><use xlink:href="#MJMATHI-43"></use></g><g is="true" transform="translate(715,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g></g><g is="true" transform="translate(1338,0)"><use xlink:href="#MJMAIN-7C"></use></g></g><g is="true" transform="translate(3530,0)"><use xlink:href="#MJMAIN-22C5"></use></g><g is="true" transform="translate(4031,0)"><use xlink:href="#MJMATHI-46"></use></g><g is="true" transform="translate(4781,0)"><g is="true"><use xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(500,-155)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-43"></use></g><g is="true" transform="translate(505,-107)"><use transform="scale(0.5)" xlink:href="#MJMATHI-69"></use></g></g></g></g><g is="true" transform="translate(1471,-942)"><g is="true"><g is="true"><use xlink:href="#MJSZ1-2211"></use></g><g is="true" transform="translate(1056,477)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6B"></use></g><g is="true" transform="translate(1056,-287)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g></g><g is="true" transform="translate(1691,0)"><g is="true"><use xlink:href="#MJMAIN-7C"></use></g><g is="true" transform="translate(278,0)"><g is="true"><use xlink:href="#MJMATHI-43"></use></g><g is="true" transform="translate(715,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g></g><g is="true" transform="translate(1338,0)"><use xlink:href="#MJMAIN-7C"></use></g></g></g></g></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable displaystyle="true" is="true"><mtr is="true"><mtd columnalign="right" is="true"><mrow is="true"><mi is="true">F</mi><msub is="true"><mn is="true">1</mn><mrow is="true"><mi is="true">w</mi><mi is="true">e</mi><mi is="true">i</mi><mi is="true">g</mi><mi is="true">h</mi><mi is="true">t</mi><mi is="true">e</mi><mi is="true">d</mi></mrow></msub></mrow></mtd><mtd is="true"><mo is="true">=</mo></mtd><mtd columnalign="left" is="true"><mfrac is="true"><mrow is="true"><msubsup is="true"><mo is="true">∑</mo><mrow is="true"><mi is="true">i</mi></mrow><mi is="true">k</mi></msubsup><mrow is="true"><mo is="true">|</mo><msub is="true"><mi is="true">C</mi><mi is="true">i</mi></msub><mo is="true">|</mo></mrow><mo is="true">·</mo><mi is="true">F</mi><msub is="true"><mn is="true">1</mn><msub is="true"><mi is="true">C</mi><mi is="true">i</mi></msub></msub></mrow><mrow is="true"><msubsup is="true"><mo is="true">∑</mo><mi is="true">i</mi><mi is="true">k</mi></msubsup><mrow is="true"><mo is="true">|</mo><msub is="true"><mi is="true">C</mi><mi is="true">i</mi></msub><mo is="true">|</mo></mrow></mrow></mfrac></mtd></mtr></mtable></math></span></span><script type="math/mml" id="MathJax-Element-17"><math><mtable displaystyle="true" is="true"><mtr is="true"><mtd columnalign="right" is="true"><mrow is="true"><mi is="true">F</mi><msub is="true"><mn is="true">1</mn><mrow is="true"><mi is="true">w</mi><mi is="true">e</mi><mi is="true">i</mi><mi is="true">g</mi><mi is="true">h</mi><mi is="true">t</mi><mi is="true">e</mi><mi is="true">d</mi></mrow></msub></mrow></mtd><mtd is="true"><mo is="true">=</mo></mtd><mtd columnalign="left" is="true"><mfrac is="true"><mrow is="true"><msubsup is="true"><mo is="true">∑</mo><mrow is="true"><mi is="true">i</mi></mrow><mi is="true">k</mi></msubsup><mrow is="true"><mo is="true">|</mo><msub is="true"><mi is="true">C</mi><mi is="true">i</mi></msub><mo is="true">|</mo></mrow><mo is="true">·</mo><mi is="true">F</mi><msub is="true"><mn is="true">1</mn><msub is="true"><mi is="true">C</mi><mi is="true">i</mi></msub></msub></mrow><mrow is="true"><msubsup is="true"><mo is="true">∑</mo><mi is="true">i</mi><mi is="true">k</mi></msubsup><mrow is="true"><mo is="true">|</mo><msub is="true"><mi is="true">C</mi><mi is="true">i</mi></msub><mo is="true">|</mo></mrow></mrow></mfrac></mtd></mtr></mtable></math></script></span></span></span> where:<dl class="list"><dt class="list-label">•</dt><dd class="list-description"><p id="para0065"><em>k</em> - number of classes,</p></dd><dt class="list-label">•</dt><dd class="list-description"><p id="para0066">|<em>C<sub>i</sub></em>| - cardinality of set <em>C<sub>i</sub></em> with classification results for class <em>i</em>, i.e. number of cases in class <em>i</em>,</p></dd><dt class="list-label">•</dt><dd class="list-description"><p id="para0067"><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-18-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>F</mi><msub is=&quot;true&quot;><mn is=&quot;true&quot;>1</mn><msub is=&quot;true&quot;><mi is=&quot;true&quot;>C</mi><mi is=&quot;true&quot;>i</mi></msub></msub></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.876ex" height="2.586ex" viewBox="0 -741.6 2099.4 1113.4" role="img" focusable="false" style="vertical-align: -0.864ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-46"></use></g><g is="true" transform="translate(749,0)"><g is="true"><use xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(500,-155)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-43"></use></g><g is="true" transform="translate(505,-107)"><use transform="scale(0.5)" xlink:href="#MJMATHI-69"></use></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">F</mi><msub is="true"><mn is="true">1</mn><msub is="true"><mi is="true">C</mi><mi is="true">i</mi></msub></msub></mrow></math></span></span><script type="math/mml" id="MathJax-Element-18"><math><mrow is="true"><mi is="true">F</mi><msub is="true"><mn is="true">1</mn><msub is="true"><mi is="true">C</mi><mi is="true">i</mi></msub></msub></mrow></math></script></span> - <em>F</em>1 score measure for <em>C<sub>i</sub></em> classification results.</p></dd></dl><span class="display"><span id="eq0003" class="formula"><span class="label">(3)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-19-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>F</mi><mn is=&quot;true&quot;>1</mn><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>2</mn><mo is=&quot;true&quot;>*</mo><mfrac is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>p</mi><mi is=&quot;true&quot;>r</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>c</mi><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>s</mi><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>o</mi><mi is=&quot;true&quot;>n</mi><mo is=&quot;true&quot;>*</mo><mi is=&quot;true&quot;>r</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>c</mi><mi is=&quot;true&quot;>a</mi><mi is=&quot;true&quot;>l</mi><mi is=&quot;true&quot;>l</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>p</mi><mi is=&quot;true&quot;>r</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>c</mi><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>s</mi><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>o</mi><mi is=&quot;true&quot;>n</mi><mo is=&quot;true&quot;>+</mo><mi is=&quot;true&quot;>r</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>c</mi><mi is=&quot;true&quot;>a</mi><mi is=&quot;true&quot;>l</mi><mi is=&quot;true&quot;>l</mi></mrow></mfrac></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="22.279ex" height="4.181ex" viewBox="0 -1164.2 9592.4 1800.2" role="img" focusable="false" style="vertical-align: -1.477ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-46"></use></g><g is="true" transform="translate(749,0)"><use xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(1527,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(2584,0)"><use xlink:href="#MJMAIN-32"></use></g><g is="true" transform="translate(3306,0)"><use xlink:href="#MJMAIN-2A"></use></g><g is="true" transform="translate(3807,0)"><g transform="translate(342,0)"><rect stroke="none" width="5322" height="60" x="0" y="220"></rect><g is="true" transform="translate(158,546)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-70"></use></g><g is="true" transform="translate(356,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-72"></use></g><g is="true" transform="translate(675,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(1005,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-63"></use></g><g is="true" transform="translate(1311,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(1555,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-73"></use></g><g is="true" transform="translate(1887,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(2132,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6F"></use></g><g is="true" transform="translate(2475,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6E"></use></g><g is="true" transform="translate(2900,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2A"></use></g><g is="true" transform="translate(3254,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-72"></use></g><g is="true" transform="translate(3573,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(3903,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-63"></use></g><g is="true" transform="translate(4209,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-61"></use></g><g is="true" transform="translate(4584,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6C"></use></g><g is="true" transform="translate(4795,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6C"></use></g></g><g is="true" transform="translate(60,-402)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-70"></use></g><g is="true" transform="translate(356,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-72"></use></g><g is="true" transform="translate(675,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(1005,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-63"></use></g><g is="true" transform="translate(1311,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(1555,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-73"></use></g><g is="true" transform="translate(1887,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(2132,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6F"></use></g><g is="true" transform="translate(2475,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6E"></use></g><g is="true" transform="translate(2900,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(3450,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-72"></use></g><g is="true" transform="translate(3769,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(4099,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-63"></use></g><g is="true" transform="translate(4406,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-61"></use></g><g is="true" transform="translate(4780,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6C"></use></g><g is="true" transform="translate(4991,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6C"></use></g></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">F</mi><mn is="true">1</mn><mo is="true">=</mo><mn is="true">2</mn><mo is="true">*</mo><mfrac is="true"><mrow is="true"><mi is="true">p</mi><mi is="true">r</mi><mi is="true">e</mi><mi is="true">c</mi><mi is="true">i</mi><mi is="true">s</mi><mi is="true">i</mi><mi is="true">o</mi><mi is="true">n</mi><mo is="true">*</mo><mi is="true">r</mi><mi is="true">e</mi><mi is="true">c</mi><mi is="true">a</mi><mi is="true">l</mi><mi is="true">l</mi></mrow><mrow is="true"><mi is="true">p</mi><mi is="true">r</mi><mi is="true">e</mi><mi is="true">c</mi><mi is="true">i</mi><mi is="true">s</mi><mi is="true">i</mi><mi is="true">o</mi><mi is="true">n</mi><mo is="true">+</mo><mi is="true">r</mi><mi is="true">e</mi><mi is="true">c</mi><mi is="true">a</mi><mi is="true">l</mi><mi is="true">l</mi></mrow></mfrac></mrow></math></span></span><script type="math/mml" id="MathJax-Element-19"><math><mrow is="true"><mi is="true">F</mi><mn is="true">1</mn><mo is="true">=</mo><mn is="true">2</mn><mo is="true">*</mo><mfrac is="true"><mrow is="true"><mi is="true">p</mi><mi is="true">r</mi><mi is="true">e</mi><mi is="true">c</mi><mi is="true">i</mi><mi is="true">s</mi><mi is="true">i</mi><mi is="true">o</mi><mi is="true">n</mi><mo is="true">*</mo><mi is="true">r</mi><mi is="true">e</mi><mi is="true">c</mi><mi is="true">a</mi><mi is="true">l</mi><mi is="true">l</mi></mrow><mrow is="true"><mi is="true">p</mi><mi is="true">r</mi><mi is="true">e</mi><mi is="true">c</mi><mi is="true">i</mi><mi is="true">s</mi><mi is="true">i</mi><mi is="true">o</mi><mi is="true">n</mi><mo is="true">+</mo><mi is="true">r</mi><mi is="true">e</mi><mi is="true">c</mi><mi is="true">a</mi><mi is="true">l</mi><mi is="true">l</mi></mrow></mfrac></mrow></math></script></span></span></span></p><div><p id="para0068">In order to compare the two approaches (WordNet2Vec and Doc2Vec), we applied a statistical test on paired measures for each of the experiments. We used the Wilcoxon signed-rank test <a name="bbib0043" href="#bib0043" class="workspace-trigger">[43]</a> for pairs of weighted F1 score (<a name="beq0002" href="#eq0002" class="workspace-trigger">Eq.&nbsp;2</a>) with confidence level <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-20-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x3B1;</mi><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>0.05</mn></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="8.72ex" height="1.972ex" viewBox="0 -741.6 3754.6 849.3" role="img" focusable="false" style="vertical-align: -0.25ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-3B1"></use></g><g is="true" transform="translate(918,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(1974,0)"><use xlink:href="#MJMAIN-30"></use><use xlink:href="#MJMAIN-2E" x="500" y="0"></use><use xlink:href="#MJMAIN-30" x="779" y="0"></use><use xlink:href="#MJMAIN-35" x="1279" y="0"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">α</mi><mo is="true">=</mo><mn is="true">0.05</mn></mrow></math></span></span><script type="math/mml" id="MathJax-Element-20"><math><mrow is="true"><mi is="true">α</mi><mo is="true">=</mo><mn is="true">0.05</mn></mrow></math></script></span> (<a name="btbl0004" href="#tbl0004" class="workspace-trigger">Tables&nbsp;4</a> and <a name="btbl0005" href="#tbl0005" class="workspace-trigger">5</a>). To provide deeper insight into the differences between the results achieved by the methods we also present histograms of differences between <em>F</em>1<sub><em>weighted</em></sub> of both methods (see <a name="bfig0006" href="#fig0006" class="workspace-trigger">Figs.&nbsp;6</a>, <a name="bfig0010" href="#fig0010" class="workspace-trigger">10</a>).</p><div class="tables rowsep-0 colsep-0 frame-topbot" id="tbl0004"><span class="captions"><span id="cap0014"><p id="spara0017"><span class="label">Table 4</span>. Wilcoxon rank-sum test results for <a href="/topics/computer-science/classification" title="Learn more about classification from ScienceDirect's AI-generated Topic Pages" class="topic-link">classification</a>.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="row" class="align-left valign-top">Method 1</th><th scope="row" class="align-left valign-top">Method 2</th><th scope="row" class="align-left valign-top"><em>H<sub>a</sub></em></th><th scope="row" class="align-left valign-top">p-value</th></tr></thead><tbody><tr><td class="align-left valign-top">Doc2Vec</td><td class="align-left valign-top">WordNet2Vec</td><td class="align-left valign-top"><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-21-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>F</mi><msubsup is=&quot;true&quot;><mn is=&quot;true&quot;>1</mn><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>g</mi><mi is=&quot;true&quot;>h</mi><mi is=&quot;true&quot;>t</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>d</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>D</mi><mi is=&quot;true&quot;>o</mi><mi is=&quot;true&quot;>c</mi><mn is=&quot;true&quot;>2</mn><mi is=&quot;true&quot;>V</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>c</mi></mrow></msubsup><mo is=&quot;true&quot;>&amp;gt;</mo><mi is=&quot;true&quot;>F</mi><msubsup is=&quot;true&quot;><mn is=&quot;true&quot;>1</mn><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>g</mi><mi is=&quot;true&quot;>h</mi><mi is=&quot;true&quot;>t</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>d</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>W</mi><mi is=&quot;true&quot;>o</mi><mi is=&quot;true&quot;>r</mi><mi is=&quot;true&quot;>d</mi><mi is=&quot;true&quot;>N</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>t</mi><mn is=&quot;true&quot;>2</mn><mi is=&quot;true&quot;>V</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>c</mi></mrow></msubsup></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="16.092ex" height="7.568ex" viewBox="0 -951.3 6928.6 3258.6" role="img" focusable="false" style="vertical-align: -5.359ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMATHI-46"></use></g><g is="true" transform="translate(749,0)"><g is="true"><use xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(500,393)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-44"></use></g><g is="true" transform="translate(585,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6F"></use></g><g is="true" transform="translate(929,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-63"></use></g><g is="true" transform="translate(1235,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-32"></use></g><g is="true" transform="translate(1589,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-56"></use></g><g is="true" transform="translate(2133,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(2463,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-63"></use></g></g><g is="true" transform="translate(500,-294)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(506,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(836,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(1080,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-67"></use></g><g is="true" transform="translate(1420,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-68"></use></g><g is="true" transform="translate(1828,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-74"></use></g><g is="true" transform="translate(2083,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(2413,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-64"></use></g></g></g><g transform="translate(0,-1756)"><g is="true"><use xlink:href="#MJMAIN-3E"></use></g><g is="true" transform="translate(1056,0)"><use xlink:href="#MJMATHI-46"></use></g><g is="true" transform="translate(1805,0)"><g is="true"><use xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(500,393)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-57"></use></g><g is="true" transform="translate(741,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6F"></use></g><g is="true" transform="translate(1084,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-72"></use></g><g is="true" transform="translate(1403,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-64"></use></g><g is="true" transform="translate(1774,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-4E"></use></g><g is="true" transform="translate(2402,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(2732,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-74"></use></g><g is="true" transform="translate(2987,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-32"></use></g><g is="true" transform="translate(3341,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-56"></use></g><g is="true" transform="translate(3885,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(4215,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-63"></use></g></g><g is="true" transform="translate(500,-294)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(506,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(836,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(1080,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-67"></use></g><g is="true" transform="translate(1420,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-68"></use></g><g is="true" transform="translate(1828,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-74"></use></g><g is="true" transform="translate(2083,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(2413,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-64"></use></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">F</mi><msubsup is="true"><mn is="true">1</mn><mrow is="true"><mi is="true">w</mi><mi is="true">e</mi><mi is="true">i</mi><mi is="true">g</mi><mi is="true">h</mi><mi is="true">t</mi><mi is="true">e</mi><mi is="true">d</mi></mrow><mrow is="true"><mi is="true">D</mi><mi is="true">o</mi><mi is="true">c</mi><mn is="true">2</mn><mi is="true">V</mi><mi is="true">e</mi><mi is="true">c</mi></mrow></msubsup><mo is="true">&gt;</mo><mi is="true">F</mi><msubsup is="true"><mn is="true">1</mn><mrow is="true"><mi is="true">w</mi><mi is="true">e</mi><mi is="true">i</mi><mi is="true">g</mi><mi is="true">h</mi><mi is="true">t</mi><mi is="true">e</mi><mi is="true">d</mi></mrow><mrow is="true"><mi is="true">W</mi><mi is="true">o</mi><mi is="true">r</mi><mi is="true">d</mi><mi is="true">N</mi><mi is="true">e</mi><mi is="true">t</mi><mn is="true">2</mn><mi is="true">V</mi><mi is="true">e</mi><mi is="true">c</mi></mrow></msubsup></mrow></math></span></span><script type="math/mml" id="MathJax-Element-21"><math><mrow is="true"><mi is="true">F</mi><msubsup is="true"><mn is="true">1</mn><mrow is="true"><mi is="true">w</mi><mi is="true">e</mi><mi is="true">i</mi><mi is="true">g</mi><mi is="true">h</mi><mi is="true">t</mi><mi is="true">e</mi><mi is="true">d</mi></mrow><mrow is="true"><mi is="true">D</mi><mi is="true">o</mi><mi is="true">c</mi><mn is="true">2</mn><mi is="true">V</mi><mi is="true">e</mi><mi is="true">c</mi></mrow></msubsup><mo is="true">&gt;</mo><mi is="true">F</mi><msubsup is="true"><mn is="true">1</mn><mrow is="true"><mi is="true">w</mi><mi is="true">e</mi><mi is="true">i</mi><mi is="true">g</mi><mi is="true">h</mi><mi is="true">t</mi><mi is="true">e</mi><mi is="true">d</mi></mrow><mrow is="true"><mi is="true">W</mi><mi is="true">o</mi><mi is="true">r</mi><mi is="true">d</mi><mi is="true">N</mi><mi is="true">e</mi><mi is="true">t</mi><mn is="true">2</mn><mi is="true">V</mi><mi is="true">e</mi><mi is="true">c</mi></mrow></msubsup></mrow></math></script></span></td><td class="align-left valign-top">0.007813<br></td></tr><tr><td class="align-left valign-top">WordNet2Vec</td><td class="align-left valign-top">Baseline</td><td class="align-left valign-top"><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-22-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>F</mi><msubsup is=&quot;true&quot;><mn is=&quot;true&quot;>1</mn><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>g</mi><mi is=&quot;true&quot;>h</mi><mi is=&quot;true&quot;>t</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>d</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>W</mi><mi is=&quot;true&quot;>o</mi><mi is=&quot;true&quot;>r</mi><mi is=&quot;true&quot;>d</mi><mi is=&quot;true&quot;>N</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>t</mi><mn is=&quot;true&quot;>2</mn><mi is=&quot;true&quot;>V</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>c</mi></mrow></msubsup><mo is=&quot;true&quot;>&amp;#x2260;</mo><mi is=&quot;true&quot;>F</mi><msubsup is=&quot;true&quot;><mn is=&quot;true&quot;>1</mn><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>g</mi><mi is=&quot;true&quot;>h</mi><mi is=&quot;true&quot;>t</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>d</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>B</mi><mi is=&quot;true&quot;>a</mi><mi is=&quot;true&quot;>s</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>l</mi><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>n</mi><mi is=&quot;true&quot;>e</mi></mrow></msubsup></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="13.639ex" height="7.726ex" viewBox="0 -1019.1 5872.3 3326.4" role="img" focusable="false" style="vertical-align: -5.359ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMATHI-46"></use></g><g is="true" transform="translate(749,0)"><g is="true"><use xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(500,393)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-57"></use></g><g is="true" transform="translate(741,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6F"></use></g><g is="true" transform="translate(1084,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-72"></use></g><g is="true" transform="translate(1403,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-64"></use></g><g is="true" transform="translate(1774,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-4E"></use></g><g is="true" transform="translate(2402,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(2732,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-74"></use></g><g is="true" transform="translate(2987,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-32"></use></g><g is="true" transform="translate(3341,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-56"></use></g><g is="true" transform="translate(3885,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(4215,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-63"></use></g></g><g is="true" transform="translate(500,-294)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(506,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(836,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(1080,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-67"></use></g><g is="true" transform="translate(1420,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-68"></use></g><g is="true" transform="translate(1828,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-74"></use></g><g is="true" transform="translate(2083,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(2413,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-64"></use></g></g></g><g transform="translate(0,-1757)"><g is="true"><use xlink:href="#MJMAIN-2260"></use></g><g is="true" transform="translate(1056,0)"><use xlink:href="#MJMATHI-46"></use></g><g is="true" transform="translate(1805,0)"><g is="true"><use xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(500,393)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-42"></use></g><g is="true" transform="translate(537,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-61"></use></g><g is="true" transform="translate(911,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-73"></use></g><g is="true" transform="translate(1243,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(1573,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6C"></use></g><g is="true" transform="translate(1784,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(2028,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6E"></use></g><g is="true" transform="translate(2453,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g></g><g is="true" transform="translate(500,-287)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(506,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(836,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(1080,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-67"></use></g><g is="true" transform="translate(1420,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-68"></use></g><g is="true" transform="translate(1828,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-74"></use></g><g is="true" transform="translate(2083,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(2413,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-64"></use></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">F</mi><msubsup is="true"><mn is="true">1</mn><mrow is="true"><mi is="true">w</mi><mi is="true">e</mi><mi is="true">i</mi><mi is="true">g</mi><mi is="true">h</mi><mi is="true">t</mi><mi is="true">e</mi><mi is="true">d</mi></mrow><mrow is="true"><mi is="true">W</mi><mi is="true">o</mi><mi is="true">r</mi><mi is="true">d</mi><mi is="true">N</mi><mi is="true">e</mi><mi is="true">t</mi><mn is="true">2</mn><mi is="true">V</mi><mi is="true">e</mi><mi is="true">c</mi></mrow></msubsup><mo is="true">≠</mo><mi is="true">F</mi><msubsup is="true"><mn is="true">1</mn><mrow is="true"><mi is="true">w</mi><mi is="true">e</mi><mi is="true">i</mi><mi is="true">g</mi><mi is="true">h</mi><mi is="true">t</mi><mi is="true">e</mi><mi is="true">d</mi></mrow><mrow is="true"><mi is="true">B</mi><mi is="true">a</mi><mi is="true">s</mi><mi is="true">e</mi><mi is="true">l</mi><mi is="true">i</mi><mi is="true">n</mi><mi is="true">e</mi></mrow></msubsup></mrow></math></span></span><script type="math/mml" id="MathJax-Element-22"><math><mrow is="true"><mi is="true">F</mi><msubsup is="true"><mn is="true">1</mn><mrow is="true"><mi is="true">w</mi><mi is="true">e</mi><mi is="true">i</mi><mi is="true">g</mi><mi is="true">h</mi><mi is="true">t</mi><mi is="true">e</mi><mi is="true">d</mi></mrow><mrow is="true"><mi is="true">W</mi><mi is="true">o</mi><mi is="true">r</mi><mi is="true">d</mi><mi is="true">N</mi><mi is="true">e</mi><mi is="true">t</mi><mn is="true">2</mn><mi is="true">V</mi><mi is="true">e</mi><mi is="true">c</mi></mrow></msubsup><mo is="true">≠</mo><mi is="true">F</mi><msubsup is="true"><mn is="true">1</mn><mrow is="true"><mi is="true">w</mi><mi is="true">e</mi><mi is="true">i</mi><mi is="true">g</mi><mi is="true">h</mi><mi is="true">t</mi><mi is="true">e</mi><mi is="true">d</mi></mrow><mrow is="true"><mi is="true">B</mi><mi is="true">a</mi><mi is="true">s</mi><mi is="true">e</mi><mi is="true">l</mi><mi is="true">i</mi><mi is="true">n</mi><mi is="true">e</mi></mrow></msubsup></mrow></math></script></span></td><td class="align-left valign-top">0.2969</td></tr></tbody></table></div></div><div class="tables rowsep-0 colsep-0 frame-topbot" id="tbl0005"><span class="captions"><span id="cap0015"><p id="spara0018"><span class="label">Table 5</span>. Wilcoxon rank-sum test results for transfer learning.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="row" class="align-left valign-top">Method 1</th><th scope="row" class="align-left valign-top">Method 2</th><th scope="row" class="align-left valign-top"><em>H<sub>a</sub></em></th><th scope="row" class="align-left valign-top"><em>p</em>-value</th></tr></thead><tbody><tr><td class="align-left valign-top">Doc2Vec</td><td class="align-left valign-top">WordNet2Vec</td><td class="align-left valign-top"><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-23-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>F</mi><msubsup is=&quot;true&quot;><mn is=&quot;true&quot;>1</mn><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>g</mi><mi is=&quot;true&quot;>h</mi><mi is=&quot;true&quot;>t</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>d</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>W</mi><mi is=&quot;true&quot;>o</mi><mi is=&quot;true&quot;>r</mi><mi is=&quot;true&quot;>d</mi><mi is=&quot;true&quot;>N</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>t</mi><mn is=&quot;true&quot;>2</mn><mi is=&quot;true&quot;>V</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>c</mi></mrow></msubsup><mo is=&quot;true&quot;>&amp;gt;</mo><mi is=&quot;true&quot;>F</mi><msubsup is=&quot;true&quot;><mn is=&quot;true&quot;>1</mn><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>g</mi><mi is=&quot;true&quot;>h</mi><mi is=&quot;true&quot;>t</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>d</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>D</mi><mi is=&quot;true&quot;>o</mi><mi is=&quot;true&quot;>c</mi><mn is=&quot;true&quot;>2</mn><mi is=&quot;true&quot;>V</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>c</mi></mrow></msubsup></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="13.639ex" height="7.726ex" viewBox="0 -1019.1 5872.3 3326.4" role="img" focusable="false" style="vertical-align: -5.359ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMATHI-46"></use></g><g is="true" transform="translate(749,0)"><g is="true"><use xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(500,393)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-57"></use></g><g is="true" transform="translate(741,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6F"></use></g><g is="true" transform="translate(1084,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-72"></use></g><g is="true" transform="translate(1403,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-64"></use></g><g is="true" transform="translate(1774,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-4E"></use></g><g is="true" transform="translate(2402,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(2732,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-74"></use></g><g is="true" transform="translate(2987,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-32"></use></g><g is="true" transform="translate(3341,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-56"></use></g><g is="true" transform="translate(3885,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(4215,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-63"></use></g></g><g is="true" transform="translate(500,-294)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(506,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(836,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(1080,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-67"></use></g><g is="true" transform="translate(1420,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-68"></use></g><g is="true" transform="translate(1828,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-74"></use></g><g is="true" transform="translate(2083,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(2413,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-64"></use></g></g></g><g transform="translate(0,-1748)"><g is="true"><use xlink:href="#MJMAIN-3E"></use></g><g is="true" transform="translate(1056,0)"><use xlink:href="#MJMATHI-46"></use></g><g is="true" transform="translate(1805,0)"><g is="true"><use xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(500,393)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-44"></use></g><g is="true" transform="translate(585,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6F"></use></g><g is="true" transform="translate(929,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-63"></use></g><g is="true" transform="translate(1235,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-32"></use></g><g is="true" transform="translate(1589,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-56"></use></g><g is="true" transform="translate(2133,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(2463,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-63"></use></g></g><g is="true" transform="translate(500,-294)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(506,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(836,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(1080,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-67"></use></g><g is="true" transform="translate(1420,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-68"></use></g><g is="true" transform="translate(1828,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-74"></use></g><g is="true" transform="translate(2083,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(2413,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-64"></use></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">F</mi><msubsup is="true"><mn is="true">1</mn><mrow is="true"><mi is="true">w</mi><mi is="true">e</mi><mi is="true">i</mi><mi is="true">g</mi><mi is="true">h</mi><mi is="true">t</mi><mi is="true">e</mi><mi is="true">d</mi></mrow><mrow is="true"><mi is="true">W</mi><mi is="true">o</mi><mi is="true">r</mi><mi is="true">d</mi><mi is="true">N</mi><mi is="true">e</mi><mi is="true">t</mi><mn is="true">2</mn><mi is="true">V</mi><mi is="true">e</mi><mi is="true">c</mi></mrow></msubsup><mo is="true">&gt;</mo><mi is="true">F</mi><msubsup is="true"><mn is="true">1</mn><mrow is="true"><mi is="true">w</mi><mi is="true">e</mi><mi is="true">i</mi><mi is="true">g</mi><mi is="true">h</mi><mi is="true">t</mi><mi is="true">e</mi><mi is="true">d</mi></mrow><mrow is="true"><mi is="true">D</mi><mi is="true">o</mi><mi is="true">c</mi><mn is="true">2</mn><mi is="true">V</mi><mi is="true">e</mi><mi is="true">c</mi></mrow></msubsup></mrow></math></span></span><script type="math/mml" id="MathJax-Element-23"><math><mrow is="true"><mi is="true">F</mi><msubsup is="true"><mn is="true">1</mn><mrow is="true"><mi is="true">w</mi><mi is="true">e</mi><mi is="true">i</mi><mi is="true">g</mi><mi is="true">h</mi><mi is="true">t</mi><mi is="true">e</mi><mi is="true">d</mi></mrow><mrow is="true"><mi is="true">W</mi><mi is="true">o</mi><mi is="true">r</mi><mi is="true">d</mi><mi is="true">N</mi><mi is="true">e</mi><mi is="true">t</mi><mn is="true">2</mn><mi is="true">V</mi><mi is="true">e</mi><mi is="true">c</mi></mrow></msubsup><mo is="true">&gt;</mo><mi is="true">F</mi><msubsup is="true"><mn is="true">1</mn><mrow is="true"><mi is="true">w</mi><mi is="true">e</mi><mi is="true">i</mi><mi is="true">g</mi><mi is="true">h</mi><mi is="true">t</mi><mi is="true">e</mi><mi is="true">d</mi></mrow><mrow is="true"><mi is="true">D</mi><mi is="true">o</mi><mi is="true">c</mi><mn is="true">2</mn><mi is="true">V</mi><mi is="true">e</mi><mi is="true">c</mi></mrow></msubsup></mrow></math></script></span></td><td class="align-left valign-top"><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-24-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mn is=&quot;true&quot;>6.821</mn><mo is=&quot;true&quot;>*</mo><msup is=&quot;true&quot;><mn is=&quot;true&quot;>10</mn><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>&amp;#x2212;</mo><mn is=&quot;true&quot;>13</mn></mrow></msup></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="12.971ex" height="2.529ex" viewBox="0 -951.3 5584.7 1088.9" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMAIN-36"></use><use xlink:href="#MJMAIN-2E" x="500" y="0"></use><use xlink:href="#MJMAIN-38" x="779" y="0"></use><use xlink:href="#MJMAIN-32" x="1279" y="0"></use><use xlink:href="#MJMAIN-31" x="1780" y="0"></use></g><g is="true" transform="translate(2502,0)"><use xlink:href="#MJMAIN-2A"></use></g><g is="true" transform="translate(3225,0)"><g is="true"><use xlink:href="#MJMAIN-31"></use><use xlink:href="#MJMAIN-30" x="500" y="0"></use></g><g is="true" transform="translate(1001,393)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(550,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use><use transform="scale(0.707)" xlink:href="#MJMAIN-33" x="500" y="0"></use></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mn is="true">6.821</mn><mo is="true">*</mo><msup is="true"><mn is="true">10</mn><mrow is="true"><mo is="true">−</mo><mn is="true">13</mn></mrow></msup></mrow></math></span></span><script type="math/mml" id="MathJax-Element-24"><math><mrow is="true"><mn is="true">6.821</mn><mo is="true">*</mo><msup is="true"><mn is="true">10</mn><mrow is="true"><mo is="true">−</mo><mn is="true">13</mn></mrow></msup></mrow></math></script></span></td></tr></tbody></table></div></div></div></section></section><section id="sec0019"><h2 id="sectt0021" class="u-h3 u-margin-l-top u-margin-xs-bottom">7. Results</h2><section id="sec0020"><h3 id="sectt0022" class="u-h4 u-margin-m-top u-margin-xs-bottom">7.1. Classification in one domain</h3><div><p id="para0069">For every domain out of the seven, Doc2Vec is slightly better than the proposed approach, if learning is performed in the same domain (<a name="bfig0005" href="#fig0005" class="workspace-trigger">Fig.&nbsp;5</a>). The difference between the results achieved by Doc2Vec and WordNet2Vec is not as large as that which can be observed in <a name="bfig0006" href="#fig0006" class="workspace-trigger">Fig.&nbsp;6</a>. Nevertheless, it is statistically significant, as was shown by the Wilcoxon rank-sum test (<a name="btbl0004" href="#tbl0004" class="workspace-trigger">Table&nbsp;4</a>). It is important to note that a statistical analysis of results also showed that WordNet2Vec is not worse than baseline.</p><figure class="figure text-xs" id="fig0005"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr5.jpg" height="731" alt="Fig. 5" aria-describedby="cap0005"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr5_lrg.jpg" target="_blank" download="" title="Download high-res image (778KB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (778KB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr5.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0005"><p id="spara0008"><span class="label">Fig. 5</span>. In domain <a href="/topics/computer-science/classification" title="Learn more about classification from ScienceDirect's AI-generated Topic Pages" class="topic-link">classification</a> results.</p></span></span></figure><figure class="figure text-xs" id="fig0006"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr6.jpg" height="300" alt="Fig. 6" aria-describedby="cap0006"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr6_lrg.jpg" target="_blank" download="" title="Download high-res image (132KB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (132KB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr6.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0006"><p id="spara0009"><span class="label">Fig. 6</span>. Histogram of differences between <em>F</em>1<sub><em>weighted</em></sub> measure between WordNet2Vec and Doc2Vec within whole domains. Negative values denote worse results.</p></span></span></figure></div></section><section id="sec0021"><h3 id="sectt0023" class="u-h4 u-margin-m-top u-margin-xs-bottom">7.2. Transfer learning: generalization ability</h3><div><p id="para0070">A transfer learning approach consists of learning on data from one domain, e.g. <em>Automotive</em> and the application of the trained model (testing) on data from another domain, e.g. <em>Books</em>. The results achieved in a transfer learning setting show the true power and abilities of the WordNet2Vec method. We observe that our method achieves better results than Doc2Vec (<a name="bfig0007" href="#fig0007" class="workspace-trigger">Fig.&nbsp;7</a> and <a name="bfig0008" href="#fig0008" class="workspace-trigger">8</a>). The variance of the weighted F1 results in a transfer learning setting for both methods showed that WordNet2Vec is more stable than Doc2Vec (<a name="bfig0009" href="#fig0009" class="workspace-trigger">Fig.&nbsp;9</a>). It is important to notice that differences in results are much greater for the WordNet2Vec method than for the Doc2Vec classification (<a name="bfig0010" href="#fig0010" class="workspace-trigger">Fig.&nbsp;10</a>). In addition, we used statistical tests in order to check the statistical significance of the differences in results (<a name="btbl0005" href="#tbl0005" class="workspace-trigger">Table&nbsp;5</a>). The superiority of WordNet2Vec over Doc2Vec is statistically significant.</p><figure class="figure text-xs" id="fig0007"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr7.jpg" height="414" alt="Fig. 7" aria-describedby="cap0007"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr7_lrg.jpg" target="_blank" download="" title="Download high-res image (239KB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (239KB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr7.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0007"><p id="spara0010"><span class="label">Fig. 7</span>. Transfer learning using Doc2Vec: <em>F</em>1<sub><em>weighted</em></sub> expressed in %.</p></span></span></figure><figure class="figure text-xs" id="fig0008"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr8.jpg" height="414" alt="Fig. 8" aria-describedby="cap0008"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr8_lrg.jpg" target="_blank" download="" title="Download high-res image (247KB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (247KB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr8.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0008"><p id="spara0011"><span class="label">Fig. 8</span>. Transfer learning using WordNet2Vec: <em>F</em>1<sub><em>weighted</em></sub> expressed in %.</p></span></span></figure><figure class="figure text-xs" id="fig0009"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr9.jpg" height="356" alt="Fig. 9" aria-describedby="cap0009"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr9_lrg.jpg" target="_blank" download="" title="Download high-res image (169KB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (169KB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr9.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0009"><p id="spara0012"><span class="label">Fig. 9</span>. Histogram of <em>F</em>1<sub><em>weighted</em></sub> in&nbsp;transfer learning – between domains.</p></span></span></figure><figure class="figure text-xs" id="fig0010"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr10.jpg" height="300" alt="Fig. 10" aria-describedby="cap0010"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr10_lrg.jpg" target="_blank" download="" title="Download high-res image (124KB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (124KB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231217315217-gr10.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0010"><p id="spara0013"><span class="label">Fig. 10</span>. Histogram of differences in <em>F</em>1<sub><em>weighted</em></sub><span> <a href="/topics/computer-science/classification" title="Learn more about classification from ScienceDirect's AI-generated Topic Pages" class="topic-link">classification</a> measure between WordNet2Vec and Doc2Vec in&nbsp;transfer learning scenario. Positive values denote better results.</span></p></span></span></figure></div></section><section id="sec0022"><h3 id="sectt0024" class="u-h4 u-margin-m-top u-margin-xs-bottom">7.3. Time complexity</h3><p id="para0071">The time of calculation should be analyzed separately for both computation phases: data <a href="/topics/computer-science/vectorization" title="Learn more about vectorization from ScienceDirect's AI-generated Topic Pages" class="topic-link">vectorization</a><span> and classification. In both phases, time varies because of different dataset sizes. The longest vectorization lasted 1&nbsp;h 45&nbsp;min, while the shortest was about 9&nbsp;min. The classification times were longer: from 1&nbsp;h 43&nbsp;min to 6&nbsp;h 16&nbsp;min. It is important to note that classification times last longer because of the large dimension of word vectors. In our further experiments we will study various methods for dimensionality reduction such as deep <a href="/topics/computer-science/autoencoders" title="Learn more about autoencoders from ScienceDirect's AI-generated Topic Pages" class="topic-link">autoencoders</a>.</span></p></section></section><section id="sec0023"><h2 id="sectt0025" class="u-h3 u-margin-l-top u-margin-xs-bottom">8. Discussion</h2><p id="para0072">Since a large wordnet reflects the structure of the lexico-semantic system of a given language it is rarely updated. The vectors once created using the WordNet2Vec method can be treated as a stable and convenient representation of this system and <a href="/topics/computer-science/lexical-meaning" title="Learn more about lexical meanings from ScienceDirect's AI-generated Topic Pages" class="topic-link">lexical meanings</a><span>. However, if we would like to operate in a more specific domain such as texts related to biomaterials or those from evolving social media, a wordnet-based knowledge resource should be replaced by another dynamic <a href="/topics/computer-science/semantic-network" title="Learn more about semantic network from ScienceDirect's AI-generated Topic Pages" class="topic-link">semantic network</a>. In such cases, it may be necessary to work out some other incremental and efficient WordNet2Vec methods.</span></p><p id="para0073">In general, the WordNet2Vec validation could be performed with respect to different dimensions: (1) quality for different wordnets (different languages), (2) word vector calculation using various structural measure (we analyzed the lengths of shortest paths), (3) efficiency – algorithms for vector calculations, (4) a method for vector application, in particular vector aggregation for sentences, paragraphs, documents or collections, (5) aggregation utilization dependent on application area (for example sentiment analysis).</p></section><section id="sec0024"><h2 id="sectt0026" class="u-h3 u-margin-l-top u-margin-xs-bottom">9. Conclusions and future work</h2><p id="para0074">A novel method, namely WordNet2Vec, for word <a href="/topics/computer-science/vectorization" title="Learn more about vectorization from ScienceDirect's AI-generated Topic Pages" class="topic-link">vectorization</a> that enables us to build a more general knowledge representation of texts on the basis of a large wordnet was presented in the paper. It provides a word representation in the vector space by exploiting distance to any other word in the wordnet network. In order to present the pair-wise word distance, the method calculates all-pairs shortest paths in the wordnet.</p><p id="para0075">The usefulness of the WordNet2Vec method was demonstrated in the <a href="/topics/computer-science/sentiment-analysis" title="Learn more about sentiment analysis from ScienceDirect's AI-generated Topic Pages" class="topic-link">sentiment analysis</a><span><span> problem, that is to say <a href="/topics/computer-science/classification" title="Learn more about classification from ScienceDirect's AI-generated Topic Pages" class="topic-link">classification</a> in a transfer learning setting using an Amazon reviews dataset. We compared the WordNet2Vec-based classification of sentiment to the Doc2Vec approach. Doc2Vec proved to be more accurate in a homogeneous setting (learning and testing within the same domain). However, in cases of cross domain application (transfer learning), our method outperformed the Doc2Vec results. Hence, we presented its </span><a href="/topics/computer-science/generalization-ability" title="Learn more about generalization ability from ScienceDirect's AI-generated Topic Pages" class="topic-link">generalization ability</a><span> in <a href="/topics/computer-science/text-classification" title="Learn more about text classification from ScienceDirect's AI-generated Topic Pages" class="topic-link">text classification</a> problems.</span></span></p><p id="para0076">There are several potential applications for the WordNet2Vec method such as opinion mining, emotional and controversy analysis, recommendation systems based on textual content, social media analysis, text summarization, document comparison, antiplagiarism systems, and <a href="/topics/computer-science/market-basket-analysis" title="Learn more about market basket analysis from ScienceDirect's AI-generated Topic Pages" class="topic-link">market basket analysis</a> based on product names and descriptions.</p><p id="para0077">In future work, we would like to investigate different methods of combining word vectors into documents (including various forms of vector normalization), treat WordNet as a multiplex network while calculating shortest paths, reduce the feature space of WordNet2Vec Matrix and validate our method on different sources of data such as Twitter or Facebook. In addition, we are working on methods for shortening the time of All-pairs Shortest Paths computation using various heuristics which will enable us to evaluate WordNet2Vec on larger networks such as BabelNet <a name="bbib0044" href="#bib0044" class="workspace-trigger">[44]</a>.<a name="bfn0004" href="#fn0004" class="workspace-trigger"><sup>4</sup></a></p></section></div><section id="ack0001"><h2 id="sectt0027" class="u-h3 u-margin-l-top u-margin-xs-bottom">Acknowledgments</h2><p id="para0078">The work was partly supported by The National Science Centre, decision no. DEC-2013/09/B/ST6/02317, the <span id="GS501100000780">European Commission</span> under the 7th Framework Programme, Coordination and Support Action, Grant Agreement Number <a href="#GS501100000780">316097</a>, Engine project, the Faculty of Computer Science and Management, Wrocław University of Science and Technology statutory funds, the European Union’s Horizon 2020 research and innovation programme under the Marie Skłodowska-Curie grant agreement No 691152, RENOIR project and the Polish Ministry of Science and Higher Education fund for supporting internationally co-financed projects in 2016–2019 (agreement no. 3628/H2020/2016/2). The calculations were carried out in the Wrocław Centre for Networking and Supercomputing, grant No 177.</p></section></div>