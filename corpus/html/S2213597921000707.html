<div class="Body u-font-serif" id="body"><div><section id="sec0005"><h2 id="sect0020" class="u-h3 u-margin-l-top u-margin-xs-bottom">1. Introduction</h2><p id="p0010"><span><a href="/topics/medicine-and-dentistry/photoacoustic-microscopy" title="Learn more about Photoacoustic microscopy from ScienceDirect's AI-generated Topic Pages" class="topic-link">Photoacoustic microscopy</a><span><span> (PAM) is described as a kind of hybrid biomedical <a href="/topics/computer-science/imaging-modality" title="Learn more about imaging modality from ScienceDirect's AI-generated Topic Pages" class="topic-link">imaging modality</a> based on combining </span><a href="/topics/physics-and-astronomy/ultrasonics" title="Learn more about ultrasonic from ScienceDirect's AI-generated Topic Pages" class="topic-link">ultrasonic</a> emission and optical excitation </span></span><a name="bbib1" href="#bib1" class="workspace-trigger">[1]</a>, <a name="bbib2" href="#bib2" class="workspace-trigger">[2]</a><span>. In PAM, a short-pulse laser is absorbed by biological tissues, inducing photothermal effect which includes thermal-elastic expansion that generates an ultrasonic pressure. The rising pressure emits the photoacoustic (PA) waves, which are acquired by an ultrasonic <a href="/topics/physics-and-astronomy/transducers" title="Learn more about transducer from ScienceDirect's AI-generated Topic Pages" class="topic-link">transducer</a> to transform PA images deposition inside the tissue for preclinical and clinical research. PAM provides a three-dimensional (3D) high-resolution images in combination with point-by-point scanning, which utilizes either focused optical beam excitation or focused acoustic beam detection </span><a name="bbib3" href="#bib3" class="workspace-trigger">[3]</a><span>. The present trends are usually research on improving PAM imaging speed while maintaining a highly sensitive detection and high spatial resolution, such as <a href="/topics/physics-and-astronomy/microelectromechanical-systems" title="Learn more about microelectromechanical system from ScienceDirect's AI-generated Topic Pages" class="topic-link">microelectromechanical system</a><span> (MEMS), <a href="/topics/medicine-and-dentistry/galvanometer" title="Learn more about galvanometer from ScienceDirect's AI-generated Topic Pages" class="topic-link">galvanometer</a> scanner, polygon scanners, and voice-coil and slider-crank scanning system </span></span><a name="bbib3" href="#bib3" class="workspace-trigger">[3]</a>, <a name="bbib4" href="#bib4" class="workspace-trigger">[4]</a>, <a name="bbib5" href="#bib5" class="workspace-trigger">[5]</a>, <a name="bbib6" href="#bib6" class="workspace-trigger">[6]</a>, <a name="bbib7" href="#bib7" class="workspace-trigger">[7]</a>, <a name="bbib8" href="#bib8" class="workspace-trigger">[8]</a>, <a name="bbib9" href="#bib9" class="workspace-trigger">[9]</a>. Due to the fast imaging with high-quality standards, fast computational technique based on deep learning is essentially important.</p><p id="p0015"><span>PAM has been found to be safe to humans; it has been widely used to image the structure of <a href="/topics/medicine-and-dentistry/microvessel" title="Learn more about microvasculature from ScienceDirect's AI-generated Topic Pages" class="topic-link">microvasculature</a> </span><a name="bbib9" href="#bib9" class="workspace-trigger">[9]</a>, <a name="bbib10" href="#bib10" class="workspace-trigger">[10]</a>, <a name="bbib11" href="#bib11" class="workspace-trigger">[11]</a><span><span>. Furthermore, PAM has great advantages for imaging the functional properties (such as <a href="/topics/medicine-and-dentistry/oxygen-saturation" title="Learn more about oxygen saturation from ScienceDirect's AI-generated Topic Pages" class="topic-link">oxygen saturation</a><span>, <a href="/topics/medicine-and-dentistry/hemoglobin-determination" title="Learn more about hemoglobin concentration from ScienceDirect's AI-generated Topic Pages" class="topic-link">hemoglobin concentration</a>, and blood flow), which are crucial for the diagnosis, staging, and study of vascular diseases like diabetes, stroke, cancer, and neural </span></span><a href="/topics/computer-science/degenerative-disease" title="Learn more about degenerative diseases from ScienceDirect's AI-generated Topic Pages" class="topic-link">degenerative diseases</a> </span><a name="bbib12" href="#bib12" class="workspace-trigger">[12]</a><span>. However, in human imaging, the generated PA signals on skin (highly absorption of melanin) dominate the inside PA signals leading to unrevealed the internal structure tissue directly. Therefore, blood <a href="/topics/computer-science/vessel-segmentation" title="Learn more about vessels segmentation from ScienceDirect's AI-generated Topic Pages" class="topic-link">vessels segmentation</a> and reconstruction in PAM is a vital step in imaging functions and structures of subcutaneous microvasculature. Many efforts have focused on blood vessels segmentation in PAM images, which is a basic method performed by clinical experts who have experience on anatomical tissues. With every B-scan image, skin profile and vessels profile were selected manually </span><a name="bbib13" href="#bib13" class="workspace-trigger">[13]</a>. Therefore, this method is not suitable with high-resolution imaging, due to the large number of B-scan images which might exceed over a thousand; most clinical experts identify the manual operation as a time-consuming process to perform. Khodaverdi et al. <a name="bbib14" href="#bib14" class="workspace-trigger">[14]</a> demonstrated segmentation by approaching adaptive threshold based on statistical characteristics of the background, but the result led to over-segmentation due to the low morphological sensitivity of PA blood vessels signal. In another method, Baik et al. <a name="bbib15" href="#bib15" class="workspace-trigger">[15]</a> used multilayered based on image depth threshold, by using a local maximum amplitude projection (MAP), instead of the global maximum value, which is commonly used in ultrasonic testing system (also call gate selection) <a name="bbib16" href="#bib16" class="workspace-trigger">[16]</a>. However, the choice of depth location and threshold is fixed for all the images; signal might be out of range depending on the gate length due to motion artifacts and different tissue types, which could affect the accuracy of the imaging. An early automatically detectable skin profile in volumetric PAM data was developed to find the skin contour on the B-scan images <a name="bbib17" href="#bib17" class="workspace-trigger">[17]</a>, but this technique requires two-round scanning, making it inappropriate for preclinical or clinical application.</p><p id="p0020"><span><span>Deep learning (DL) approaches, e.g., <a href="/topics/computer-science/convolutional-neural-networks" title="Learn more about convolutional neural networks from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolutional neural networks</a> (CNN), have recently exhibited state-of-the-art performance on </span><a href="/topics/medicine-and-dentistry/photoacoustic-imaging" title="Learn more about PA imaging from ScienceDirect's AI-generated Topic Pages" class="topic-link">PA imaging</a> applications. Several review articles as regard to DL applications for PAM imaging have been discussed by Yang et al. and Deng et al., wherein different relevant research articles were explained </span><a name="bbib18" href="#bib18" class="workspace-trigger">[18]</a>, <a name="bbib19" href="#bib19" class="workspace-trigger">[19]</a>. Another important review article by Grohl et al. <a name="bbib20" href="#bib20" class="workspace-trigger">[20]</a> presented the current advancement regarding DL in PA imaging. DL has been determined to be applicable in a variety of aspects for PAM such as image reconstruction <a name="bbib21" href="#bib21" class="workspace-trigger">[21]</a>, <a name="bbib22" href="#bib22" class="workspace-trigger">[22]</a>, <a name="bbib23" href="#bib23" class="workspace-trigger">[23]</a>, <a name="bbib24" href="#bib24" class="workspace-trigger">[24]</a>, <a name="bbib25" href="#bib25" class="workspace-trigger">[25]</a><span>, <a href="/topics/computer-science/image-classification" title="Learn more about image classification from ScienceDirect's AI-generated Topic Pages" class="topic-link">image classification</a> </span><a name="bbib26" href="#bib26" class="workspace-trigger">[26]</a><span>, <a href="/topics/medicine-and-dentistry/quantitative-imaging" title="Learn more about quantitative imaging from ScienceDirect's AI-generated Topic Pages" class="topic-link">quantitative imaging</a> </span><a name="bbib27" href="#bib27" class="workspace-trigger">[27]</a>, image detection, <a name="bbib28" href="#bib28" class="workspace-trigger">[28]</a><span> and, especially, <a href="/topics/computer-science/image-segmentation" title="Learn more about image segmentation from ScienceDirect's AI-generated Topic Pages" class="topic-link">image segmentation</a> </span><a name="bbib26" href="#bib26" class="workspace-trigger">[26]</a>, <a name="bbib29" href="#bib29" class="workspace-trigger">[29]</a>, <a name="bbib30" href="#bib30" class="workspace-trigger">[30]</a>, <a name="bbib31" href="#bib31" class="workspace-trigger">[31]</a>, <a name="bbib32" href="#bib32" class="workspace-trigger">[32]</a>, <a name="bbib33" href="#bib33" class="workspace-trigger">[33]</a>. However, those studies almost have been reported about segmentation of the C-scan image (MAP image domain) <a name="bbib26" href="#bib26" class="workspace-trigger">[26]</a>, <a name="bbib29" href="#bib29" class="workspace-trigger">[29]</a>, <a name="bbib31" href="#bib31" class="workspace-trigger">[31]</a>, <a name="bbib32" href="#bib32" class="workspace-trigger">[32]</a>, <a name="bbib33" href="#bib33" class="workspace-trigger">[33]</a>, not widely applied to 3D PA images for separating skin and blood vessels areas. Unlike other works, Chlis et al. <a name="bbib30" href="#bib30" class="workspace-trigger">[30]</a><span> used a <a href="/topics/computer-science/deep-learning-method" title="Learn more about DL method from ScienceDirect's AI-generated Topic Pages" class="topic-link">DL method</a><span> for processing the cross-sectional B-scan image to avoid the rigorous and time-consuming <a href="/topics/computer-science/manual-segmentation" title="Learn more about manual segmentation from ScienceDirect's AI-generated Topic Pages" class="topic-link">manual segmentation</a>. However, the requirement input image for this algorithm is fixed, that is, 400&nbsp;×&nbsp;400 pixels; it may likely be difficult to fully view small vessel features in the axial and lateral resolution. Thus, an automatic algorithm for segmentation in high-resolution PA images using DL is deemed necessary.</span></span></p><p id="p0025"><span><span>In this research work, we propose a DL method for the segmentation of skin and blood vessels profile PAM images in 3D <a href="/topics/computer-science/volumetric-data" title="Learn more about volumetric data from ScienceDirect's AI-generated Topic Pages" class="topic-link">volumetric data</a>, leveraging the pre-trained 2D model on B-scan dataset. By performing full-form CNN semantic </span><a href="/topics/computer-science/segmentation-approach" title="Learn more about segmentation approaches from ScienceDirect's AI-generated Topic Pages" class="topic-link">segmentation approaches</a> (U-Net) </span><a name="bbib34" href="#bib34" class="workspace-trigger">[34]</a>, the technique proposes an automatic skin and vessels segmentation ability for in vivo PA imaging of humans. The key approaches of our research are 3D volumetric segmentation and full-image reconstruction, as it offers a solution in keeping the standards quality high with excellent imaging. However, we could not compare the explicit and quantity metrics because it was not specified in the references <a name="bbib17" href="#bib17" class="workspace-trigger">[17]</a>, <a name="bbib30" href="#bib30" class="workspace-trigger">[30]</a><span>. The results are often evaluated in terms of accuracy, Intersection over Union (IoU), sensitivity, and boundary F1 (BF) score and are compared with other popular semantic <a href="/topics/computer-science/segmentation-model" title="Learn more about segmentation models from ScienceDirect's AI-generated Topic Pages" class="topic-link">segmentation models</a> such as SegNet </span><a name="bbib35" href="#bib35" class="workspace-trigger">[35]</a><span>, and fully <a href="/topics/computer-science/convolutional-network" title="Learn more about convolutional networks from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolutional networks</a> (FCN) </span><a name="bbib36" href="#bib36" class="workspace-trigger">[36]</a>. Skin and vessels profiles on each B-scan image were detected automatically in approximately 30&nbsp;ms, which can be achieved in real-time estimation on high-resolution image data (1000&nbsp;×&nbsp;1200 pixels), and motion artifacts problem in in vivo experiments <a name="bbib17" href="#bib17" class="workspace-trigger">[17]</a><span><span> could be resolved. Moreover, the <a href="/topics/computer-science/deep-learning-model" title="Learn more about DL model from ScienceDirect's AI-generated Topic Pages" class="topic-link">DL model</a> was trained on a large number of B-scan images for in vivo testing results of humans as the ground truth; thus, it was validated in preclinical and </span><a href="/topics/medicine-and-dentistry/biomedical-research" title="Learn more about biomedical research from ScienceDirect's AI-generated Topic Pages" class="topic-link">biomedical research</a>.</span></p></section><section id="sec0010"><h2 id="sect0025" class="u-h3 u-margin-l-top u-margin-xs-bottom">2. Methods</h2><section id="sec0015"><h3 id="sect0030" class="u-h4 u-margin-m-top u-margin-xs-bottom">2.1. Data preparation</h3><div><p id="p0030"><span>In this study, all of the data were acquired using a dual-fast scanning <a href="/topics/medicine-and-dentistry/photoacoustic-microscopy" title="Learn more about photoacoustic microscopy from ScienceDirect's AI-generated Topic Pages" class="topic-link">photoacoustic microscopy</a> system (Ohlabs, Busan, 48513, Republic of Korea) </span><a name="bbib9" href="#bib9" class="workspace-trigger">[9]</a><span><span>. The three-dimension imaging is acquired by <a href="/topics/physics-and-astronomy/raster-scanning" title="Learn more about raster scanning from ScienceDirect's AI-generated Topic Pages" class="topic-link">raster scanning</a> of the PA probe over the </span><a href="/topics/physics-and-astronomy/field-of-view" title="Learn more about field of view from ScienceDirect's AI-generated Topic Pages" class="topic-link">field of view</a> (FOV) with a step size along both X-axis and Y-axis (</span><a name="bfig0005" href="#fig0005" class="workspace-trigger">Fig. 1</a><span>(B)). All procedures were performed on a human volunteer following the regulations and guidelines approved by Institutional Review Board of Pukyong National University. The system used 532&nbsp;nm laser for achieving high <a href="/topics/physics-and-astronomy/absorptivity" title="Learn more about absorption coefficients from ScienceDirect's AI-generated Topic Pages" class="topic-link">absorption coefficients</a> of oxygenated blood with low illumination energy which is under the American National Standards Institute standards safety limit (20&nbsp;mJ/cm</span><sup>2</sup> for 532&nbsp;nm wavelength) <a name="bbib37" href="#bib37" class="workspace-trigger">[37]</a><span>. The acoustic signal was performed by Olympus flat <a href="/topics/physics-and-astronomy/transducers" title="Learn more about transducer from ScienceDirect's AI-generated Topic Pages" class="topic-link">transducer</a><span> with the central frequency of 50&nbsp;MHz. Ultrasound signal was acquired for each illumination pulse under a sampling rate of 200&nbsp;MHz by National Instruments digitizer and was directly fed in to a <a href="/topics/computer-science/time-series-data" title="Learn more about time series data from ScienceDirect's AI-generated Topic Pages" class="topic-link">time series data</a> (A-scan) line. The motion control, laser pulsing and data acquisition are synchronized using LabVIEW software. </span></span><a name="bfig0005" href="#fig0005" class="workspace-trigger">Fig. 1</a>(A) showed the experimental scheme, images have been obtained from the foot of a volunteer.</p><figure class="figure text-xs" id="fig0005"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr1.jpg" height="357" alt="Fig. 1" aria-describedby="cap0005"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr1_lrg.jpg" target="_blank" download="" title="Download high-res image (458KB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (458KB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr1.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0005"><p id="sp0005"><span class="label">Fig. 1</span>. Experimental setup: (A) Photograph of the experimental set up; (B) Photograph of region of interest (ROI). It represented by red dash box. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)</p></span></span></figure></div></section><section id="sec0020"><h3 id="sect0035" class="u-h4 u-margin-m-top u-margin-xs-bottom">2.2. Framework description</h3><div><p id="p0035"><a name="bfig0010" href="#fig0010" class="workspace-trigger">Fig. 2</a><span> shows the flowchart for the comprehensive segmentation, which includes preparation input images (1), extraction images (2), DL <a href="/topics/computer-science/network-segmentation" title="Learn more about segmentation network from ScienceDirect's AI-generated Topic Pages" class="topic-link">segmentation network</a><span>, (3) model comparison, post-processing in skin and blood vessels extraction (4), and (5) 3D <a href="/topics/computer-science/rendering" title="Learn more about rendering from ScienceDirect's AI-generated Topic Pages" class="topic-link">rendering</a>. First, human palm and foot were scanned using the PAM system, with rescanning done thrice: D1 and D2 for the palm imaging corresponding to the step size of 0.1 mm and 0.04 mm, and D3 for the foot imaging with the step size of 0.04 mm. All the scanned data was acquired with a 100 × 80 mm</span></span><sup>2</sup> field of view, same step size along both X-axis and Y-axis (<a name="bfig0005" href="#fig0005" class="workspace-trigger">Fig. 1</a><span>(B)), and 1200-sample record along Z-axis at a sample rate of 200 MS/s. By using <a href="/topics/computer-science/hilbert-transform" title="Learn more about Hilbert transform from ScienceDirect's AI-generated Topic Pages" class="topic-link">Hilbert transform</a><span> in each A-scan, the 2D B-scan images were reconstructed. In total, 800 B-scan images were acquired in D1, while 2000 B-scan images were acquired in D2 and D3. A normalize method was adopted to scale the pixel values to range 0–1, which is preferred for <a href="/topics/computer-science/neural-network-model" title="Learn more about neural network models from ScienceDirect's AI-generated Topic Pages" class="topic-link">neural network models</a>. For training process, 60 images were chosen randomly from D1 dataset. The original images were extended by sliding window extraction architecture with the stride of S</span></span><sub>W</sub> = 248 and S<sub>H</sub> = 236, which were calculated by sub-multiple finding function. Therefore, the final dataset contains 1200 pairs of the extraction patches (1000 patches for training and validation, 200 patches for testing). In the training process, two classes of object were considered (skin, blood vessels) and the performance of U-Net, SegNet-5 and FCN-8 approach was examined for semantic segmentation of PA images. The accuracy segmented was then compared to other models to evaluate different solutions and find the best results. The highest performance model was utilized to segment the images on D2 and D3 data. For significant standard deviation, the predicted pixel values of each class were arranged in an order from 0 to 1, and the upper 50% (from 0.5 to 1) were set to 1 and lower 50% (less than 0.5) to 0. Bitwise operations were used to extract skin and blood vessels from the images by using a mask which was created by segmentation result via the model. Predicted images were back into original size by inverse sliding window extraction. Finally, 3D geometry and structure of the scanning data were reconstructed by concatenating multiple 2D B-scan images.</p><figure class="figure text-xs" id="fig0010"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr2.jpg" height="495" alt="Fig. 2" aria-describedby="cap0010"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr2_lrg.jpg" target="_blank" download="" title="Download high-res image (674KB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (674KB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr2.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0010"><p id="sp0010"><span class="label">Fig. 2</span>. Deep learning based skin and blood vessels profile segmentation framework for in vivo photoacoustic image.</p></span></span></figure></div></section><section id="sec0025"><h3 id="sect0040" class="u-h4 u-margin-m-top u-margin-xs-bottom">2.3. CNN networks</h3><section id="sec0030"><h4 id="sect0045" class="u-margin-m-top u-margin-xs-bottom">2.3.1. U-Net architecture</h4><div><p id="p0040">Our method is a direct modification of the completely convolution architecture of U-Net <a name="bbib34" href="#bib34" class="workspace-trigger">[34]</a><span>, which is well known for its biomedical <a href="/topics/computer-science/image-segmentation" title="Learn more about image segmentation from ScienceDirect's AI-generated Topic Pages" class="topic-link">image segmentation</a> using information from the skip connections. The network consists of a pair of encoder (contraction path) and decoder (expansion path), similar to the original U-Net (</span><a name="bfig0015" href="#fig0015" class="workspace-trigger">Fig. 3</a><span>). The network takes input size image of 256 × 256 × 1 and then passes through the first convolution block which has two <a href="/topics/computer-science/convolution-layer" title="Learn more about convolution layers from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolution layers</a><span>; 64 <a href="/topics/computer-science/convolution-filter" title="Learn more about convolution filters from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolution filters</a><span>, measuring 3 × 3, were then used across the input image to extract 256 × 256 × 64 feature map data. Rectified linear unit (ReLU) <a href="/topics/computer-science/activation-function" title="Learn more about activation function from ScienceDirect's AI-generated Topic Pages" class="topic-link">activation function</a> was used in converting negative values to 0. Max-pooling process 2 × 2 for downsize of first feature map to 128 × 128 × 64. In the second convolution block, the same convolution layer with keeping the first two dimension of the previous layer and increase the third dimension from 2-times to 128. Max-pooling was used to reduce the dimension to 64 × 64 × 128. The process was repeated twice to reach the bottommost convolution block, which is still built with two convolution layers without max-pooling. Furthermore, dropout was added between two hidden layers having the two largest number of convolutional parameters </span></span></span><a name="bbib38" href="#bib38" class="workspace-trigger">[38]</a>, <a name="bbib39" href="#bib39" class="workspace-trigger">[39]</a><span>. Up-sampling path to expand the feature map size from lower resolution to a higher resolution by add some padding on the previous layer followed by a <a href="/topics/computer-science/convolution-operation" title="Learn more about convolution operation from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolution operation</a><span>. At each up-sampling path, feature map was concatenated with the corresponding feature from the encoder to combine the information from the encoder layer. The process was repeated three more times to back the layer input resolution. The output of the final decoder is fed into a <a href="/topics/medicine-and-dentistry/sigmoid" title="Learn more about sigmoid from ScienceDirect's AI-generated Topic Pages" class="topic-link">sigmoid</a><span> activation layer to give the segmentation mask representing the pixel-wise <a href="/topics/computer-science/classification" title="Learn more about classification from ScienceDirect's AI-generated Topic Pages" class="topic-link">classification</a>.</span></span></span></p><figure class="figure text-xs" id="fig0015"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr3.jpg" height="356" alt="Fig. 3" aria-describedby="cap0015"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr3_lrg.jpg" target="_blank" download="" title="Download high-res image (186KB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (186KB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr3.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0015"><p id="sp0015"><span class="label">Fig. 3</span>. U-Net architecture. The variables L1, L2, L3, L4, L5 refer to the image size (w × h) at the level of different compression depth.</p></span></span></figure></div></section><section id="sec0035"><h4 id="sect0050" class="u-margin-m-top u-margin-xs-bottom">2.3.2. SegNet-5 with Vgg16 backbone</h4><div><p id="p0045">SegNet <a name="bbib35" href="#bib35" class="workspace-trigger">[35]</a> is described as a semantic segmentation convolutional neural network that consists of an encoder-decoder architecture; it can be classified into SegNet-3 and Segnet-5, depending on the number of convolution blocks inside the model. SegNet-5 is based on Vgg16 <a name="bbib40" href="#bib40" class="workspace-trigger">[40]</a><span><span><span>, which is a popular <a href="/topics/computer-science/convolutional-neural-networks" title="Learn more about CNN from ScienceDirect's AI-generated Topic Pages" class="topic-link">CNN</a> model in </span><a href="/topics/computer-science/image-classification" title="Learn more about image classification from ScienceDirect's AI-generated Topic Pages" class="topic-link">image classification</a>. But the resulting use for segments the image instead of classifying it. In SegNet-5, the encoder path has five convolution blocks (consisting of 13 </span><a href="/topics/computer-science/convolutional-layer" title="Learn more about convolutional layers from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolutional layers</a><span> and 5 max-pooling layers), whereas the decoder path is the opposite of the encoder; however, its max-pooling layer is replaced by pooling indices to match the feature map in up-sampling process. For our modified SegNet-5, we changed the input to grayscale image instead of <a href="/topics/computer-science/rgb-image" title="Learn more about RGB image from ScienceDirect's AI-generated Topic Pages" class="topic-link">RGB image</a>. Due to the scanning result, PA image is a grayscale correspond to color images with equal values in all 3-channel. Hence, reducing the input to 1-channel also minimize model parameters </span></span><a name="bbib41" href="#bib41" class="workspace-trigger">[41]</a><span> without affecting to the <a href="/topics/computer-science/input-feature-map" title="Learn more about input feature map from ScienceDirect's AI-generated Topic Pages" class="topic-link">input feature map</a>. Moreover, unlike normal classification, medical images classification might belong to more than one class label (mutually inclusive classes) such as many diseases in the same organ </span><a name="bbib42" href="#bib42" class="workspace-trigger">[42]</a><span>. Therefore, we opted for choosing classifications, instead of multiclassification for easily improving our future research with a multi-label segmentation. In the encoders process, the model takes an input image of 256 × 256 × 1 and the passes through five convolution blocks. Each convolution block performs with a dense convolution layer, <a href="/topics/computer-science/batch-normalization" title="Learn more about batch normalization from ScienceDirect's AI-generated Topic Pages" class="topic-link">batch normalization</a>, ReLU activation and 2 × 2 max-pooling layer. Meanwhile, the decoder process is the opposite to that of encoder, wherein it helps in upsizing the feature map at the end of the encoder to the full-size predicted image. Different from the U-Net, during up-sampling process, the max pooling indices at the corresponding encoder layer are recalled to up-sample instead of concatenation to perform convolution. The SegNet-5 architecture is shown in </span><a name="bfig0020" href="#fig0020" class="workspace-trigger">Fig. 4</a>.</p><figure class="figure text-xs" id="fig0020"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr4.jpg" height="321" alt="Fig. 4" aria-describedby="cap0020"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr4_lrg.jpg" target="_blank" download="" title="Download high-res image (248KB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (248KB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr4.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0020"><p id="sp0020"><span class="label">Fig. 4</span>. Architecture of SegNet-5. Where variables L1, L2, L3, L4, L5, L6 refer to the image size (w × h) at the level of different compression depth.</p></span></span></figure></div></section><section id="sec0040"><h4 id="sect0055" class="u-margin-m-top u-margin-xs-bottom">2.3.3. FCN-8 with Vgg16 backbone</h4><div><p id="p0050">Fully convolutional network (FCN) <a name="bbib36" href="#bib36" class="workspace-trigger">[36]</a><span><span> is one of the first proposed <a href="/topics/computer-science/deep-learning-method" title="Learn more about DL method from ScienceDirect's AI-generated Topic Pages" class="topic-link">DL method</a> for semantic segmentation. Unlike other approaches where up-sampling process uses mathematical interpolations, </span><a href="/topics/computer-science/convolutional-network" title="Learn more about FCN from ScienceDirect's AI-generated Topic Pages" class="topic-link">FCN</a><span> uses transposed convolutions layer. Three types of variation are FCN-8, FCN-16 and FCN-32. FCN-32 uses the 32-stride up-sampling at the final prediction layer, whereas FCN-16 and FCN-8 combine with lower layers with more detail in the up-sampling process. In this study, we opted to use FCN-8, which has been identified to have the highest detail feature maps in the up-sampling process. Same with SegNet-5, FCN-8 is also based on Vgg16 <a href="/topics/computer-science/network-architecture" title="Learn more about network architecture from ScienceDirect's AI-generated Topic Pages" class="topic-link">network architecture</a>. There are some innovations of using FCN-8 with Vgg16 backbone </span></span><a name="bbib43" href="#bib43" class="workspace-trigger">[43]</a>: Vgg16 use only 3 × 3 convolution filter instead of variable size convolution filter in Alexnet <a name="bbib44" href="#bib44" class="workspace-trigger">[44]</a><span> (11 × 11, 5 × 5, 3 × 3), which can reduce parameters and improve the training time; moreover, Vgg16 give the deeper networks and achieve the effect of variable size kernel by implementing the stack of convolutional layers before performing 2 × 2 max pooling layer. FCN-8 takes the input image size of 256 × 256 × 1, in order to obtain the output image of the same size, and transposed convolution was used at the last three down-sampling layers. For up-sampling process, FCN-8 consist 3 <a href="/topics/physics-and-astronomy/deconvolution" title="Learn more about deconvolution from ScienceDirect's AI-generated Topic Pages" class="topic-link">deconvolution</a> layers: the first deconvolution layer is 2× up-sample from the last max-pooling layer prediction; the second deconvolution is 2× up-sample from the combination of the first deconvolution layer and second-last max-pooling prediction; the final deconvolution layer performs 8× up-sampling from the fusion of the second deconvolution layer and third-last max-pooling prediction. The number of channels and feature map size corresponding to each step process in FCN-8 are shown in </span><a name="bfig0025" href="#fig0025" class="workspace-trigger">Fig. 5</a>.</p><figure class="figure text-xs" id="fig0025"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr5.jpg" height="414" alt="Fig. 5" aria-describedby="cap0025"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr5_lrg.jpg" target="_blank" download="" title="Download high-res image (237KB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (237KB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr5.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0025"><p id="sp0025"><span class="label">Fig. 5</span>. Architecture of FCN-8. The variable L refers to the image size (w × h) at the level of different compression depth.</p></span></span></figure></div></section></section><section id="sec0045"><h3 id="sect0060" class="u-h4 u-margin-m-top u-margin-xs-bottom">2.4. Sliding window architecture</h3><p id="p0055">All the models should take 256 × 256 pixel in B-scan images as the input and output images. However, a full B-scan data image might be larger than the required input size; thus, it cannot be directly fed into the model. To overcome this image size limitation concern, we developed sliding window architecture to transform larger images to subset 256 × 256 pixels patches that could be processed using U-Net, SegNet-5, and FCN-8 model and recompose overlap algorithm to transform predicted patches back into the original image size.</p><p id="p0060">Sliding window architecture requires three arguments: first is the image size that the sliding window is going to loop over; second is the window size defined as the width and height of the desired window extract from the full image; and third is the stride size which is indicated as the step size in pixels the sliding window is going to skip.</p><p id="p0065">In order to perform sliding window image selection, the window with size of 256 × 256 like a 2D convolution of a single extractor through the full-sized image and extract the part of the image before were assessed by the trained and predicted model. Stride is the number of pixels shifts over the input matrix, the value of stride height and stride width depends on the full size of the image and sliding window size, were calculated under sub-multiple finding function in Python code. The complete output of the image patches can be calculated using <a name="beqn0005" href="#eqn0005" class="workspace-trigger">Eq. 1</a>:<span class="display"><span id="eqn0005" class="formula"><span class="label">(1)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 90%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>O</mi><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><mrow is=&quot;true&quot;><mfenced open=&quot;(&quot; close=&quot;)&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><mfrac is=&quot;true&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>F</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>H</mi></mrow></msub><mo is=&quot;true&quot;>&amp;#x2212;</mo><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>K</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>H</mi></mrow></msub></mrow><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>S</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>H</mi></mrow></msub></mrow></mfrac><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>+</mo><mn is=&quot;true&quot;>1</mn></mrow></mfenced></mrow><mo is=&quot;true&quot;>*</mo><mrow is=&quot;true&quot;><mfenced open=&quot;(&quot; close=&quot;)&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><mfrac is=&quot;true&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>F</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>W</mi></mrow></msub><mo is=&quot;true&quot;>&amp;#x2212;</mo><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>K</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>W</mi></mrow></msub></mrow><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>S</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>W</mi></mrow></msub></mrow></mfrac><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>+</mo><mn is=&quot;true&quot;>1</mn></mrow></mfenced></mrow></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="33.235ex" height="4.549ex" viewBox="0 -1217.1 14309.4 1958.7" role="img" focusable="false" style="vertical-align: -1.722ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-4F"></use></g><g is="true" transform="translate(1041,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(1819,0)"><g is="true"><use xlink:href="#MJSZ2-28"></use><g is="true" transform="translate(597,0)"><g is="true"><g transform="translate(120,0)"><rect stroke="none" width="2756" height="60" x="0" y="220"></rect><g is="true" transform="translate(60,515)"><g is="true"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-46"></use></g></g><g is="true" transform="translate(455,-107)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-48"></use></g></g></g><g is="true" transform="translate(969,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(1520,0)"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-4B"></use></g></g><g is="true" transform="translate(600,-107)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-48"></use></g></g></g></g><g is="true" transform="translate(903,-409)"><g is="true"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-53"></use></g></g><g is="true" transform="translate(433,-107)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-48"></use></g></g></g></g></g></g><g is="true" transform="translate(3218,0)"><use xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(4219,0)"><use xlink:href="#MJMAIN-31"></use></g></g><use xlink:href="#MJSZ2-29" x="5317" y="-1"></use></g></g><g is="true" transform="translate(7734,0)"><use xlink:href="#MJMAIN-2A"></use></g><g is="true" transform="translate(8234,0)"><g is="true"><use xlink:href="#MJSZ2-28"></use><g is="true" transform="translate(597,0)"><g is="true"><g transform="translate(120,0)"><rect stroke="none" width="2916" height="60" x="0" y="220"></rect><g is="true" transform="translate(60,526)"><g is="true"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-46"></use></g></g><g is="true" transform="translate(455,-107)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-57"></use></g></g></g><g is="true" transform="translate(1049,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(1600,0)"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-4B"></use></g></g><g is="true" transform="translate(600,-107)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-57"></use></g></g></g></g><g is="true" transform="translate(943,-409)"><g is="true"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-53"></use></g></g><g is="true" transform="translate(433,-107)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-57"></use></g></g></g></g></g></g><g is="true" transform="translate(3378,0)"><use xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(4379,0)"><use xlink:href="#MJMAIN-31"></use></g></g><use xlink:href="#MJSZ2-29" x="5477" y="-1"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">O</mi><mo linebreak="goodbreak" is="true">=</mo><mrow is="true"><mfenced open="(" close=")" is="true"><mrow is="true"><mfrac is="true"><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">F</mi></mrow><mrow is="true"><mi is="true">H</mi></mrow></msub><mo is="true">−</mo><msub is="true"><mrow is="true"><mi is="true">K</mi></mrow><mrow is="true"><mi is="true">H</mi></mrow></msub></mrow><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">S</mi></mrow><mrow is="true"><mi is="true">H</mi></mrow></msub></mrow></mfrac><mo linebreak="goodbreak" is="true">+</mo><mn is="true">1</mn></mrow></mfenced></mrow><mo is="true">*</mo><mrow is="true"><mfenced open="(" close=")" is="true"><mrow is="true"><mfrac is="true"><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">F</mi></mrow><mrow is="true"><mi is="true">W</mi></mrow></msub><mo is="true">−</mo><msub is="true"><mrow is="true"><mi is="true">K</mi></mrow><mrow is="true"><mi is="true">W</mi></mrow></msub></mrow><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">S</mi></mrow><mrow is="true"><mi is="true">W</mi></mrow></msub></mrow></mfrac><mo linebreak="goodbreak" is="true">+</mo><mn is="true">1</mn></mrow></mfenced></mrow></mrow></math></span></span><script type="math/mml" id="MathJax-Element-1"><math><mrow is="true"><mi is="true">O</mi><mo linebreak="goodbreak" is="true">=</mo><mrow is="true"><mfenced open="(" close=")" is="true"><mrow is="true"><mfrac is="true"><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">F</mi></mrow><mrow is="true"><mi is="true">H</mi></mrow></msub><mo is="true">−</mo><msub is="true"><mrow is="true"><mi is="true">K</mi></mrow><mrow is="true"><mi is="true">H</mi></mrow></msub></mrow><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">S</mi></mrow><mrow is="true"><mi is="true">H</mi></mrow></msub></mrow></mfrac><mo linebreak="goodbreak" is="true">+</mo><mn is="true">1</mn></mrow></mfenced></mrow><mo is="true">*</mo><mrow is="true"><mfenced open="(" close=")" is="true"><mrow is="true"><mfrac is="true"><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">F</mi></mrow><mrow is="true"><mi is="true">W</mi></mrow></msub><mo is="true">−</mo><msub is="true"><mrow is="true"><mi is="true">K</mi></mrow><mrow is="true"><mi is="true">W</mi></mrow></msub></mrow><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">S</mi></mrow><mrow is="true"><mi is="true">W</mi></mrow></msub></mrow></mfrac><mo linebreak="goodbreak" is="true">+</mo><mn is="true">1</mn></mrow></mfenced></mrow></mrow></math></script></span></span></span>where F<sub>H</sub> and F<sub>W</sub> are the height and width of the full-sized image, K<sub>H</sub> and K<sub>W</sub> are the sliding window height and width (each being 256), and S<sub>H</sub> and S<sub>W</sub><span> are stride height and stride width of the sliding window operation. The total patches image O indicates the number of part <a href="/topics/medicine-and-dentistry/afterimage" title="Learn more about image after from ScienceDirect's AI-generated Topic Pages" class="topic-link">image after</a> extract through full-sized image given by sliding window technique.</span></p><p id="p0070">For the inverse sliding window extraction, predicted patches are assumed to overlap and the full-size B-scan image is reconstructed by fulling in the patches from left to right and top to bottom. The overlapping regions were combined by average based on linear blend operator <a name="bbib45" href="#bib45" class="workspace-trigger">[45]</a>:<span class="display"><span id="eqn0010" class="formula"><span class="label">(2)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 90%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>g</mi><mrow is=&quot;true&quot;><mfenced open=&quot;(&quot; close=&quot;)&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>x</mi></mrow></mfenced></mrow><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><mfrac is=&quot;true&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>f</mi></mrow><mrow is=&quot;true&quot;><mn is=&quot;true&quot;>0</mn></mrow></msub><mrow is=&quot;true&quot;><mfenced open=&quot;(&quot; close=&quot;)&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>x</mi></mrow></mfenced></mrow><mo is=&quot;true&quot;>+</mo><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>f</mi></mrow><mrow is=&quot;true&quot;><mn is=&quot;true&quot;>1</mn></mrow></msub><mrow is=&quot;true&quot;><mfenced open=&quot;(&quot; close=&quot;)&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>x</mi></mrow></mfenced></mrow></mrow><mrow is=&quot;true&quot;><mn is=&quot;true&quot;>2</mn></mrow></mfrac></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="16.364ex" height="3.936ex" viewBox="0 -1217.1 7045.7 1694.5" role="img" focusable="false" style="vertical-align: -1.109ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-67"></use></g><g is="true" transform="translate(480,0)"><g is="true"><use xlink:href="#MJMAIN-28" x="0" y="0"></use><g is="true" transform="translate(389,0)"><g is="true"><use xlink:href="#MJMATHI-78"></use></g></g><use xlink:href="#MJMAIN-29" x="962" y="0"></use></g></g><g is="true" transform="translate(1832,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(2610,0)"><g transform="translate(397,0)"><rect stroke="none" width="3917" height="60" x="0" y="220"></rect><g is="true" transform="translate(60,591)"><g is="true"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-66"></use></g></g><g is="true" transform="translate(346,-171)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMAIN-30"></use></g></g></g><g is="true" transform="translate(667,0)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-28" x="0" y="0"></use><g is="true" transform="translate(275,0)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-78"></use></g></g><use transform="scale(0.707)" xlink:href="#MJMAIN-29" x="962" y="0"></use></g></g><g is="true" transform="translate(1623,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(2173,0)"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-66"></use></g></g><g is="true" transform="translate(346,-171)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMAIN-31"></use></g></g></g><g is="true" transform="translate(2841,0)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-28" x="0" y="0"></use><g is="true" transform="translate(275,0)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-78"></use></g></g><use transform="scale(0.707)" xlink:href="#MJMAIN-29" x="962" y="0"></use></g></g></g><g is="true" transform="translate(1781,-381)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-32"></use></g></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">g</mi><mrow is="true"><mfenced open="(" close=")" is="true"><mrow is="true"><mi is="true">x</mi></mrow></mfenced></mrow><mo linebreak="goodbreak" is="true">=</mo><mfrac is="true"><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">f</mi></mrow><mrow is="true"><mn is="true">0</mn></mrow></msub><mrow is="true"><mfenced open="(" close=")" is="true"><mrow is="true"><mi is="true">x</mi></mrow></mfenced></mrow><mo is="true">+</mo><msub is="true"><mrow is="true"><mi is="true">f</mi></mrow><mrow is="true"><mn is="true">1</mn></mrow></msub><mrow is="true"><mfenced open="(" close=")" is="true"><mrow is="true"><mi is="true">x</mi></mrow></mfenced></mrow></mrow><mrow is="true"><mn is="true">2</mn></mrow></mfrac></mrow></math></span></span><script type="math/mml" id="MathJax-Element-2"><math><mrow is="true"><mi is="true">g</mi><mrow is="true"><mfenced open="(" close=")" is="true"><mrow is="true"><mi is="true">x</mi></mrow></mfenced></mrow><mo linebreak="goodbreak" is="true">=</mo><mfrac is="true"><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">f</mi></mrow><mrow is="true"><mn is="true">0</mn></mrow></msub><mrow is="true"><mfenced open="(" close=")" is="true"><mrow is="true"><mi is="true">x</mi></mrow></mfenced></mrow><mo is="true">+</mo><msub is="true"><mrow is="true"><mi is="true">f</mi></mrow><mrow is="true"><mn is="true">1</mn></mrow></msub><mrow is="true"><mfenced open="(" close=")" is="true"><mrow is="true"><mi is="true">x</mi></mrow></mfenced></mrow></mrow><mrow is="true"><mn is="true">2</mn></mrow></mfrac></mrow></math></script></span></span></span>where g(x) is overlapping regions image, f<sub>0</sub>(x) and f<sub>1</sub>(x) is two patches which might have some overlapping region.</p><div><p id="p0075"><span>In this way, we can cover the whole image without resizing the input images. The combination of sliding window architecture and <a href="/topics/computer-science/deep-learning-model" title="Learn more about DL model from ScienceDirect's AI-generated Topic Pages" class="topic-link">DL model</a> is represented in </span><a name="bfig0030" href="#fig0030" class="workspace-trigger">Fig. 6</a>. The goal of sliding window is to transform high resolution input image into a probability map that corresponds to a ground truth segmentation mask.</p><figure class="figure text-xs" id="fig0030"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr6.jpg" height="213" alt="Fig. 6" aria-describedby="cap0030"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr6_lrg.jpg" target="_blank" download="" title="Download high-res image (342KB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (342KB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr6.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0030"><p id="sp0030"><span class="label">Fig. 6</span>. Block diagram of the Sliding window architecture.</p></span></span></figure></div></section><section id="sec0050"><h3 id="sect0065" class="u-h4 u-margin-m-top u-margin-xs-bottom">2.5. Training dataset</h3><p id="p0080"><span>The D1 dataset contained 800 B-scan images of human palm, all acquired using the PAM system. The data was then randomly split into training set, validation set (50 images), and test set (10 images). Each B-scan image has normalized pixel values, ranging from 0 to 1. For the <a href="/topics/computer-science/ground-truth-image" title="Learn more about ground truth image from ScienceDirect's AI-generated Topic Pages" class="topic-link">ground truth image</a> dataset, segmentation mask is a grayscale image (0–255) which was normalized to (0–1), extracted from raw data in PAM system, which were manually segmented by an experienced researcher. For data augmentation, random rotational transform (90, 180 and 270 degrees), random lateral and vertical shift (up to 10% of the image size) </span><a name="bbib46" href="#bib46" class="workspace-trigger">[46]</a><span><span> were applied to the training set images to tackle model over fitting due to the similarities of images presented by the PA system. The <a href="/topics/computer-science/validation-dataset" title="Learn more about validation dataset from ScienceDirect's AI-generated Topic Pages" class="topic-link">validation dataset</a> used the same data augmentation techniques utilized on the training dataset; none of the augmentation process was used on the testing datasets. The use of sliding window extraction focuses on the segmentation of multiresolution images without resizing method. All the models used the same training parameter in evaluating their performance. The model was trained using a batch size of four images of subset training due to memory constraints. The output layer uses a sigmoid activation to score a prediction of each pixel on patch images. Activation functions are specially used in artificial </span><a href="/topics/computer-science/neural-networks" title="Learn more about neural networks from ScienceDirect's AI-generated Topic Pages" class="topic-link">neural networks</a> to transform an input signal to an output signal </span><a name="bbib47" href="#bib47" class="workspace-trigger">[47]</a>. There are many different types of activation functions used in neural networks, depending on the type of neural network and network’s prediction accuracy. Sigmoid function, which can transform the value in range of 0–1, could be defined as <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 90%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>f</mi><mrow is=&quot;true&quot;><mfenced open=&quot;(&quot; close=&quot;)&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>x</mi></mrow></mfenced></mrow><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><mfrac is=&quot;true&quot;><mrow is=&quot;true&quot;><mn is=&quot;true&quot;>1</mn></mrow><mrow is=&quot;true&quot;><msup is=&quot;true&quot;><mrow is=&quot;true&quot;><mn is=&quot;true&quot;>1</mn><mo is=&quot;true&quot;>+</mo><mi is=&quot;true&quot;>e</mi></mrow><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>&amp;#x2212;</mo><mi is=&quot;true&quot;>x</mi></mrow></msup></mrow></mfrac></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="12.307ex" height="3.69ex" viewBox="0 -952.9 5298.7 1588.9" role="img" focusable="false" style="vertical-align: -1.477ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-66"></use></g><g is="true" transform="translate(550,0)"><g is="true"><use xlink:href="#MJMAIN-28" x="0" y="0"></use><g is="true" transform="translate(389,0)"><g is="true"><use xlink:href="#MJMATHI-78"></use></g></g><use xlink:href="#MJMAIN-29" x="962" y="0"></use></g></g><g is="true" transform="translate(1902,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(2680,0)"><g transform="translate(397,0)"><rect stroke="none" width="2100" height="60" x="0" y="220"></rect><g is="true" transform="translate(873,409)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g></g><g is="true" transform="translate(60,-480)"><g is="true"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(353,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(904,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g></g><g is="true" transform="translate(1234,278)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(389,0)"><use transform="scale(0.5)" xlink:href="#MJMATHI-78"></use></g></g></g></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">f</mi><mrow is="true"><mfenced open="(" close=")" is="true"><mrow is="true"><mi is="true">x</mi></mrow></mfenced></mrow><mo linebreak="goodbreak" is="true">=</mo><mfrac is="true"><mrow is="true"><mn is="true">1</mn></mrow><mrow is="true"><msup is="true"><mrow is="true"><mn is="true">1</mn><mo is="true">+</mo><mi is="true">e</mi></mrow><mrow is="true"><mo is="true">−</mo><mi is="true">x</mi></mrow></msup></mrow></mfrac></mrow></math></span></span><script type="math/mml" id="MathJax-Element-3"><math><mrow is="true"><mi is="true">f</mi><mrow is="true"><mfenced open="(" close=")" is="true"><mrow is="true"><mi is="true">x</mi></mrow></mfenced></mrow><mo linebreak="goodbreak" is="true">=</mo><mfrac is="true"><mrow is="true"><mn is="true">1</mn></mrow><mrow is="true"><msup is="true"><mrow is="true"><mn is="true">1</mn><mo is="true">+</mo><mi is="true">e</mi></mrow><mrow is="true"><mo is="true">−</mo><mi is="true">x</mi></mrow></msup></mrow></mfrac></mrow></math></script></span>. The model’s accuracy and model’s loss correspond to the accuracy and loss of the 256 × 256 binary segmentation. The total binary cross entropy loss function L, is used to train the model.<span class="display"><span id="eqn0015" class="formula"><span class="label">(3)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 90%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>L</mi><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><mspace width=&quot;1em&quot; is=&quot;true&quot; /><mo linebreak=&quot;badbreak&quot; is=&quot;true&quot;>&amp;#x2212;</mo><mfrac is=&quot;true&quot;><mrow is=&quot;true&quot;><mn is=&quot;true&quot;>1</mn></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>H</mi><mo is=&quot;true&quot;>*</mo><mi is=&quot;true&quot;>W</mi></mrow></mfrac><munderover is=&quot;true&quot;><mo is=&quot;true&quot;>&amp;#x2211;</mo><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>h</mi><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>1</mn></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>H</mi></mrow></munderover><mrow is=&quot;true&quot;><mspace width=&quot;1em&quot; is=&quot;true&quot; /></mrow><munderover is=&quot;true&quot;><mo is=&quot;true&quot;>&amp;#x2211;</mo><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>1</mn></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>W</mi></mrow></munderover><mrow is=&quot;true&quot;><mfenced open=&quot;(&quot; close=&quot;)&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>y</mi></mrow><mrow is=&quot;true&quot;><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>hw</mi></mrow></msub><mo is=&quot;true&quot;>*</mo><mi mathvariant=&quot;normal&quot; is=&quot;true&quot;>ln</mi><mrow is=&quot;true&quot;><mfenced open=&quot;(&quot; close=&quot;)&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>p</mi></mrow><mrow is=&quot;true&quot;><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>hw</mi></mrow></msub></mrow></mfenced></mrow><mo linebreak=&quot;badbreak&quot; is=&quot;true&quot;>+</mo><mrow is=&quot;true&quot;><mfenced open=&quot;(&quot; close=&quot;)&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><mn is=&quot;true&quot;>1</mn><mo linebreak=&quot;badbreak&quot; is=&quot;true&quot;>&amp;#x2212;</mo><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>y</mi></mrow><mrow is=&quot;true&quot;><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>hw</mi></mrow></msub></mrow></mfenced></mrow><mo is=&quot;true&quot;>*</mo><mi mathvariant=&quot;normal&quot; is=&quot;true&quot;>ln</mi><mrow is=&quot;true&quot;><mfenced open=&quot;(&quot; close=&quot;)&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><mn is=&quot;true&quot;>1</mn><mo linebreak=&quot;badbreak&quot; is=&quot;true&quot;>&amp;#x2212;</mo><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>p</mi></mrow><mrow is=&quot;true&quot;><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>hw</mi></mrow></msub></mrow></mfenced></mrow></mrow></mfenced></mrow></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="67.546ex" height="3.69ex" viewBox="0 -1058.6 29082.4 1588.9" role="img" focusable="false" style="vertical-align: -1.232ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-4C"></use></g><g is="true" transform="translate(959,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true"></g><g is="true" transform="translate(3015,0)"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(3794,0)"><g transform="translate(120,0)"><rect stroke="none" width="1843" height="60" x="0" y="220"></rect><g is="true" transform="translate(744,409)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g></g><g is="true" transform="translate(60,-441)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-48"></use></g><g is="true" transform="translate(628,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2A"></use></g><g is="true" transform="translate(982,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-57"></use></g></g></g></g><g is="true" transform="translate(6044,0)"><g is="true"><use xlink:href="#MJSZ1-2211"></use></g><g is="true" transform="translate(1056,477)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-48"></use></g></g><g is="true" transform="translate(1056,-287)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-68"></use></g><g is="true" transform="translate(407,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(958,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g></g></g><g is="true" transform="translate(8679,0)"><g is="true"></g></g><g is="true" transform="translate(9846,0)"><g is="true"><use xlink:href="#MJSZ1-2211"></use></g><g is="true" transform="translate(1056,477)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-57"></use></g></g><g is="true" transform="translate(1056,-287)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(506,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(1057,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g></g></g><g is="true" transform="translate(12413,0)"><g is="true"><use xlink:href="#MJMAIN-28" x="0" y="0"></use><g is="true" transform="translate(389,0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-79"></use></g></g><g is="true" transform="translate(490,-242)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-68"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-77" x="576" y="0"></use></g></g></g><g is="true" transform="translate(1727,0)"><use xlink:href="#MJMAIN-2A"></use></g><g is="true" transform="translate(2449,0)"><use xlink:href="#MJMAIN-6C"></use><use xlink:href="#MJMAIN-6E" x="278" y="0"></use></g><g is="true" transform="translate(3284,0)"><g is="true"><use xlink:href="#MJMAIN-28" x="0" y="0"></use><g is="true" transform="translate(389,0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-70"></use></g></g><g is="true" transform="translate(503,-231)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-68"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-77" x="576" y="0"></use></g></g></g></g><use xlink:href="#MJMAIN-29" x="1907" y="0"></use></g></g><g is="true" transform="translate(5581,0)"><use xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(6360,0)"><g is="true"><use xlink:href="#MJMAIN-28" x="0" y="0"></use><g is="true" transform="translate(389,0)"><g is="true"><use xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(722,0)"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(1723,0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-79"></use></g></g><g is="true" transform="translate(490,-242)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-68"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-77" x="576" y="0"></use></g></g></g></g><use xlink:href="#MJMAIN-29" x="3617" y="0"></use></g></g><g is="true" transform="translate(10367,0)"><use xlink:href="#MJMAIN-2A"></use></g><g is="true" transform="translate(11034,0)"><use xlink:href="#MJMAIN-6C"></use><use xlink:href="#MJMAIN-6E" x="278" y="0"></use></g><g is="true" transform="translate(11869,0)"><g is="true"><use xlink:href="#MJMAIN-28" x="0" y="0"></use><g is="true" transform="translate(389,0)"><g is="true"><use xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(722,0)"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(1723,0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-70"></use></g></g><g is="true" transform="translate(503,-231)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-68"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-77" x="576" y="0"></use></g></g></g></g><use xlink:href="#MJMAIN-29" x="3630" y="0"></use></g></g></g><use xlink:href="#MJMAIN-29" x="16279" y="0"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">L</mi><mo linebreak="goodbreak" is="true">=</mo><mspace width="1em" is="true"></mspace><mo linebreak="badbreak" is="true">−</mo><mfrac is="true"><mrow is="true"><mn is="true">1</mn></mrow><mrow is="true"><mi is="true">H</mi><mo is="true">*</mo><mi is="true">W</mi></mrow></mfrac><munderover is="true"><mo is="true">∑</mo><mrow is="true"><mi is="true">h</mi><mo is="true">=</mo><mn is="true">1</mn></mrow><mrow is="true"><mi is="true">H</mi></mrow></munderover><mrow is="true"><mspace width="1em" is="true"></mspace></mrow><munderover is="true"><mo is="true">∑</mo><mrow is="true"><mi is="true">w</mi><mo is="true">=</mo><mn is="true">1</mn></mrow><mrow is="true"><mi is="true">W</mi></mrow></munderover><mrow is="true"><mfenced open="(" close=")" is="true"><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">y</mi></mrow><mrow is="true"><mi mathvariant="italic" is="true">hw</mi></mrow></msub><mo is="true">*</mo><mi mathvariant="normal" is="true">ln</mi><mrow is="true"><mfenced open="(" close=")" is="true"><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">p</mi></mrow><mrow is="true"><mi mathvariant="italic" is="true">hw</mi></mrow></msub></mrow></mfenced></mrow><mo linebreak="badbreak" is="true">+</mo><mrow is="true"><mfenced open="(" close=")" is="true"><mrow is="true"><mn is="true">1</mn><mo linebreak="badbreak" is="true">−</mo><msub is="true"><mrow is="true"><mi is="true">y</mi></mrow><mrow is="true"><mi mathvariant="italic" is="true">hw</mi></mrow></msub></mrow></mfenced></mrow><mo is="true">*</mo><mi mathvariant="normal" is="true">ln</mi><mrow is="true"><mfenced open="(" close=")" is="true"><mrow is="true"><mn is="true">1</mn><mo linebreak="badbreak" is="true">−</mo><msub is="true"><mrow is="true"><mi is="true">p</mi></mrow><mrow is="true"><mi mathvariant="italic" is="true">hw</mi></mrow></msub></mrow></mfenced></mrow></mrow></mfenced></mrow></mrow></math></span></span><script type="math/mml" id="MathJax-Element-4"><math><mrow is="true"><mi is="true">L</mi><mo linebreak="goodbreak" is="true">=</mo><mspace width="1em" is="true"></mspace><mo linebreak="badbreak" is="true">−</mo><mfrac is="true"><mrow is="true"><mn is="true">1</mn></mrow><mrow is="true"><mi is="true">H</mi><mo is="true">*</mo><mi is="true">W</mi></mrow></mfrac><munderover is="true"><mo is="true">∑</mo><mrow is="true"><mi is="true">h</mi><mo is="true">=</mo><mn is="true">1</mn></mrow><mrow is="true"><mi is="true">H</mi></mrow></munderover><mrow is="true"><mspace width="1em" is="true"></mspace></mrow><munderover is="true"><mo is="true">∑</mo><mrow is="true"><mi is="true">w</mi><mo is="true">=</mo><mn is="true">1</mn></mrow><mrow is="true"><mi is="true">W</mi></mrow></munderover><mrow is="true"><mfenced open="(" close=")" is="true"><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">y</mi></mrow><mrow is="true"><mi mathvariant="italic" is="true">hw</mi></mrow></msub><mo is="true">*</mo><mi mathvariant="normal" is="true">ln</mi><mrow is="true"><mfenced open="(" close=")" is="true"><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">p</mi></mrow><mrow is="true"><mi mathvariant="italic" is="true">hw</mi></mrow></msub></mrow></mfenced></mrow><mo linebreak="badbreak" is="true">+</mo><mrow is="true"><mfenced open="(" close=")" is="true"><mrow is="true"><mn is="true">1</mn><mo linebreak="badbreak" is="true">−</mo><msub is="true"><mrow is="true"><mi is="true">y</mi></mrow><mrow is="true"><mi mathvariant="italic" is="true">hw</mi></mrow></msub></mrow></mfenced></mrow><mo is="true">*</mo><mi mathvariant="normal" is="true">ln</mi><mrow is="true"><mfenced open="(" close=")" is="true"><mrow is="true"><mn is="true">1</mn><mo linebreak="badbreak" is="true">−</mo><msub is="true"><mrow is="true"><mi is="true">p</mi></mrow><mrow is="true"><mi mathvariant="italic" is="true">hw</mi></mrow></msub></mrow></mfenced></mrow></mrow></mfenced></mrow></mrow></math></script></span></span></span>where H and W correspond to the image height and width in pixels (in this case is 256), <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 90%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>y</mi></mrow><mrow is=&quot;true&quot;><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>hw</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.495ex" height="1.972ex" viewBox="0 -530.3 1504.8 849.3" role="img" focusable="false" style="vertical-align: -0.741ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-79"></use></g></g><g is="true" transform="translate(490,-242)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-68"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-77" x="576" y="0"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub is="true"><mrow is="true"><mi is="true">y</mi></mrow><mrow is="true"><mi mathvariant="italic" is="true">hw</mi></mrow></msub></math></span></span><script type="math/mml" id="MathJax-Element-5"><math><msub is="true"><mrow is="true"><mi is="true">y</mi></mrow><mrow is="true"><mi mathvariant="italic" is="true">hw</mi></mrow></msub></math></script></span> and <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 90%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>p</mi></mrow><mrow is=&quot;true&quot;><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>hw</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.615ex" height="1.972ex" viewBox="-38.5 -530.3 1556.3 849.3" role="img" focusable="false" style="vertical-align: -0.741ex; margin-left: -0.089ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-70"></use></g></g><g is="true" transform="translate(503,-231)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-68"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-77" x="576" y="0"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub is="true"><mrow is="true"><mi is="true">p</mi></mrow><mrow is="true"><mi mathvariant="italic" is="true">hw</mi></mrow></msub></math></span></span><script type="math/mml" id="MathJax-Element-6"><math><msub is="true"><mrow is="true"><mi is="true">p</mi></mrow><mrow is="true"><mi mathvariant="italic" is="true">hw</mi></mrow></msub></math></script></span><span> correspond to the ground truth segmentations value and the predicted value for the corresponding pixel at position (h, w), and ln corresponds to the <a href="/topics/computer-science/natural-logarithm" title="Learn more about natural logarithm from ScienceDirect's AI-generated Topic Pages" class="topic-link">natural logarithm</a>.</span></p><p id="p0085">TensorFlow <a name="bbib48" href="#bib48" class="workspace-trigger">[48]</a><span> is used in implementing the proposed DL approach. The hardware platform we used in this study is a high-performance computer consisting of eight Intel Core i7-6700 (4.00 GHz) and high-speed graphics <a href="/topics/computer-science/computing-units" title="Learn more about computing unit from ScienceDirect's AI-generated Topic Pages" class="topic-link">computing unit</a> NVIDIA GeForce GTX 1060 with 32 GB memory. The networks were set up using Python 3.7 in Keras with a TensorFlow backend. The learning rate of the program is 0.0001 with Adam </span><a name="bbib49" href="#bib49" class="workspace-trigger">[49]</a> optimizer algorithm, where the number of iterations is set for 200 epochs. To prevent overfitting, the program is also set for early stopping if the model’s loss on the validation set did not improve for the next 10 patience epochs. ModelCheckPoint callbacks are used to keep the best weight of the model build at each iteration if it achieved minimum validation loss.</p></section><section id="sec0055"><h3 id="sect0070" class="u-h4 u-margin-m-top u-margin-xs-bottom">2.6. Evaluation methods</h3><div><p id="p0090"><span>To quantify model performance in <a href="/topics/computer-science/segmentation-task" title="Learn more about segmentation tasks from ScienceDirect's AI-generated Topic Pages" class="topic-link">segmentation tasks</a>, the performances of U-Net, SegNet-5, and FCN-8 were tested on the testing dataset. Model evaluation is based on four parameters: pixel accuracy, Intersection Over Union (IoU) (</span><a name="bfig0035" href="#fig0035" class="workspace-trigger">Fig. 7</a>), recall (also known as <em>sensitivity</em>), and BF-score <a name="bbib50" href="#bib50" class="workspace-trigger">[50]</a>. Global accuracy represents the ratio of the highest correctly classified pixels, regardless of all the classes, while accuracy indicates the average percentage of correctly identified pixels for each class.<span class="display"><span id="eqn0020" class="formula"><span class="label">(4)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 90%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>ac</mi><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>curacy</mi><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><mspace width=&quot;1em&quot; is=&quot;true&quot; /><mfrac is=&quot;true&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>T</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>P</mi></mrow></msub><mo is=&quot;true&quot;>+</mo><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>T</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>N</mi></mrow></msub></mrow><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>T</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>P</mi></mrow></msub><mo is=&quot;true&quot;>+</mo><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>T</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>N</mi></mrow></msub><mo is=&quot;true&quot;>+</mo><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>F</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>P</mi></mrow></msub><mo is=&quot;true&quot;>+</mo><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>F</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>N</mi></mrow></msub></mrow></mfrac></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="27.977ex" height="3.813ex" viewBox="0 -1058.6 12045.7 1641.7" role="img" focusable="false" style="vertical-align: -1.354ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-61"></use><use xlink:href="#MJMATHI-63" x="529" y="0"></use></g><g is="true" transform="translate(1129,0)"><use xlink:href="#MJMATHI-63"></use><use xlink:href="#MJMATHI-75" x="433" y="0"></use><use xlink:href="#MJMATHI-72" x="1006" y="0"></use><use xlink:href="#MJMATHI-61" x="1457" y="0"></use><use xlink:href="#MJMATHI-63" x="1987" y="0"></use><use xlink:href="#MJMATHI-79" x="2420" y="0"></use></g><g is="true" transform="translate(4318,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true"></g><g is="true" transform="translate(6096,0)"><g transform="translate(397,0)"><rect stroke="none" width="5430" height="60" x="0" y="220"></rect><g is="true" transform="translate(1546,515)"><g is="true"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-54"></use></g></g><g is="true" transform="translate(413,-107)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-50"></use></g></g></g><g is="true" transform="translate(859,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(1410,0)"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-54"></use></g></g><g is="true" transform="translate(413,-107)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-4E"></use></g></g></g></g><g is="true" transform="translate(60,-391)"><g is="true"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-54"></use></g></g><g is="true" transform="translate(413,-107)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-50"></use></g></g></g><g is="true" transform="translate(859,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(1410,0)"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-54"></use></g></g><g is="true" transform="translate(413,-107)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-4E"></use></g></g></g><g is="true" transform="translate(2338,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(2888,0)"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-46"></use></g></g><g is="true" transform="translate(455,-107)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-50"></use></g></g></g><g is="true" transform="translate(3790,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(4340,0)"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-46"></use></g></g><g is="true" transform="translate(455,-107)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-4E"></use></g></g></g></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi mathvariant="italic" is="true">ac</mi><mi mathvariant="italic" is="true">curacy</mi><mo linebreak="goodbreak" is="true">=</mo><mspace width="1em" is="true"></mspace><mfrac is="true"><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">T</mi></mrow><mrow is="true"><mi is="true">P</mi></mrow></msub><mo is="true">+</mo><msub is="true"><mrow is="true"><mi is="true">T</mi></mrow><mrow is="true"><mi is="true">N</mi></mrow></msub></mrow><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">T</mi></mrow><mrow is="true"><mi is="true">P</mi></mrow></msub><mo is="true">+</mo><msub is="true"><mrow is="true"><mi is="true">T</mi></mrow><mrow is="true"><mi is="true">N</mi></mrow></msub><mo is="true">+</mo><msub is="true"><mrow is="true"><mi is="true">F</mi></mrow><mrow is="true"><mi is="true">P</mi></mrow></msub><mo is="true">+</mo><msub is="true"><mrow is="true"><mi is="true">F</mi></mrow><mrow is="true"><mi is="true">N</mi></mrow></msub></mrow></mfrac></mrow></math></span></span><script type="math/mml" id="MathJax-Element-7"><math><mrow is="true"><mi mathvariant="italic" is="true">ac</mi><mi mathvariant="italic" is="true">curacy</mi><mo linebreak="goodbreak" is="true">=</mo><mspace width="1em" is="true"></mspace><mfrac is="true"><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">T</mi></mrow><mrow is="true"><mi is="true">P</mi></mrow></msub><mo is="true">+</mo><msub is="true"><mrow is="true"><mi is="true">T</mi></mrow><mrow is="true"><mi is="true">N</mi></mrow></msub></mrow><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">T</mi></mrow><mrow is="true"><mi is="true">P</mi></mrow></msub><mo is="true">+</mo><msub is="true"><mrow is="true"><mi is="true">T</mi></mrow><mrow is="true"><mi is="true">N</mi></mrow></msub><mo is="true">+</mo><msub is="true"><mrow is="true"><mi is="true">F</mi></mrow><mrow is="true"><mi is="true">P</mi></mrow></msub><mo is="true">+</mo><msub is="true"><mrow is="true"><mi is="true">F</mi></mrow><mrow is="true"><mi is="true">N</mi></mrow></msub></mrow></mfrac></mrow></math></script></span></span></span></p><figure class="figure text-xs" id="fig0035"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr7.jpg" height="189" alt="Fig. 7" aria-describedby="cap0035"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr7_lrg.jpg" target="_blank" download="" title="Download high-res image (41KB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (41KB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr7.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0035"><p id="sp0035"><span class="label">Fig. 7</span>. Definition of intersection over union (IoU).</p></span></span></figure></div><p id="p0095"><span>IoU is an <a href="/topics/computer-science/evaluation-metric" title="Learn more about evaluation metric from ScienceDirect's AI-generated Topic Pages" class="topic-link">evaluation metric</a> used to measure the accuracy of predicted bounding box on a ground truth bounding box, whereas mean IoU is defined as the average value over classes. IoU is defined in </span><a name="beqn0025" href="#eqn0025" class="workspace-trigger">Eq. 5</a>.<span class="display"><span id="eqn0025" class="formula"><span class="label">(5)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-8-Frame" tabindex="0" style="font-size: 90%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>IoU</mi><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><mspace width=&quot;1em&quot; is=&quot;true&quot; /><mfrac is=&quot;true&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>T</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>P</mi></mrow></msub></mrow><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>T</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>P</mi></mrow></msub><mo is=&quot;true&quot;>+</mo><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>F</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>P</mi></mrow></msub><mo is=&quot;true&quot;>+</mo><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>F</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>N</mi></mrow></msub></mrow></mfrac></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="18.896ex" height="3.813ex" viewBox="0 -1058.6 8135.8 1641.7" role="img" focusable="false" style="vertical-align: -1.354ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-49"></use><use xlink:href="#MJMATHI-6F" x="440" y="0"></use><use xlink:href="#MJMATHI-55" x="926" y="0"></use></g><g is="true" transform="translate(1887,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true"></g><g is="true" transform="translate(3665,0)"><g transform="translate(397,0)"><rect stroke="none" width="3952" height="60" x="0" y="220"></rect><g is="true" transform="translate(1546,515)"><g is="true"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-54"></use></g></g><g is="true" transform="translate(413,-107)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-50"></use></g></g></g></g><g is="true" transform="translate(60,-391)"><g is="true"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-54"></use></g></g><g is="true" transform="translate(413,-107)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-50"></use></g></g></g><g is="true" transform="translate(859,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(1410,0)"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-46"></use></g></g><g is="true" transform="translate(455,-107)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-50"></use></g></g></g><g is="true" transform="translate(2311,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(2862,0)"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-46"></use></g></g><g is="true" transform="translate(455,-107)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-4E"></use></g></g></g></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi mathvariant="italic" is="true">IoU</mi><mo linebreak="goodbreak" is="true">=</mo><mspace width="1em" is="true"></mspace><mfrac is="true"><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">T</mi></mrow><mrow is="true"><mi is="true">P</mi></mrow></msub></mrow><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">T</mi></mrow><mrow is="true"><mi is="true">P</mi></mrow></msub><mo is="true">+</mo><msub is="true"><mrow is="true"><mi is="true">F</mi></mrow><mrow is="true"><mi is="true">P</mi></mrow></msub><mo is="true">+</mo><msub is="true"><mrow is="true"><mi is="true">F</mi></mrow><mrow is="true"><mi is="true">N</mi></mrow></msub></mrow></mfrac></mrow></math></span></span><script type="math/mml" id="MathJax-Element-8"><math><mrow is="true"><mi mathvariant="italic" is="true">IoU</mi><mo linebreak="goodbreak" is="true">=</mo><mspace width="1em" is="true"></mspace><mfrac is="true"><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">T</mi></mrow><mrow is="true"><mi is="true">P</mi></mrow></msub></mrow><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">T</mi></mrow><mrow is="true"><mi is="true">P</mi></mrow></msub><mo is="true">+</mo><msub is="true"><mrow is="true"><mi is="true">F</mi></mrow><mrow is="true"><mi is="true">P</mi></mrow></msub><mo is="true">+</mo><msub is="true"><mrow is="true"><mi is="true">F</mi></mrow><mrow is="true"><mi is="true">N</mi></mrow></msub></mrow></mfrac></mrow></math></script></span></span></span>where T<sub>P</sub>, T<sub>N</sub>, F<sub>P</sub>, and F<sub>N</sub> correspond to true positive, true negative, false positive and false negative pixels, respectively. A true positive is a correctly predicted pixels in positive class, a false positive is a falsely predicted pixels in positive class, and the false negative corresponds to a falsely predicted pixels in negative class.</p><p id="p0100">The IoU has been known to be well suited to evaluate the dataset with imbalance class, where more than 90% of the pixels are background. The IoU range from 0–1, where 1 signifying the greatest similarity between ground truth and predicted image.</p><p id="p0105">BF-score measures the proximity and similarity between the predicted boundary and the ground truth boundary, and is given by weighted mean of precision and recall, as defined in <a name="beqn0030" href="#eqn0030" class="workspace-trigger">Eq. 6</a>.<span class="display"><span id="eqn0030" class="formula"><span class="label">(6)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-9-Frame" tabindex="0" style="font-size: 90%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>BF</mi><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><mspace width=&quot;1em&quot; is=&quot;true&quot; /><mfrac is=&quot;true&quot;><mrow is=&quot;true&quot;><mn is=&quot;true&quot;>2</mn><mo is=&quot;true&quot;>*</mo><mrow is=&quot;true&quot;><mfenced open=&quot;(&quot; close=&quot;)&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>precision</mi><mo is=&quot;true&quot;>*</mo><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>recall</mi></mrow></mfenced></mrow></mrow><mrow is=&quot;true&quot;><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>precision</mi><mo is=&quot;true&quot;>+</mo><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>recall</mi></mrow></mfrac></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="24.067ex" height="4.304ex" viewBox="0 -1217.1 10362 1853" role="img" focusable="false" style="vertical-align: -1.477ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-42"></use><use xlink:href="#MJMATHI-46" x="759" y="0"></use></g><g is="true" transform="translate(1680,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true"></g><g is="true" transform="translate(3459,0)"><g transform="translate(397,0)"><rect stroke="none" width="6384" height="60" x="0" y="220"></rect><g is="true" transform="translate(60,586)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-32"></use></g><g is="true" transform="translate(353,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2A"></use></g><g is="true" transform="translate(707,0)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-28" x="0" y="0"></use><g is="true" transform="translate(275,0)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-70"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-72" x="503" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-65" x="955" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-63" x="1421" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-69" x="1855" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-73" x="2200" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-69" x="2670" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-6F" x="3015" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-6E" x="3501" y="0"></use></g><g is="true" transform="translate(2900,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2A"></use></g><g is="true" transform="translate(3254,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-72"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-65" x="451" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-63" x="918" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-61" x="1351" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-6C" x="1880" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-6C" x="2179" y="0"></use></g></g><use transform="scale(0.707)" xlink:href="#MJMAIN-29" x="7469" y="0"></use></g></g></g><g is="true" transform="translate(591,-402)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-70"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-72" x="503" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-65" x="955" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-63" x="1421" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-69" x="1855" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-73" x="2200" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-69" x="2670" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-6F" x="3015" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-6E" x="3501" y="0"></use></g><g is="true" transform="translate(2900,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(3450,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-72"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-65" x="451" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-63" x="918" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-61" x="1351" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-6C" x="1880" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-6C" x="2179" y="0"></use></g></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi mathvariant="italic" is="true">BF</mi><mo linebreak="goodbreak" is="true">=</mo><mspace width="1em" is="true"></mspace><mfrac is="true"><mrow is="true"><mn is="true">2</mn><mo is="true">*</mo><mrow is="true"><mfenced open="(" close=")" is="true"><mrow is="true"><mi mathvariant="italic" is="true">precision</mi><mo is="true">*</mo><mi mathvariant="italic" is="true">recall</mi></mrow></mfenced></mrow></mrow><mrow is="true"><mi mathvariant="italic" is="true">precision</mi><mo is="true">+</mo><mi mathvariant="italic" is="true">recall</mi></mrow></mfrac></mrow></math></span></span><script type="math/mml" id="MathJax-Element-9"><math><mrow is="true"><mi mathvariant="italic" is="true">BF</mi><mo linebreak="goodbreak" is="true">=</mo><mspace width="1em" is="true"></mspace><mfrac is="true"><mrow is="true"><mn is="true">2</mn><mo is="true">*</mo><mrow is="true"><mfenced open="(" close=")" is="true"><mrow is="true"><mi mathvariant="italic" is="true">precision</mi><mo is="true">*</mo><mi mathvariant="italic" is="true">recall</mi></mrow></mfenced></mrow></mrow><mrow is="true"><mi mathvariant="italic" is="true">precision</mi><mo is="true">+</mo><mi mathvariant="italic" is="true">recall</mi></mrow></mfrac></mrow></math></script></span></span></span>where precision is the ratio of true positives and all pixels classified as positives, while ‘recall’ is the ratio of true positives and all positive elements (ground truth).<span class="display"><span id="eqn0035" class="formula"><span class="label">(7)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-10-Frame" tabindex="0" style="font-size: 90%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>precision</mi><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><mspace width=&quot;1em&quot; is=&quot;true&quot; /><mfrac is=&quot;true&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>T</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>P</mi></mrow></msub></mrow><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>T</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>P</mi></mrow></msub><mo is=&quot;true&quot;>+</mo><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>F</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>P</mi></mrow></msub></mrow></mfrac></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="21.242ex" height="3.813ex" viewBox="-38.5 -1058.6 9145.8 1641.7" role="img" focusable="false" style="vertical-align: -1.354ex; margin-left: -0.089ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-70"></use><use xlink:href="#MJMATHI-72" x="503" y="0"></use><use xlink:href="#MJMATHI-65" x="955" y="0"></use><use xlink:href="#MJMATHI-63" x="1421" y="0"></use><use xlink:href="#MJMATHI-69" x="1855" y="0"></use><use xlink:href="#MJMATHI-73" x="2200" y="0"></use><use xlink:href="#MJMATHI-69" x="2670" y="0"></use><use xlink:href="#MJMATHI-6F" x="3015" y="0"></use><use xlink:href="#MJMATHI-6E" x="3501" y="0"></use></g><g is="true" transform="translate(4379,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true"></g><g is="true" transform="translate(6157,0)"><g transform="translate(397,0)"><rect stroke="none" width="2431" height="60" x="0" y="220"></rect><g is="true" transform="translate(785,515)"><g is="true"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-54"></use></g></g><g is="true" transform="translate(413,-107)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-50"></use></g></g></g></g><g is="true" transform="translate(60,-391)"><g is="true"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-54"></use></g></g><g is="true" transform="translate(413,-107)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-50"></use></g></g></g><g is="true" transform="translate(859,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(1410,0)"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-46"></use></g></g><g is="true" transform="translate(455,-107)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-50"></use></g></g></g></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi mathvariant="italic" is="true">precision</mi><mo linebreak="goodbreak" is="true">=</mo><mspace width="1em" is="true"></mspace><mfrac is="true"><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">T</mi></mrow><mrow is="true"><mi is="true">P</mi></mrow></msub></mrow><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">T</mi></mrow><mrow is="true"><mi is="true">P</mi></mrow></msub><mo is="true">+</mo><msub is="true"><mrow is="true"><mi is="true">F</mi></mrow><mrow is="true"><mi is="true">P</mi></mrow></msub></mrow></mfrac></mrow></math></span></span><script type="math/mml" id="MathJax-Element-10"><math><mrow is="true"><mi mathvariant="italic" is="true">precision</mi><mo linebreak="goodbreak" is="true">=</mo><mspace width="1em" is="true"></mspace><mfrac is="true"><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">T</mi></mrow><mrow is="true"><mi is="true">P</mi></mrow></msub></mrow><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">T</mi></mrow><mrow is="true"><mi is="true">P</mi></mrow></msub><mo is="true">+</mo><msub is="true"><mrow is="true"><mi is="true">F</mi></mrow><mrow is="true"><mi is="true">P</mi></mrow></msub></mrow></mfrac></mrow></math></script></span></span></span><span class="display"><span id="eqn0040" class="formula"><span class="label">(8)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-11-Frame" tabindex="0" style="font-size: 90%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>recall</mi><mspace width=&quot;1em&quot; is=&quot;true&quot; /><mo stretchy=&quot;false&quot; is=&quot;true&quot;>(</mo><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>sensitivity</mi><mo stretchy=&quot;false&quot; is=&quot;true&quot;>)</mo><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><mspace width=&quot;1em&quot; is=&quot;true&quot; /><mfrac is=&quot;true&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>T</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>P</mi></mrow></msub></mrow><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>T</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>P</mi></mrow></msub><mo is=&quot;true&quot;>+</mo><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>F</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>N</mi></mrow></msub></mrow></mfrac></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="32.685ex" height="3.813ex" viewBox="0 -1058.6 14072.8 1641.7" role="img" focusable="false" style="vertical-align: -1.354ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-72"></use><use xlink:href="#MJMATHI-65" x="451" y="0"></use><use xlink:href="#MJMATHI-63" x="918" y="0"></use><use xlink:href="#MJMATHI-61" x="1351" y="0"></use><use xlink:href="#MJMATHI-6C" x="1881" y="0"></use><use xlink:href="#MJMATHI-6C" x="2179" y="0"></use></g><g is="true"></g><g is="true" transform="translate(3478,0)"><use xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(3867,0)"><use xlink:href="#MJMATHI-73"></use><use xlink:href="#MJMATHI-65" x="469" y="0"></use><use xlink:href="#MJMATHI-6E" x="936" y="0"></use><use xlink:href="#MJMATHI-73" x="1536" y="0"></use><use xlink:href="#MJMATHI-69" x="2006" y="0"></use><use xlink:href="#MJMATHI-74" x="2351" y="0"></use><use xlink:href="#MJMATHI-69" x="2713" y="0"></use><use xlink:href="#MJMATHI-76" x="3058" y="0"></use><use xlink:href="#MJMATHI-69" x="3544" y="0"></use><use xlink:href="#MJMATHI-74" x="3889" y="0"></use><use xlink:href="#MJMATHI-79" x="4251" y="0"></use></g><g is="true" transform="translate(8609,0)"><use xlink:href="#MJMAIN-29"></use></g><g is="true" transform="translate(9276,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true"></g><g is="true" transform="translate(11054,0)"><g transform="translate(397,0)"><rect stroke="none" width="2500" height="60" x="0" y="220"></rect><g is="true" transform="translate(820,515)"><g is="true"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-54"></use></g></g><g is="true" transform="translate(413,-107)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-50"></use></g></g></g></g><g is="true" transform="translate(60,-391)"><g is="true"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-54"></use></g></g><g is="true" transform="translate(413,-107)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-50"></use></g></g></g><g is="true" transform="translate(859,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(1410,0)"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-46"></use></g></g><g is="true" transform="translate(455,-107)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-4E"></use></g></g></g></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi mathvariant="italic" is="true">recall</mi><mspace width="1em" is="true"></mspace><mo stretchy="false" is="true">(</mo><mi mathvariant="italic" is="true">sensitivity</mi><mo stretchy="false" is="true">)</mo><mo linebreak="goodbreak" is="true">=</mo><mspace width="1em" is="true"></mspace><mfrac is="true"><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">T</mi></mrow><mrow is="true"><mi is="true">P</mi></mrow></msub></mrow><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">T</mi></mrow><mrow is="true"><mi is="true">P</mi></mrow></msub><mo is="true">+</mo><msub is="true"><mrow is="true"><mi is="true">F</mi></mrow><mrow is="true"><mi is="true">N</mi></mrow></msub></mrow></mfrac></mrow></math></span></span><script type="math/mml" id="MathJax-Element-11"><math><mrow is="true"><mi mathvariant="italic" is="true">recall</mi><mspace width="1em" is="true"></mspace><mo stretchy="false" is="true">(</mo><mi mathvariant="italic" is="true">sensitivity</mi><mo stretchy="false" is="true">)</mo><mo linebreak="goodbreak" is="true">=</mo><mspace width="1em" is="true"></mspace><mfrac is="true"><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">T</mi></mrow><mrow is="true"><mi is="true">P</mi></mrow></msub></mrow><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">T</mi></mrow><mrow is="true"><mi is="true">P</mi></mrow></msub><mo is="true">+</mo><msub is="true"><mrow is="true"><mi is="true">F</mi></mrow><mrow is="true"><mi is="true">N</mi></mrow></msub></mrow></mfrac></mrow></math></script></span></span></span></p></section><section id="sec0060"><h3 id="sect0075" class="u-h4 u-margin-m-top u-margin-xs-bottom">2.7. Segmentation in 3D volumetric</h3><p id="p0110"><span>The output generated by CNN model is 2-channel tensor binary segmentation mask which is same dimension as the input image. The first channel representing segmentation mask for skin layer and second channel representing for blood vessels layer. In order to divide skin and blood vessels in a 3D volume, mask bitwise operation AND was computed between original 3D data and segmentation mask 3D data. The skin signals were removed by logical <a href="/topics/computer-science/bitwise-operator" title="Learn more about bitwise operator from ScienceDirect's AI-generated Topic Pages" class="topic-link">bitwise operator</a><span> AND with blood vessels mask (inversely for blood vessel signal). Finally, the output consists of two 3D <a href="/topics/computer-science/segmentation-map" title="Learn more about segmentation maps from ScienceDirect's AI-generated Topic Pages" class="topic-link">segmentation maps</a> for each class (also see in </span></span><a name="bsec0105" href="#sec0105" class="workspace-trigger">Supplementary Fig. S1</a>).</p><p id="p0115"><span><span>For processing 3D image formats, the input data from segmented image was converted in to NRRD (nearly raw raster data) file, which is a common medical <a href="/topics/computer-science/data-type" title="Learn more about data format from ScienceDirect's AI-generated Topic Pages" class="topic-link">data format</a> for visualization and processing involving three-dimensional raster data. Besides that, the 3D image </span><a href="/topics/computer-science/rendering-process" title="Learn more about rendering process from ScienceDirect's AI-generated Topic Pages" class="topic-link">rendering process</a> is powered by the Visualization Toolkit (VTK) open-source library and CUDA Toolkit GPU-accelerated libraries, which is a powerful tool in visualizing a 3D perspective from multiple 3D images. The imaging results were visualized in graphical user interface designed by Qt creator on C++ platform. To distinguish between the two profiles in a 3D volumetric rendering, scalars to colors converting was applied for each profile with a different colormap (gray-colormap for skin profile and hot-colormap for blood vessels profile). The 3D volumetric segmentation image was show in </span><a name="bfig0060" href="#fig0060" class="workspace-trigger">Fig. 12</a>.</p></section></section><section id="sec0065"><h2 id="sect0080" class="u-h3 u-margin-l-top u-margin-xs-bottom">3. Results</h2><section id="sec0070"><h3 id="sect0085" class="u-h4 u-margin-m-top u-margin-xs-bottom">3.1. Model architecture comparison</h3><div><p id="p0120">U-Net is trained for 33 epochs due to the early stopping callbacks; the training loss was noted to keep on decreasing, but the validation loss did not improve and started to increase which might be due to overfitting. The SegNet-5 is trained for 32 epochs, where model overfitting is prevented by early stopping callback and dropout layers. FCN-8 is then trained on the same dataset using the same cross entropy loss of function and Adam optimizer with U-Net and SegNet-5. The model is trained for 74 epochs after the early stopping callbacks and stopped it. The training loss kept on decreasing with the number of epochs but the validation did not decrease after the 64th epoch. The accuracy and loss of training and validation are shown in <a name="bfig0040" href="#fig0040" class="workspace-trigger">Fig. 8</a>.</p><figure class="figure text-xs" id="fig0040"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr8.jpg" height="795" alt="Fig. 8" aria-describedby="cap0040"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr8_lrg.jpg" target="_blank" download="" title="Download high-res image (376KB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (376KB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr8.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0040"><p id="sp0040"><span class="label">Fig. 8</span>. Model accuracy and loss comparison with respect to the corresponding number of epochs. (A) U-Net accuracy; (B) U-Net loss; (C) SegNet-5 accuracy; (D) SegNet-5 loss; (E) FCN-8 accuracy; (F) FCN-8 loss.</p></span></span></figure></div><div><p id="p0125"><span>To quantify model performance in <a href="/topics/computer-science/segmentation-task" title="Learn more about segmentation tasks from ScienceDirect's AI-generated Topic Pages" class="topic-link">segmentation tasks</a>, five evaluation indicators can be observed on testing dataset. The testing dataset includes 10 full-size B-scan images (1000 × 1200 pixels) split randomly from D1 data without any augmentation performance (also see in </span><a name="bfig0050" href="#fig0050" class="workspace-trigger">Fig. 10</a> and <a name="bsec0105" href="#sec0105" class="workspace-trigger">Supplementary Fig. S2</a>). The performance of three models is reported in <a name="btbl0005" href="#tbl0005" class="workspace-trigger">Table 1</a> and constructed in <a name="bfig0045" href="#fig0045" class="workspace-trigger">Fig. 9</a><span>. Among the <a href="/topics/computer-science/deep-learning-method" title="Learn more about DL methods from ScienceDirect's AI-generated Topic Pages" class="topic-link">DL methods</a>, FCN-8 exhibited very poor performance, while U-Net was noted to have the best performance. U-Net outperforms FCN-8 by 0.48% in pixel accuracy, 17.12% in IoU, 18.64% in sensitivity, and 18.66% in BF-score. Moreover, the epoch time was reduced by two-times. The SegNet-5 model performance is equivalent to FCN-8, but the number of iterations is not more than twice. SegNet-5 outperforms FCN-8 by 0.16% in pixel accuracy, 3.77% in IoU, 1.86% in sensitivity, and 7.75% in BF-score. To visualize the performance comparison of three model, five examples of segmentation results from the testing dataset are shown in </span><a name="bfig0050" href="#fig0050" class="workspace-trigger">Fig. 10</a>. From column A to D, the image is Ground truth, U-Net, SegNet-5, FCN-8.</p><div class="tables colsep-0 rowsep-0 frame-topbot" id="tbl0005"><span class="captions"><span id="cap0065"><p id="sp0065"><span class="label">Table 1</span>. Statistical metrics (Mean ± standard deviation) comparison of <a href="/topics/computer-science/segmentation-performance" title="Learn more about segmentation performance from ScienceDirect's AI-generated Topic Pages" class="topic-link">segmentation performance</a> on testing dataset.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col"></th><th scope="col">U-Net</th><th scope="col">SegNet-5</th><th scope="col">FCN-8</th></tr></thead><tbody><tr><th scope="row">Global accuracy</th><td>0.9953 ± 0.0015</td><td>0.9938 ± 0.0013</td><td>0.9920 ± 0.0019</td></tr><tr><th scope="row">Accuracy</th><td>0.9908 ± 0.0013</td><td>0.9876 ± 0.0022</td><td>0.9860 ± 0.0025</td></tr><tr><th scope="row">IoU</th><td>0.7406 ± 0.0144</td><td>0.6071 ± 0.0091</td><td>0.5694 ± 0.0127</td></tr><tr><th scope="row">Sensitivity</th><td>0.8084 ± 0.0109</td><td>0.6406 ± 0.0230</td><td>0.6220 ± 0.0268</td></tr><tr><th scope="row">BF-score</th><td>0.7529 ± 0.0205</td><td>0.6438 ± 0.0231</td><td>0.5663 ± 0.0245</td></tr></tbody></table></div></div><figure class="figure text-xs" id="fig0045"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr9.jpg" height="522" alt="Fig. 9" aria-describedby="cap0045"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr9_lrg.jpg" target="_blank" download="" title="Download high-res image (165KB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (165KB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr9.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0045"><p id="sp0045"><span class="label">Fig. 9</span>. Boxplots of averaged statistical metrics of U-Net, SegNet-5 and FCN-8 as represented in <a name="btbl0005" href="#tbl0005" class="workspace-trigger">Table 1</a>. (A) Accuracy; (B) Intersection over Union (IoU); (C) Sensitivity; (D) BF-score.</p></span></span></figure><figure class="figure text-xs" id="fig0050"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr10.jpg" height="594" alt="Fig. 10" aria-describedby="cap0050"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr10_lrg.jpg" target="_blank" download="" title="Download high-res image (580KB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (580KB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr10.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0050"><p id="sp0050"><span class="label">Fig. 10</span>. Visualization of segmentation comparison using different methods on five examples from testing dataset. Column A to D correspond to different method, from left to right: Ground truth, U-Net, SegNet-5, FCN-8; the five examples correspond to five rows from 1 to 5 (please find <a name="bsec0105" href="#sec0105" class="workspace-trigger">Supplementary Fig. S2</a> for examples 6–10).</p></span></span></figure></div><div><p id="p0130">As shown from visualization results (<a name="bfig0045" href="#fig0045" class="workspace-trigger">Figs. 9</a> and <a name="bfig0050" href="#fig0050" class="workspace-trigger">10</a>), it can be observed that U-Net outperforms SegNet-5 and FCN-8 and demonstrates good reliability and stability. Furthermore, a comparison of training time and memory requirements to train the models is summarized in <a name="btbl0010" href="#tbl0010" class="workspace-trigger">Table 2</a>.</p><div class="tables colsep-0 rowsep-0 frame-topbot" id="tbl0010"><span class="captions"><span id="cap0070"><p id="sp0070"><span class="label">Table 2</span>. Comparison of training time and memory requirements for different model.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col"></th><th scope="col">U-Net</th><th scope="col">SegNet-5</th><th scope="col">FCN-8</th></tr></thead><tbody><tr><th scope="row">Training time (min)</th><td class="align-char">55</td><td class="align-char">59</td><td class="align-char">121</td></tr><tr><th scope="row">Memory (MB)</th><td class="align-char">3012</td><td class="align-char">2989</td><td class="align-char">2992</td></tr></tbody></table></div></div></div></section><section id="sec0075"><h3 id="sect0090" class="u-h4 u-margin-m-top u-margin-xs-bottom">3.2. Performance in in vivo PA imaging</h3><p id="p0135"><span>U-Net architectures archive the best evaluation in all the performance of <a href="/topics/computer-science/convolutional-neural-networks" title="Learn more about CNN from ScienceDirect's AI-generated Topic Pages" class="topic-link">CNN</a> models. The U-Net produced better results in segmenting the skin and blood vessels with IoU of 0.74 and BF score of 0.75. These values are reliable for the imbalance class dataset, where background is more than 90% of pixels. Thus, U-Net is the best-suited solution and was chosen to perform segmentation in in vivo </span><a href="/topics/medicine-and-dentistry/photoacoustic-imaging" title="Learn more about PA imaging from ScienceDirect's AI-generated Topic Pages" class="topic-link">PA imaging</a>.</p><div><p id="p0140">To show the possibility of our model, skin surface and blood vessels profile segmentation were performed on two-sample test: D2 and D3 (PA imaging of a human palm and PA imaging of a human foot). Region of interest inside the red dashed area with an area of 100 × 80 mm<sup>2</sup> was imaged as shown in <a name="bfig0060" href="#fig0060" class="workspace-trigger">Fig. 12</a><span>(A, B). B-scan images from the scanning data were then fed to the Slide-U-Net (combination of sliding window architecture and U-Net) algorithm, which gives the segmented image. Due to the result of scanning, B-scan image included only two kinds of PA signal: skin and subcutaneous vessels. After feeding B-scan image into the model, images were segmented into two classes binary mask (one-hot encoding) in two-dimensional predicted image. By decode one-hot labels, each segmentation B-scan image is a <a href="/topics/computer-science/segmentation-map" title="Learn more about segmentation map from ScienceDirect's AI-generated Topic Pages" class="topic-link">segmentation map</a> where each pixel contains a class label represented as an integer (as show in </span><a name="bfig0050" href="#fig0050" class="workspace-trigger">Fig. 10</a><span>): 0 represents background, 1 represents blood vessels profile and 2 represents skin profile. The comparison of in vivo MAP images which were visualized using maximum amplitude projection on each 3D <a href="/topics/computer-science/volumetric-data" title="Learn more about volumetric data from ScienceDirect's AI-generated Topic Pages" class="topic-link">volumetric data</a> (before and after segmentation) along Z-axis is shown in </span><a name="bfig0055" href="#fig0055" class="workspace-trigger">Fig. 11</a><span>. The detailed PA amplitude image that is overshadowed by mixture signals between the skin surface and underlying <a href="/topics/medicine-and-dentistry/vascularity" title="Learn more about vasculature from ScienceDirect's AI-generated Topic Pages" class="topic-link">vasculature</a> is shown in </span><a name="bfig0055" href="#fig0055" class="workspace-trigger">Fig. 11</a>(A) and <a name="bfig0055" href="#fig0055" class="workspace-trigger">Fig. 11</a>(D), but it is clearly visualized in <a name="bfig0055" href="#fig0055" class="workspace-trigger">Fig. 11</a>(B, C) and <a name="bfig0055" href="#fig0055" class="workspace-trigger">Fig. 11</a>(E, F).</p><figure class="figure text-xs" id="fig0055"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr11.jpg" height="566" alt="Fig. 11" aria-describedby="cap0055"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr11_lrg.jpg" target="_blank" download="" title="Download high-res image (1MB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (1MB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr11.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0055"><p id="sp0055"><span class="label">Fig. 11</span>. Comparison of in vivo MAP image of skin and underlying <a href="/topics/medicine-and-dentistry/vascularity" title="Learn more about vasculature from ScienceDirect's AI-generated Topic Pages" class="topic-link">vasculature</a> in a human palm and foot before and after performing segmentation in Slide-UNET. PA MAP image of human palm (A) and human foot (D) before segmentation. PA image of skin surface structure of human palm (B) and human foot (E) after segmentation. PA image of subcutaneous vasculature structure of human palm (C) and human foot (F) after segmentation. Close-up images of the dashed box regions (1–2) are shown to the right side as (A1), (A2).</p></span></span></figure></div><div><p id="p0145">The 3D volume was reconstructed by leveraging the union of 2D B-scan images. Each B-scan image was segmented by pre-trained Slide-U-Net algorithm. For illustrative purposes, the image of 3D volumetric segmentation was shown in <a name="bfig0060" href="#fig0060" class="workspace-trigger">Fig. 12</a>(C, D) (also see Supplementary Movies 1 and 2). In order to facilitate visualization, results have been projected on the coronal cross-sectional and sagittal cross-sectional planes (<a name="bfig0060" href="#fig0060" class="workspace-trigger">Fig. 12</a>(C1, C2, D1, D2)). It is possible to enhance and detect the skin surface and underlying vasculature in a first-person viewpoint.</p><figure class="figure text-xs" id="fig0060"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr12.jpg" height="645" alt="Fig. 12" aria-describedby="cap0060"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr12_lrg.jpg" target="_blank" download="" title="Download high-res image (515KB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (515KB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-gr12.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0060"><p id="sp0060"><span class="label">Fig. 12</span>. Segmentation of skin and blood vessels in 3D volumetric. Photograph of human palm (A), foot (B) with marked region of interest (ROI), represented by dash box; 3D PA images for separating skin and blood vessels areas inside the ROI for (C) human palm, (D) human foot. 3D cross section image at coronal plane (C1) and sagittal plane (C2) as marked in (C). 3D cross section image at coronal plane (D1) and sagittal plane (D2) as marked in (D). White dashed boxes in C1, C2, D1, D2 are the enlarged images of small dashed boxes in each figure. S: Skin and V: Vessel. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)</p></span></span></figure></div><div><p id="p0155">The following is the Supplementary material related to this article <a name="bec0005" href="#ec0005" class="workspace-trigger">Movie S1</a>, <a name="bec0010" href="#ec0010" class="workspace-trigger">Movie S2</a>.<span class="display"><span class="e-component e-component-mmc2" id="ec0005"><span class="article-attachment"><span class="video-player"><div class="ableplayer elsevierjsplayer "><div class="able-wrapper"><div class="able"><h4 class="able-offscreen">Media player</h4><div class="able-vidcap-container"><div class="able-media-container"><button class="able-big-play-button icon-play" aria-hidden="true" tabindex="-1" style="width: 548px; height: 312px;"></button><video crossorigin="anonymous" preload="auto" style="width: 100%; height: auto;" id="gemp_player_id_0_0_1649354383812" tabindex="-1"><source src="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-mmc2.mp4" type="video/mp4"><p><a class="icon-link" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-mmc2.mp4" title="Movie" target="_blank" rel="noreferrer noopener"><svg focusable="false" viewBox="0 0 128 128" width="24" height="24" class="icon icon-video-camera"><path d="m3e1 76h46v1e1h-46v-1e1zm82 8.24l-12-4.92v-14.64l12-4.92v24.48zm3.8-36.24c-0.86 0-1.72 0.17-2.56 0.51l-13.24 5.43v-0.94c0-8.28-6.72-15-15-15h-5.2l-5.62-16.6c-0.68-2.03-2.58-3.4-4.74-3.4h-49.44v1e1h45.86l6.78 2e1h12.36c2.76 0 5 2.24 5 5v4e1c0 2.76-2.24 5-5 5h-64c-2.76 0-5-2.24-5-5v-4e1c0-2.76 2.24-5 5-5h41.08l-3.4-1e1h-37.68c-8.28 0-15 6.72-15 15v4e1c0 8.28 6.72 15 15 15h64c8.28 0 15-6.72 15-15v-2.94l13.24 5.43c0.84 0.34 1.7 0.51 2.56 0.51 3.48 0 6.2-2.78 6.2-6.33v-35.34c0-3.55-2.72-6.33-6.2-6.33"></path></svg></a></p></video></div></div><div class="able-player able-video" role="region" aria-label="video player"><div class="able-now-playing" aria-live="assertive" aria-atomic="true"></div><div class="able-controller able-white-controls"><div id="gemp_player_id_0_0_1649354383812-tooltip" class="able-tooltip"></div><div class="able-left-controls"><button type="button" tabindex="0" aria-label="Play" class="able-button-handler-play"><span class="icon-play" aria-hidden="true"></span><span class="able-clipped">Play</span></button><button type="button" tabindex="0" aria-label="Restart" class="able-button-handler-restart"><span class="icon-restart" aria-hidden="true"></span><span class="able-clipped">Restart</span></button><button type="button" tabindex="0" aria-label="Rewind" class="able-button-handler-rewind"><span class="icon-rewind" aria-hidden="true"></span><span class="able-clipped">Rewind</span></button><button type="button" tabindex="0" aria-label="Forward" class="able-button-handler-forward"><span class="icon-forward" aria-hidden="true"></span><span class="able-clipped">Forward</span></button></div><div class="able-right-controls"><div class="able-seekbar-wrapper" style="width: 388px;"><div class="able-seekbar"><div role="tooltip" class="able-tooltip" style="display: none;"></div><div class="able-seekbar-loaded" style="width: 41.8532px;"></div><div class="able-seekbar-played" style="width: 0px;"></div><div orientation="horizontal" class="able-seekbar-head" tabindex="0" role="slider" aria-label="video timeline" aria-valuemin="0" aria-valuemax="60.032" aria-valuetext="0 seconds" aria-valuenow="0" style="left: -6.5px;"></div></div><span class="able-offscreen" aria-live="polite">0 seconds</span></div><button type="button" tabindex="0" aria-label="Volume" class="able-button-handler-volume" aria-controls="gemp_player_id_0_0_1649354383812-volume-slider" aria-describedby="gemp_player_id_0_0_1649354383812-volume-help"><span class="icon-volume-medium" aria-hidden="true"></span><span class="able-clipped">Volume</span></button><div id="gemp_player_id_0_0_1649354383812-volume-slider" class="able-volume-slider" aria-hidden="true"><div class="able-tooltip" role="tooltip"></div><div class="able-volume-track"><div class="able-volume-track able-volume-track-on" style="height: 35px; top: 15px;"></div><div class="able-volume-head" role="slider" aria-orientation="vertical" aria-label="Volume up down" aria-valuemin="0" aria-valuemax="10" aria-valuenow="7" tabindex="-1" aria-valuetext="70%" style="top: 8px;"></div></div><div class="able-offscreen" aria-live="assertive" aria-atomic="true">70%</div><div id="gemp_player_id_0_0_1649354383812-volume-help" class="able-volume-help">70%, Click to access volume slider</div></div></div><div style="clear:both;"></div><div class="able-left-controls"><button type="button" tabindex="0" aria-label="Slower" class="able-button-handler-slower"><span class="icon-slower" aria-hidden="true"></span><span class="able-clipped">Slower</span></button><button type="button" tabindex="0" aria-label="Faster" class="able-button-handler-faster"><span class="icon-faster" aria-hidden="true"></span><span class="able-clipped">Faster</span></button></div><div class="able-right-controls"><button type="button" tabindex="0" aria-label="Preferences" class="able-button-handler-preferences" aria-controls="gemp_player_id_0_0_1649354383812-prefs-menu"><span class="icon-preferences" aria-hidden="true"></span><span class="able-clipped">Preferences</span></button><button type="button" tabindex="0" aria-label="Enter full screen" class="able-button-handler-fullscreen"><span class="icon-fullscreen icon-fullscreen-expand" aria-hidden="true"></span><span class="able-clipped">Enter full screen</span></button></div><div style="clear:both;"></div><div id="gemp_player_id_0_0_1649354383812-prefs-menu" class="able-popup able-popup-no-radio"><ul><li><input type="radio" value="captions" name="gemp_player_id_0_0_1649354383812-prefs-choice" id="gemp_player_id_0_0_1649354383812-prefs-0"><label for="gemp_player_id_0_0_1649354383812-prefs-0">Captions</label></li><li><input type="radio" value="descriptions" name="gemp_player_id_0_0_1649354383812-prefs-choice" id="gemp_player_id_0_0_1649354383812-prefs-1"><label for="gemp_player_id_0_0_1649354383812-prefs-1">Descriptions</label></li><li><input type="radio" value="keyboard" name="gemp_player_id_0_0_1649354383812-prefs-choice" id="gemp_player_id_0_0_1649354383812-prefs-2"><label for="gemp_player_id_0_0_1649354383812-prefs-2">Keyboard</label></li><li><input type="radio" value="transcript" name="gemp_player_id_0_0_1649354383812-prefs-choice" id="gemp_player_id_0_0_1649354383812-prefs-3"><label for="gemp_player_id_0_0_1649354383812-prefs-3">Transcript</label></li></ul></div></div><div class="able-status-bar"><span class="able-timer"><span class="able-elapsedTime">0:00</span><span class="able-duration"> / 1:00</span></span><span class="able-speed" aria-live="assertive">Speed: 1x</span><span class="able-status" aria-live="polite">Stopped</span></div></div><div class="able-descriptions" aria-live="assertive" aria-atomic="true" style="display: none; font-family: sans-serif; font-size: 100%; color: white; background-color: black; opacity: 1;"></div><div role="alert" class="able-alert" style="top: 22441.9px;"></div><div role="alert" class="able-screenreader-alert"></div></div></div></div></span><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-mmc2.mp4" target="_blank" download="" title="Download video (94MB)"><span class="anchor-text">Download : <span class="download-link-title">Download video (94MB)</span></span></a></span><span class="captions"><span><p><span class="label">Movie S1</span>. </p></span></span></span></span><span class="display"><span class="e-component e-component-mmc3" id="ec0010"><span class="article-attachment"><span class="video-player"><div class="ableplayer elsevierjsplayer "><div class="able-wrapper"><div class="able"><h4 class="able-offscreen">Media player</h4><div class="able-vidcap-container"><div class="able-media-container"><button class="able-big-play-button icon-play" aria-hidden="true" tabindex="-1" style="width: 548px; height: 312px;"></button><video crossorigin="anonymous" preload="auto" style="width: 100%; height: auto;" id="gemp_player_id_1_0_1649354383813" tabindex="-1"><source src="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-mmc3.mp4" type="video/mp4"><p><a class="icon-link" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-mmc3.mp4" title="Movie" target="_blank" rel="noreferrer noopener"><svg focusable="false" viewBox="0 0 128 128" width="24" height="24" class="icon icon-video-camera"><path d="m3e1 76h46v1e1h-46v-1e1zm82 8.24l-12-4.92v-14.64l12-4.92v24.48zm3.8-36.24c-0.86 0-1.72 0.17-2.56 0.51l-13.24 5.43v-0.94c0-8.28-6.72-15-15-15h-5.2l-5.62-16.6c-0.68-2.03-2.58-3.4-4.74-3.4h-49.44v1e1h45.86l6.78 2e1h12.36c2.76 0 5 2.24 5 5v4e1c0 2.76-2.24 5-5 5h-64c-2.76 0-5-2.24-5-5v-4e1c0-2.76 2.24-5 5-5h41.08l-3.4-1e1h-37.68c-8.28 0-15 6.72-15 15v4e1c0 8.28 6.72 15 15 15h64c8.28 0 15-6.72 15-15v-2.94l13.24 5.43c0.84 0.34 1.7 0.51 2.56 0.51 3.48 0 6.2-2.78 6.2-6.33v-35.34c0-3.55-2.72-6.33-6.2-6.33"></path></svg></a></p></video></div></div><div class="able-player able-video" role="region" aria-label="video player"><div class="able-now-playing" aria-live="assertive" aria-atomic="true"></div><div class="able-controller able-white-controls"><div id="gemp_player_id_1_0_1649354383813-tooltip" class="able-tooltip"></div><div class="able-left-controls"><button type="button" tabindex="0" aria-label="Play" class="able-button-handler-play"><span class="icon-play" aria-hidden="true"></span><span class="able-clipped">Play</span></button><button type="button" tabindex="0" aria-label="Restart" class="able-button-handler-restart"><span class="icon-restart" aria-hidden="true"></span><span class="able-clipped">Restart</span></button><button type="button" tabindex="0" aria-label="Rewind" class="able-button-handler-rewind"><span class="icon-rewind" aria-hidden="true"></span><span class="able-clipped">Rewind</span></button><button type="button" tabindex="0" aria-label="Forward" class="able-button-handler-forward"><span class="icon-forward" aria-hidden="true"></span><span class="able-clipped">Forward</span></button></div><div class="able-right-controls"><div class="able-seekbar-wrapper" style="width: 388px;"><div class="able-seekbar"><div role="tooltip" class="able-tooltip" style="display: none;"></div><div class="able-seekbar-loaded" style="width: 63.4589px;"></div><div class="able-seekbar-played" style="width: 0px;"></div><div orientation="horizontal" class="able-seekbar-head" tabindex="0" role="slider" aria-label="video timeline" aria-valuemin="0" aria-valuemax="60.032" aria-valuetext="0 seconds" aria-valuenow="0" style="left: -6px;"></div></div><span class="able-offscreen" aria-live="polite"></span></div><button type="button" tabindex="0" aria-label="Volume" class="able-button-handler-volume" aria-controls="gemp_player_id_1_0_1649354383813-volume-slider" aria-describedby="gemp_player_id_1_0_1649354383813-volume-help"><span class="icon-volume-medium" aria-hidden="true"></span><span class="able-clipped">Volume</span></button><div id="gemp_player_id_1_0_1649354383813-volume-slider" class="able-volume-slider" aria-hidden="true"><div class="able-tooltip" role="tooltip"></div><div class="able-volume-track"><div class="able-volume-track able-volume-track-on" style="height: 35px; top: 15px;"></div><div class="able-volume-head" role="slider" aria-orientation="vertical" aria-label="Volume up down" aria-valuemin="0" aria-valuemax="10" aria-valuenow="7" tabindex="-1" aria-valuetext="70%" style="top: 8px;"></div></div><div class="able-offscreen" aria-live="assertive" aria-atomic="true">70%</div><div id="gemp_player_id_1_0_1649354383813-volume-help" class="able-volume-help">70%, Click to access volume slider</div></div></div><div style="clear:both;"></div><div class="able-left-controls"><button type="button" tabindex="0" aria-label="Slower" class="able-button-handler-slower"><span class="icon-slower" aria-hidden="true"></span><span class="able-clipped">Slower</span></button><button type="button" tabindex="0" aria-label="Faster" class="able-button-handler-faster"><span class="icon-faster" aria-hidden="true"></span><span class="able-clipped">Faster</span></button></div><div class="able-right-controls"><button type="button" tabindex="0" aria-label="Preferences" class="able-button-handler-preferences" aria-controls="gemp_player_id_1_0_1649354383813-prefs-menu"><span class="icon-preferences" aria-hidden="true"></span><span class="able-clipped">Preferences</span></button><button type="button" tabindex="0" aria-label="Enter full screen" class="able-button-handler-fullscreen"><span class="icon-fullscreen icon-fullscreen-expand" aria-hidden="true"></span><span class="able-clipped">Enter full screen</span></button></div><div style="clear:both;"></div><div id="gemp_player_id_1_0_1649354383813-prefs-menu" class="able-popup able-popup-no-radio"><ul><li><input type="radio" value="captions" name="gemp_player_id_1_0_1649354383813-prefs-choice" id="gemp_player_id_1_0_1649354383813-prefs-0"><label for="gemp_player_id_1_0_1649354383813-prefs-0">Captions</label></li><li><input type="radio" value="descriptions" name="gemp_player_id_1_0_1649354383813-prefs-choice" id="gemp_player_id_1_0_1649354383813-prefs-1"><label for="gemp_player_id_1_0_1649354383813-prefs-1">Descriptions</label></li><li><input type="radio" value="keyboard" name="gemp_player_id_1_0_1649354383813-prefs-choice" id="gemp_player_id_1_0_1649354383813-prefs-2"><label for="gemp_player_id_1_0_1649354383813-prefs-2">Keyboard</label></li><li><input type="radio" value="transcript" name="gemp_player_id_1_0_1649354383813-prefs-choice" id="gemp_player_id_1_0_1649354383813-prefs-3"><label for="gemp_player_id_1_0_1649354383813-prefs-3">Transcript</label></li></ul></div></div><div class="able-status-bar"><span class="able-timer"><span class="able-elapsedTime">0:00</span><span class="able-duration"> / 1:00</span></span><span class="able-speed" aria-live="assertive">Speed: 1x</span><span class="able-status" aria-live="polite">Stopped</span></div></div><div class="able-descriptions" aria-live="assertive" aria-atomic="true" style="display: none; font-family: sans-serif; font-size: 100%; color: white; background-color: black; opacity: 1;"></div><div role="alert" class="able-alert" style="top: 23008.5px;"></div><div role="alert" class="able-screenreader-alert"></div></div></div></div></span><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-mmc3.mp4" target="_blank" download="" title="Download video (84MB)"><span class="anchor-text">Download : <span class="download-link-title">Download video (84MB)</span></span></a></span><span class="captions"><span><p><span class="label">Movie S2</span>. </p></span></span></span></span>.</p></div><p id="p0160"><span>Further, for comparison of the visibility of the structures in PA image, the peak signal-to-noise ratio (PSNR) between the B-scan <a href="/topics/medicine-and-dentistry/afterimage" title="Learn more about image after from ScienceDirect's AI-generated Topic Pages" class="topic-link">image after</a> and before segmentation was approximately 21.3 dB (also see </span><a name="bsec0105" href="#sec0105" class="workspace-trigger">Supplementary Fig. S3</a>). PSNR is defined in the following <a name="beqn0045" href="#eqn0045" class="workspace-trigger">Eq. 9</a>:<span class="display"><span id="eqn0045" class="formula"><span class="label">(9)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-12-Frame" tabindex="0" style="font-size: 90%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>PSNR</mi><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>20</mn><mo is=&quot;true&quot;>*</mo><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>log</mi></mrow><mrow is=&quot;true&quot;><mn is=&quot;true&quot;>10</mn></mrow></msub><mrow is=&quot;true&quot;><mfenced open=&quot;(&quot; close=&quot;)&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><mfrac is=&quot;true&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>MAX</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>I</mi></mrow></msub></mrow><mrow is=&quot;true&quot;><msqrt is=&quot;true&quot;><mrow is=&quot;true&quot;><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>MSE</mi></mrow></msqrt></mrow></mfrac></mrow></mfenced></mrow></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="27.766ex" height="4.549ex" viewBox="0 -1217.1 11954.9 1958.7" role="img" focusable="false" style="vertical-align: -1.722ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-50"></use><use xlink:href="#MJMATHI-53" x="642" y="0"></use><use xlink:href="#MJMATHI-4E" x="1256" y="0"></use><use xlink:href="#MJMATHI-52" x="2059" y="0"></use></g><g is="true" transform="translate(3096,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(4153,0)"><use xlink:href="#MJMAIN-32"></use><use xlink:href="#MJMAIN-30" x="500" y="0"></use></g><g is="true" transform="translate(5376,0)"><use xlink:href="#MJMAIN-2A"></use></g><g is="true" transform="translate(6099,0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-6C"></use><use xlink:href="#MJMATHI-6F" x="298" y="0"></use><use xlink:href="#MJMATHI-67" x="784" y="0"></use></g></g><g is="true" transform="translate(1261,-242)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use><use transform="scale(0.707)" xlink:href="#MJMAIN-30" x="500" y="0"></use></g></g></g><g is="true" transform="translate(8168,0)"><g is="true"><use xlink:href="#MJSZ2-28"></use><g is="true" transform="translate(597,0)"><g is="true"><g transform="translate(120,0)"><rect stroke="none" width="2351" height="60" x="0" y="220"></rect><g is="true" transform="translate(112,515)"><g is="true"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-4D"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-41" x="970" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-58" x="1720" y="0"></use></g></g><g is="true" transform="translate(1802,-107)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-49"></use></g></g></g></g><g is="true" transform="translate(60,-551)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-221A" x="0" y="45"></use><rect stroke="none" width="1642" height="42" x="589" y="556"></rect><g transform="translate(589,0)"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-4D"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-53" x="970" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-45" x="1583" y="0"></use></g></g></g></g></g></g></g></g><use xlink:href="#MJSZ2-29" x="3189" y="-1"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi mathvariant="italic" is="true">PSNR</mi><mo linebreak="goodbreak" is="true">=</mo><mn is="true">20</mn><mo is="true">*</mo><msub is="true"><mrow is="true"><mi mathvariant="italic" is="true">log</mi></mrow><mrow is="true"><mn is="true">10</mn></mrow></msub><mrow is="true"><mfenced open="(" close=")" is="true"><mrow is="true"><mfrac is="true"><mrow is="true"><msub is="true"><mrow is="true"><mi mathvariant="italic" is="true">MAX</mi></mrow><mrow is="true"><mi is="true">I</mi></mrow></msub></mrow><mrow is="true"><msqrt is="true"><mrow is="true"><mi mathvariant="italic" is="true">MSE</mi></mrow></msqrt></mrow></mfrac></mrow></mfenced></mrow></mrow></math></span></span><script type="math/mml" id="MathJax-Element-12"><math><mrow is="true"><mi mathvariant="italic" is="true">PSNR</mi><mo linebreak="goodbreak" is="true">=</mo><mn is="true">20</mn><mo is="true">*</mo><msub is="true"><mrow is="true"><mi mathvariant="italic" is="true">log</mi></mrow><mrow is="true"><mn is="true">10</mn></mrow></msub><mrow is="true"><mfenced open="(" close=")" is="true"><mrow is="true"><mfrac is="true"><mrow is="true"><msub is="true"><mrow is="true"><mi mathvariant="italic" is="true">MAX</mi></mrow><mrow is="true"><mi is="true">I</mi></mrow></msub></mrow><mrow is="true"><msqrt is="true"><mrow is="true"><mi mathvariant="italic" is="true">MSE</mi></mrow></msqrt></mrow></mfrac></mrow></mfenced></mrow></mrow></math></script></span></span></span>where MAX<sub>I</sub> is the maximum pixel value of the image (in this case is 255), MSE is mean squared error between the reconstructed PA image before and after segmentation.</p></section></section><section id="sec0080"><h2 id="sect0095" class="u-h3 u-margin-l-top u-margin-xs-bottom">4. Discussion</h2><p id="p0165"><span>In summary, we designed the DL <a href="/topics/computer-science/network-architecture" title="Learn more about network architecture from ScienceDirect's AI-generated Topic Pages" class="topic-link">network architecture</a><span> for blood <a href="/topics/computer-science/vessel-segmentation" title="Learn more about vessel segmentation from ScienceDirect's AI-generated Topic Pages" class="topic-link">vessel segmentation</a><span> in in vivo <a href="/topics/medicine-and-dentistry/photoacoustic-microscopy" title="Learn more about PAM from ScienceDirect's AI-generated Topic Pages" class="topic-link">PAM</a><span> imaging. The advantage of this proposed Slide-U-Net approach to learn how to reconstruct and segment images in 3D <a href="/topics/computer-science/volumetric-data" title="Learn more about volumetric data from ScienceDirect's AI-generated Topic Pages" class="topic-link">volumetric data</a>, which might cause mixture signal by using threshold, gate selection and local MAP method. The network architectures require more training time, depending on the number of layers and training parameters, but it gives a segmentation by using the trained model in a few seconds. Our results show a good performance segmentation in two types of PA samples (</span></span></span></span><a name="bfig0060" href="#fig0060" class="workspace-trigger">Fig. 12</a>(A) and (B)) in high-resolution (2500 × 2000 × 1200 in pixel). Slide-U-Net model is not dependent on the size of the input image. Many other studies are reported for image in small resolution (depending on model requirements). Therefore, the segmentation in Slide-U-Net without using the downsize method enables full view with small vessels reconstructing features.</p><p id="p0170"><span>However, there are several restrictions Slide-U-Net algorithm. Firstly, although the sample data (60 full-size B-scan images) in our research is moderately sufficient enough to support the training of the network, the number of data is still limited. Additionally, in data acquisition, our method still has not focused on the impact of <a href="/topics/physics-and-astronomy/ultrasonics" title="Learn more about ultrasonic from ScienceDirect's AI-generated Topic Pages" class="topic-link">ultrasonic</a> frequency, optical wavelength, and scanning method on PAM </span><a href="/topics/computer-science/imaging-systems" title="Learn more about imaging system from ScienceDirect's AI-generated Topic Pages" class="topic-link">imaging system</a><span><span><span><span>. Hence, we plan to conduct more experimental study with more sample data and analyze other effects which have been mentioned above. Secondly, signal processing should be considered for the experimental study. At present, the <a href="/topics/computer-science/segmentation-model" title="Learn more about segmentation model from ScienceDirect's AI-generated Topic Pages" class="topic-link">segmentation model</a> uses the raw data without filtering and </span><a href="/topics/computer-science/signal-denoising" title="Learn more about denoising signal from ScienceDirect's AI-generated Topic Pages" class="topic-link">denoising signal</a><span>, which may have some effects on the results. Therefore, we are planning to implement signal processing methods in future study. Thirdly, <a href="/topics/computer-science/manual-segmentation" title="Learn more about manual segmentation from ScienceDirect's AI-generated Topic Pages" class="topic-link">manual segmentation</a> of the skin and </span></span><a href="/topics/medicine-and-dentistry/microvessel" title="Learn more about microvasculature from ScienceDirect's AI-generated Topic Pages" class="topic-link">microvasculature</a><span> requires an experience researcher or clinical expert in <a href="/topics/medicine-and-dentistry/photoacoustic-imaging" title="Learn more about photoacoustic imaging from ScienceDirect's AI-generated Topic Pages" class="topic-link">photoacoustic imaging</a>. Moving forward, to keep the fully sampled image size, the segmentation procedure for </span></span><a href="/topics/computer-science/ground-truth-image" title="Learn more about ground truth image from ScienceDirect's AI-generated Topic Pages" class="topic-link">ground truth image</a><span> dataset may take hours. Finally, our method automatically calculated the stride of sliding window extraction to extract overlap the input image for prediction and reconstruction. If the size of the input image is a prime number, the stride will be one. It can take a longer time for extraction and out of memory when we fed sub-dataset into the model. It will slightly affect the performance of the Slide-U-Net <a href="/topics/computer-science/automatic-segmentation" title="Learn more about automatic segmentation from ScienceDirect's AI-generated Topic Pages" class="topic-link">automatic segmentation</a> algorithm in photoacoustic imaging.</span></span></p></section><section id="sec0085"><h2 id="sect0100" class="u-h3 u-margin-l-top u-margin-xs-bottom">5. Conclusions</h2><p id="p0175"><span>In conclusion, we were able to successfully apply <a href="/topics/computer-science/deep-learning-model" title="Learn more about DL model from ScienceDirect's AI-generated Topic Pages" class="topic-link">DL model</a><span> in reconstructing and segmenting the full-view imaging of <a href="/topics/medicine-and-dentistry/photoacoustic-microscopy" title="Learn more about PAM from ScienceDirect's AI-generated Topic Pages" class="topic-link">PAM</a>. In this study, we have tested and compared on different models and found that U-Net architecture demonstrated the best performance (as described in </span></span><a name="btbl0005" href="#tbl0005" class="workspace-trigger">Table 1</a><span>). Our Slide-U-Net model outperformed all scanning step-size imaging datasets. The purposed <a href="/topics/computer-science/image-segmentation" title="Learn more about image segmentation from ScienceDirect's AI-generated Topic Pages" class="topic-link">image segmentation</a><span><span> techniques are fast and accurate and could help clinical experts in the diagnosis of <a href="/topics/medicine-and-dentistry/microvessel" title="Learn more about microvasculature from ScienceDirect's AI-generated Topic Pages" class="topic-link">microvasculature</a>. Furthermore, the results provide a 3D volumetric segmentation image in NRRD file, which is a common type of </span><a href="/topics/computer-science/data-type" title="Learn more about file format from ScienceDirect's AI-generated Topic Pages" class="topic-link">file format</a> for scientific and medical visualization and could be opened by various medical 3D viewer software.</span></span></p><p id="p0180"><span>In the future, the proposed models should be improved in image analysis, along with other modalities of the PAM imaging such <a href="/topics/chemistry/lipid-a" title="Learn more about as lipids from ScienceDirect's AI-generated Topic Pages" class="topic-link">as lipids</a><span>, tumor cells, <a href="/topics/medicine-and-dentistry/oxygen-saturation" title="Learn more about oxygen saturation from ScienceDirect's AI-generated Topic Pages" class="topic-link">oxygen saturation</a>, </span></span><a href="/topics/medicine-and-dentistry/nodular-melanoma" title="Learn more about melanoma from ScienceDirect's AI-generated Topic Pages" class="topic-link">melanoma</a>, and organs. Also, we plan to upgrade the network by incorporating super-resolution training in enhancement of PA images, which can define native image resolution on smaller tissue structures.</p></section><section id="sec0090"><h2 id="sect0105" class="u-h3 u-margin-l-top u-margin-xs-bottom">Author contribution</h2><p id="p0185">C.D.L programmed, designed the <a href="/topics/computer-science/deep-learning-model" title="Learn more about DL model from ScienceDirect's AI-generated Topic Pages" class="topic-link">DL model</a><span>, trained, tested, and valuated the data, reconstructed images, as well as prepared the figures for the manuscript. V.T.N, and T.T.H.V acquired the in vivo <a href="/topics/medicine-and-dentistry/photoacoustic-microscopy" title="Learn more about PAM from ScienceDirect's AI-generated Topic Pages" class="topic-link">PAM</a> data, and manually labeled dataset. T.H.V programmed the 3D visualization software. S.M revised the manuscript, interpreted the data. V.T.N, S.P, J.C performed the experiment. J.O and C.S.K conceived and supervised the project. All authors contributed to critical reading of the manuscript.</span></p></section></div><section id="coi0005"><h2 id="sect0110" class="u-h3 u-margin-l-top u-margin-xs-bottom">Declaration of competing interest</h2><p id="p0190">The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p></section><section id="ack0005"><h2 id="sect0115" class="u-h3 u-margin-l-top u-margin-xs-bottom">Acknowledgment</h2><p id="p0195">This research was supported by the Engineering Research Center of Excellence (ERC) Program supported by the <span id="gs1">National Research Foundation</span> (NRF) of the Korean Ministry of Science, ICT and Future Planning (MSIP) (<a href="#gs1">NRF-2021R1A5A1032937</a>).</p><p id="p0200">This work was supported by <span id="gs2">Institute of Information &amp; Communications Technology Planning &amp; Evaluation</span> (IITP) grant funded by the Korea government (MSIT) (No. <a href="#gs2">2021-0-01914</a>, Development of Welding Inspection Automation and Monitoring System Based on AI laser vision sensor).</p></section><div class="Appendices"><section id="sec0105"><h2 id="sect0125" class="u-h3 u-margin-l-top u-margin-xs-bottom">Appendix A. Supplementary material</h2><span class="download-all-supplemental-data"><span class="article-attachment"><form method="post" action="/sdfe/pdf/download/S2213597921000707/attachments"><input name="eids" type="hidden" value="1-s2.0-S2213597921000707-mmc2.mp4"><input name="eids" type="hidden" value="1-s2.0-S2213597921000707-mmc3.mp4"><input name="eids" type="hidden" value="1-s2.0-S2213597921000707-mmc1.docx"><button class="button-link button-link-secondary u-font-sans" type="submit"><svg focusable="false" viewBox="0 0 98 128" width="18.375" height="24" class="icon icon-download"><path d="m77.38 56.18l-6.6-7.06-16.78 17.24v-40.36h-1e1v40.34l-17.72-17.24-7.3 7.08 29.2 29.32 29.2-29.32m10.62 17.82v2e1h-78v-2e1h-1e1v3e1h98v-3e1h-1e1"></path></svg><span class="button-link-text"><span class="download-all-title">Download all </span>supplementary files<span class="desktop-text"> included with this article</span></span></button></form><a class="anchor help-link move-right u-font-sans u-margin-0-bottom" href="https://service.elsevier.com/app/answers/detail/a_id/19286/supporthub/sciencedirect/" title="Help (Opens in new window)" target="_blank"><span class="anchor-text">Help</span></a></span></span><p id="p0210"><span class="display"><span class="e-component e-component-mmc1" id="ec0015"><span class="article-attachment"><a class="icon-link" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-mmc1.docx" title="Download Word document (2MB)" target="_blank" rel="noreferrer noopener"><svg focusable="false" viewBox="0 0 94 128" width="17.625" height="24" class="icon icon-text-document"><path d="m35.6 1e1c-5.38 0-10.62 1.92-14.76 5.4-9.1 7.68-18.84 20.14-18.84 32.1v70.5h9e1v-15.99-2.01-4e1 -17.64-32.36h-56.4zm0 1e1h46.4v22.36 17.64 4e1 2.01 5.99h-7e1v-49c0-6.08 4.92-11 11-11h17v-2e1h-6c-2.2 0-4 1.8-4 4v6h-7c-3.32 0-6.44 0.78-9.22 2.16 2.46-5.62 7.28-11.86 13.5-17.1 2.34-1.98 5.3-3.06 8.32-3.06zm-13.6 38v1e1h5e1v-1e1h-5e1zm0 2e1v1e1h5e1v-1e1h-5e1z"></path></svg></a><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S2213597921000707-mmc1.docx" target="_blank" download="" title="Download Word document (2MB)"><span class="anchor-text">Download : <span class="download-link-title">Download Word document (2MB)</span></span></a></span><span class="captions"><span id="cap0075"><p id="sp0080">Supplementary material.</p></span></span></span></span>.</p></section></div></div>