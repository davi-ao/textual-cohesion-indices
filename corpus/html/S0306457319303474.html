<div class="Body u-font-serif" id="body"><div><section id="sec0001"><h2 id="sctt0004" class="u-h3 u-margin-l-top u-margin-xs-bottom">1. Introduction</h2><p id="p0005"><span>With the advancement of technology, a huge amount of information is floating around the Web which is expressed in <a href="/topics/computer-science/natural-languages" title="Learn more about natural language from ScienceDirect's AI-generated Topic Pages" class="topic-link">natural language</a>. Detecting the sense of a word is a primary step for natural language understanding. Researchers have tried to detect the sense of words from a given corpus in both supervised and unsupervised ways. One stream of work deals with the task of word sense induction (WSI), the goal of which is to automatically induce different senses of a given word, generally in the form of an </span><a href="/topics/computer-science/unsupervised-learning" title="Learn more about unsupervised learning from ScienceDirect's AI-generated Topic Pages" class="topic-link">unsupervised learning</a> task with senses represented as clusters of words. The word sense disambiguation (WSD) task opens up another stream of literature, where a fixed sense inventory is assumed to exist, and the senses of a given word are disambiguated using the sense inventory as a reference. However, in both of these tasks, the assumption is that the number of senses that a word has is static. In addition, the senses do exist in the sense inventory to compare with for these tasks. They attempt to detect or induce one of these senses depending on the context.</p><p id="p0006">Natural language, however, is dynamic and is constantly evolving as per the users’ needs which leads to continuous changes of word meanings over time. For example, by late 20th century, the word ‘virus’ has come up with the ‘technology’ related sense whereas the word ‘cool’ has emerged with ‘smart, calm personality’ related sense. How to automatically detect such changes? Given sufficient time-stamped data, can one design efficient algorithms to detect known as well as unknown shifts in word meanings highly precisely? Such automation can directly benefit people such as librarians, historians or <a href="/topics/social-sciences/linguists" title="Learn more about linguists from ScienceDirect's AI-generated Topic Pages" class="topic-link">linguists</a><span><span> who work with digitized texts from different time periods. The variation in the sense of a word could either be attributed to the emergence of a completely new sense of the word or change of usage of a well-established sense of the word. This semantic evolution of a word over time is of great interest to <a href="/topics/social-sciences/diachronic-linguistics" title="Learn more about historical linguistics from ScienceDirect's AI-generated Topic Pages" class="topic-link">historical linguistics</a>. Besides, </span><a href="/topics/social-sciences/lexicography" title="Learn more about lexicography from ScienceDirect's AI-generated Topic Pages" class="topic-link">lexicography</a> is also expensive; compiling, editing and updating sense inventory entries frequently remains cumbersome and labor-intensive.</span></p><p id="p0007"><span><span>In general, detecting time-specific knowledge would make word meaning representations more accurate and hence, is a worthy problem to study for specialists such as etymologists, librarians, general public and NLP researchers. A well constructed <a href="/topics/computer-science/semantic-representation" title="Learn more about semantic representation from ScienceDirect's AI-generated Topic Pages" class="topic-link">semantic representation</a> of a word is useful for many </span><a href="/topics/computer-science/natural-language-processing" title="Learn more about natural language processing from ScienceDirect's AI-generated Topic Pages" class="topic-link">natural language processing</a> or </span><a href="/topics/computer-science/information-retrieval-systems" title="Learn more about information retrieval systems from ScienceDirect's AI-generated Topic Pages" class="topic-link">information retrieval systems</a><span> like machine translation, <a href="/topics/computer-science/semantic-search" title="Learn more about semantic search from ScienceDirect's AI-generated Topic Pages" class="topic-link">semantic search</a>, disambiguation, Q&amp;A, etc. Taking into account the newer senses of a word can increase the relevance of the query result leading to a better semantic search. Similarly, a sense disambiguation engine informed with the newer senses of a word can increase the efficiency of disambiguation; it can recognize senses not available in sense inventory that would otherwise be wrongly assigned to any of the available senses from the inventory. Above all, a system having the ability to perceive the novel sense of a word can help in an automatic sense inventory update by taking into account the temporal scope of senses.</span></p><section id="sec0002"><h3 id="sctt0005" class="u-h4 u-margin-m-top u-margin-xs-bottom">1.1. Recent advancements</h3><p id="p0008">Investigations of individual words or phrases were very limited due to the need for huge human involvement until now. Recently, with the arrival of large-scale collections of historic texts and online libraries such as Google books, a new paradigm has been added to this research area, whereby the prime interest is in identifying the temporal scope of a sense&nbsp;(<a name="bbib0023" href="#bib0023" class="workspace-trigger">Gulordava, Baroni, 2011</a>, <a name="bbib0027" href="#bib0027" class="workspace-trigger">Jatowt, Duh, 2014</a>, <a name="bbib0033" href="#bib0033" class="workspace-trigger">Lau, Cook, McCarthy, Gella, Baldwin, 2014</a>, <a name="bbib0050" href="#bib0050" class="workspace-trigger">Tahmasebi, Risse, Dietze, 2011</a>) which, in turn, can give further insights to the phenomenon of language evolution. Some recent attempts&nbsp;(<a name="bbib0016" href="#bib0016" class="workspace-trigger">Eger, Mehler, 2016</a>, <a name="bbib0020" href="#bib0020" class="workspace-trigger">Frermann, Lapata, 2016</a>, <a name="bbib0024" href="#bib0024" class="workspace-trigger">Hamilton, Leskovec, Jurafsky, 2016a</a>, <a name="bbib0025" href="#bib0025" class="workspace-trigger">Hamilton, Leskovec, Jurafsky, 2016b</a>, <a name="bbib0030" href="#bib0030" class="workspace-trigger">Kulkarni, Al-Rfou, Perozzi, Skiena, 2015</a>) have been made to model the dynamics of language in terms of word senses.</p><p id="p0009">One of the studies in this area has been presented by <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a><span> where the authors show that at earlier times, the sense of the word ‘sick’ was mostly associated to some form of illness; however, over the years, a new sense associating the same word to something that is ‘cool’ or ‘crazy’ has emerged. Their study is based on a unique network representation of the corpus called a distributional thesauri (DT) network built using Google books <a href="/topics/computer-science/syntactics" title="Learn more about syntactic from ScienceDirect's AI-generated Topic Pages" class="topic-link">syntactic</a><span> n-grams. They have used unsupervised <a href="/topics/computer-science/clustering-technique" title="Learn more about clustering techniques from ScienceDirect's AI-generated Topic Pages" class="topic-link">clustering techniques</a> to induce a sense of a word and then compared the induced senses of two time periods to get the new sense for a particular target word.</span></span></p></section><section id="sec0003"><h3 id="sctt0006" class="u-h4 u-margin-m-top u-margin-xs-bottom">1.2. Limitations of the recent approaches</h3><p id="p0010">While <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a> reported a precision close to 0.6 over a random sample of 49 words, we take another random sample of 100 words separately and repeat manual evaluation. When we extract the novel senses by comparing the DTs from 1909–1953 and 2002–2005, the precision obtained for these 100 words is as low as 0.32. Similarly, if we extract the novel senses comparing the DTs of 1909–1953 with 2006–2008, the precision stands at 0.23. We then explore another unsupervised approach presented in <a name="bbib0033" href="#bib0033" class="workspace-trigger">Lau&nbsp;et&nbsp;al.&nbsp;(2014)</a> over the same Google books corpus,<a name="bfn0001" href="#fn0001" class="workspace-trigger"><sup>1</sup></a> apply topic modeling for sense induction and directly adapt their similarity measure to get the new senses. Using a set intersecting with the 100 random samples for <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a>, we obtain the precision values of 0.21 and 0.28, respectively. Clearly, none of the precision values are good enough for reliable novel sense detection. Thus, the primary motivation of this work is to devise an approach that is able to boost the precision values to an acceptable range. However, the idea is not to build the entire framework from scratch but to carefully re-engineer the algorithm presented by <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a>. Precisely, we show how we can take extreme advantage of the differences in certain properties of the networks that the authors had originally built to detect sense changes. Note that these properties were completely overlooked in the original approach and our main contribution is to unfold their tremendous benefit in improving the precision of novel sense detection.</p><p id="p0011">It is well known that network science has proved to be very effective in addressing problems related to various complex phenomena including the structure and dynamics of the human brain, the functions of genetic pathways, the social behavior of humans in the online and offline world and many more. Some recent work shows that complex network concepts are being applied to understand human languages as well&nbsp;(<a name="bbib0001" href="#bib0001" class="workspace-trigger">Antiqueira, Nunes, Oliveira&nbsp;Jr, Costa, 2007</a>, <a name="bbib0010" href="#bib0010" class="workspace-trigger">Ferrer i Cancho, Capocci, Caldarelli, 2007</a>). The ability to access embedded knowledge makes complex networks extremely promising for natural language processing which normally requires deep knowledge representation. Many works exist where network properties are applied to natural language processing tasks, which lead to elegant solutions to the problem. Examples include word co-occurrence network&nbsp;(<a name="bbib0011" href="#bib0011" class="workspace-trigger">Ferrer&nbsp;i&nbsp;Cancho &amp; Solé, 2001</a>), word association network&nbsp;(<a name="bbib0007" href="#bib0007" class="workspace-trigger">Bonneau,&nbsp;Just, &amp; Matthews, 2010</a><span>), <a href="/topics/computer-science/syntactic-dependency" title="Learn more about syntactic dependency from ScienceDirect's AI-generated Topic Pages" class="topic-link">syntactic dependency</a> network&nbsp;(</span><a name="bbib0009" href="#bib0009" class="workspace-trigger">Ferrer&nbsp;i&nbsp;Cancho,&nbsp;2004</a>), etc. Some other applications of complex networks in NLP include ways to evaluate machine-generated summaries&nbsp;(<a name="bbib0040" href="#bib0040" class="workspace-trigger">Pardo,&nbsp;Antiqueira, Nunes, Oliveira&nbsp;Jr, &amp; da&nbsp;Fontoura&nbsp;Costa, 2006</a>), detection of ambiguity in a text&nbsp;(<a name="bbib0015" href="#bib0015" class="workspace-trigger">Dorow&nbsp;et&nbsp;al., 2004</a>), etc. These works constitute our prime motivation to apply network science methods to enhance the precision of novel word sense detection.</p></section><section id="sec0004"><h3 id="sctt0007" class="u-h4 u-margin-m-top u-margin-xs-bottom">1.3. Our proposal and the encouraging results</h3><p id="p0012">We propose a supervised method based on the network features to reduce the number of false positives and thereby, increase the overall precision of the method proposed by <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a>. As per <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a>, the basic idea is to prepare Distributional Thesaurus networks from a corpus that covers old and new time periods, cluster the network around target word to obtain the sense clusters in both the time periods and then do a cluster comparison to find out the sense cluster from the new time period to have a ‘birth’ sense for the target word which is not present in the old time period. Now, if a target word qualifies as having a new sense (‘birth’) as per their method, we construct two induced subgraphs of those words that form the cluster corresponding to this ‘birth’ sense, from the corresponding distributional thesauri (DT) networks of the two time periods. Next, we compare the following three network properties: (i) the edge density (ED), (ii) the structural similarity (SS) and (iii) the average path length (APL)&nbsp;(<a name="bbib0053" href="#bib0053" class="workspace-trigger">Turnu, Marchesi, Tonelli, 2012</a>, <a name="bbib0055" href="#bib0055" class="workspace-trigger">Wasserman, Faust, 1994</a><span><span>) of the two induced subgraphs from the two time periods. A remarkable observation is that although this is a small set of only three features, for the actual ‘birth’ cases, each of them has a significantly different value for the later time point and are therefore very discriminative indicators. In fact, the features are so powerful that even a small set of training instances is sufficient for making highly accurate predictions. We pose this problem as a binary <a href="/topics/computer-science/classification" title="Learn more about classification from ScienceDirect's AI-generated Topic Pages" class="topic-link">classification</a> task where we get the best results for </span><a href="/topics/computer-science/support-vector-machine" title="Learn more about Support Vector Machine from ScienceDirect's AI-generated Topic Pages" class="topic-link">Support Vector Machine</a><span> (SVM) <a href="/topics/computer-science/classification-machine-learning" title="Learn more about classifier from ScienceDirect's AI-generated Topic Pages" class="topic-link">classifier</a> fed with the fractional change of ED, SS, and APL over time as features.</span></span></p><p id="p0013"><strong>Preparation of gold standard dataset</strong>: In order to evaluate our model, we prepare a gold standard dataset through human annotations. As far as we are aware of the literature, there are no such gold standard datasets (even âǣsilver annotationsâǥ) available, which in turn makes the evaluation task difficult for this particular problem of novel sense detection. This concern is also discussed in detail in the recent surveys&nbsp;(<a name="bbib0031" href="#bib0031" class="workspace-trigger">Kutuzov, Øvrelid, Szymanski, Velldal, 2018</a>, <a name="bbib0049" href="#bib0049" class="workspace-trigger">Tahmasebi, Borin, Jatowt, 2018</a>). In most of the studies dealing with this task, researchers take some example words known to have emerged with new sense and try to model their characteristics over time. On the other hand, the datasets for evaluating tasks like word sense disambiguation or word sense induction do not contain the time information. Considering all these issues, we introduce a carefully prepared gold standard dataset. Note that this gold standard dataset consists of 365 words (nouns extracted from the torso region of word frequency as per Google books corpus), 184 for 1909–1953&nbsp;vs 2002–2005 and 181 for 1909–1953&nbsp;vs 2006–2008. This dataset is one of our contributions as well which will help the community to move further in this otherwise difficult task.</p><p id="p0014"><strong>Results:</strong> Evaluation using this gold standard dataset shows that this classification achieves an overall precision of 0.86 and 0.74 for the two time point pairs over the same set of samples, in contrast with the precision values of 0.32 and 0.23 by the original method. Note that we would like to stress here that an improvement of <strong>more than double</strong> in the precision of novel sense detection that we achieve has the potential to be the new stepping stone in many NLP and IR applications that are sensitive to novel senses of a word.</p></section><section id="sec0005"><h3 id="sctt0008" class="u-h4 u-margin-m-top u-margin-xs-bottom">1.4. Inspection with network embeddings</h3><p id="p0015">In addition to exploring the usefulness of network measures obtained from the DT networks, we also investigate the effect of using network representation learning methods. For that purpose we produce network embeddings to map the DT from the network space to the vector space using Deepwalk&nbsp;(<a name="bbib0042" href="#bib0042" class="workspace-trigger">Perozzi,&nbsp;Al-Rfou, &amp; Skiena, 2014</a>) and node2vec&nbsp;(<a name="bbib0022" href="#bib0022" class="workspace-trigger">Grover &amp; Leskovec,&nbsp;2016</a>). We propose two measures – Intra-cluster Average Similarity (IAS) and Average Similarity with Target word (AST) computed from the network embeddings, and apply fractional change of these two measures as features in the classifier. We find that using these two features or a combination of these features along with the network features (ED, SS, APL) in the classifier helps to improve precision in some cases but is not able to beat the overall F-measure values of the classifier fed with only network features (ED, SS, APL).</p></section><section id="sec0006"><h3 id="sctt0009" class="u-h4 u-margin-m-top u-margin-xs-bottom">1.5. Inspection with FastText embeddings</h3><p id="p0016"><span>We further investigate the usefulness of <a href="/topics/computer-science/word-embeddings" title="Learn more about word embeddings from ScienceDirect's AI-generated Topic Pages" class="topic-link">word embeddings</a> obtained using FastText&nbsp;(</span><a name="bbib0006" href="#bib0006" class="workspace-trigger">Bojanowski,&nbsp;Grave, Joulin, &amp; Mikolov, 2017</a>) trained on the corpus from two different time periods. We use the same two measures as discussed before – Intra-cluster Average Similarity (IAS) and Average Similarity with Target word (AST) but computed using FastText embeddings, and apply fractional change of these two measures as features in the classifier. In this scenario as well, we observe that using these two features or a combination of these features along with the network features (ED, SS, APL) in the classifier helps to improve precision in some cases but is not able to beat the overall F-measure values of the classifier fed with only network features (ED, SS, APL).</p></section><section id="sec0007"><h3 id="sctt0010" class="u-h4 u-margin-m-top u-margin-xs-bottom">1.6. Detecting known shifts</h3><p id="p0017">Further, we also investigate the robustness of our approach by analyzing the ability to capture known historical shifts in meaning. Preparing a list of words that have been suggested by different prior works as having undergone sense change, we see that 80% of those words get detected by our approach. We believe that the ability to detect such diachronic shifts in data can significantly enhance various standard studies in natural language evolution and change.</p><p id="p0018">The work presented here is an extension of <a name="bbib0026" href="#bib0026" class="workspace-trigger">Jana,&nbsp;Mukherjee, and Goyal&nbsp;(2019)</a>. The novel aspects and contributions of this paper with respect to the conference version are (a) it is an extended version of the conference paper with a detailed explanation of the baselines, dataset description, proposed methodology, extensive feature analysis along with illustrative examples and (b) in addition to applying only complex network measures, we also investigate the applicability of network representation learning methods and FastText embedding methods for the task of precise novel sense detection.</p></section></section><section id="sec0008"><h2 id="sctt0011" class="u-h3 u-margin-l-top u-margin-xs-bottom">2. Related work</h2><p id="p0019">Word sense induction and word sense disambiguation are the broad problems that deal with the detection of word senses. Some of the first attempts were made by <a name="bbib0036" href="#bib0036" class="workspace-trigger">Mihalcea&nbsp;and Moldovan&nbsp;(1999)</a> where they proposed an approach to automatically generate an arbitrarily large corpus for word senses using the information provided in WordNet and the information gathered from Web using existing search engines. <a name="bbib0047" href="#bib0047" class="workspace-trigger">Sahlgren&nbsp;(2002)</a><span> tried to build a model of <a href="/topics/computer-science/semantic-knowledge" title="Learn more about semantic knowledge from ScienceDirect's AI-generated Topic Pages" class="topic-link">semantic knowledge</a><span> using random indexing, which is able to acquire ambiguous <a href="/topics/computer-science/semantic-information" title="Learn more about semantic information from ScienceDirect's AI-generated Topic Pages" class="topic-link">semantic information</a> in an unsupervised fashion from unstructured text data. Recently, </span></span><a name="bbib0056" href="#bib0056" class="workspace-trigger">Wu&nbsp;and Giles&nbsp;(2015)</a> proposed a multi-prototype model for word representation using Wikipedia, namely SaSA, that could give more accurate sense-specific representation to words with multiple senses. Another stream of literature focuses on inducing senses of words by using clustering approaches with different context representations. <a name="bbib0039" href="#bib0039" class="workspace-trigger">Pantel&nbsp;and Lin&nbsp;(2002)</a><span> presented a <a href="/topics/computer-science/clustering-algorithm" title="Learn more about clustering algorithm from ScienceDirect's AI-generated Topic Pages" class="topic-link">clustering algorithm</a>, CBC (Clustering By Committee) to automatically discover senses from the text. In a similar line, </span><a name="bbib0014" href="#bib0014" class="workspace-trigger">Dorow&nbsp;and Widdows&nbsp;(2003)</a> came up with an iterative clustering-based method on the word-relation graph. <a name="bbib0008" href="#bib0008" class="workspace-trigger">Bordag&nbsp;(2006)</a> proposed a triplet-based clustering algorithm that instantiated the ‘one sense per collocation’ observation. <a name="bbib0041" href="#bib0041" class="workspace-trigger">Pedersen&nbsp;and Bruce&nbsp;(1998)</a> presented a corpus-based approach to word-sense disambiguation that only requires information that can be automatically extracted from the untagged text. Some of the recent attempts to word sense disambiguation have been made by <a name="bbib0044" href="#bib0044" class="workspace-trigger">Raviv,&nbsp;Markovitch, and Maneas&nbsp;(2012)</a><span>. They introduced Concept-Based Disambiguation (CBD), a novel framework that utilizes recent <a href="/topics/computer-science/semantic-analysis" title="Learn more about semantic analysis from ScienceDirect's AI-generated Topic Pages" class="topic-link">semantic analysis</a> techniques to represent both the context of the word and its senses in a high-dimensional space of natural concepts. </span><a name="bbib0003" href="#bib0003" class="workspace-trigger">Baskaya&nbsp;and Jurgens&nbsp;(2016)</a> presented a new approach to build a semi-supervised WSD system that combines a small amount of sense-annotated data with information from WSI. Some researchers&nbsp;(<a name="bbib0018" href="#bib0018" class="workspace-trigger">Erk &amp; Pado,&nbsp;2007</a>) even observed that the senses of a word are not completely disjoint and attempted to propose a graded representation of word sense.</p><p id="p0020">On the other hand, researchers have also tried to develop data-driven models of language dynamics. One of the first attempts was made by <a name="bbib0017" href="#bib0017" class="workspace-trigger">Erk&nbsp;(2006)</a><span>, where the author tried to model this problem as an instance of <a href="/topics/computer-science/outlier-detection" title="Learn more about outlier detection from ScienceDirect's AI-generated Topic Pages" class="topic-link">outlier detection</a>, using a simple nearest neighbor-based approach. </span><a name="bbib0023" href="#bib0023" class="workspace-trigger">Gulordava&nbsp;and Baroni&nbsp;(2011)</a> study the change in the semantic orientation of words using Google book n-grams corpus from different time periods. In another work, <a name="bbib0037" href="#bib0037" class="workspace-trigger">Mihalcea&nbsp;and Nastase&nbsp;(2012)</a><span> attempted to quantify the changes in word usage over time and came up with the intuition that changes in <a href="/topics/computer-science/usage-frequency" title="Learn more about usage frequency from ScienceDirect's AI-generated Topic Pages" class="topic-link">usage frequency</a> and word senses contribute to these differences in usages. In similar lines, </span><a name="bbib0027" href="#bib0027" class="workspace-trigger">Jatowt&nbsp;and Duh&nbsp;(2014)</a> used the Google n-grams corpus from two different time periods and proposed a method to identify semantic change based on the distributional similarity between the word vectors. <a name="bbib0050" href="#bib0050" class="workspace-trigger">Tahmasebi&nbsp;et&nbsp;al.&nbsp;(2011)</a> attempted to track sense changes from a newspaper corpus containing articles between 1785 and 1985. Even though the interest for automatic identification of new word senses has grown, the research has been limited by the availability of appropriate evaluation resources. Efforts have been made by <a name="bbib0012" href="#bib0012" class="workspace-trigger">Cook,&nbsp;Lau, McCarthy, and Baldwin&nbsp;(2014)</a> to prepare the largest corpus-based dataset of diachronic sense differences. Attempts have been made by <a name="bbib0034" href="#bib0034" class="workspace-trigger">Lau,&nbsp;Cook, McCarthy, Newman, and Baldwin&nbsp;(2012)</a> where they first introduced topic modeling based word sense induction method to automatically detect words with emergent novel senses. In subsequent work, <a name="bbib0033" href="#bib0033" class="workspace-trigger">Lau&nbsp;et&nbsp;al.&nbsp;(2014)</a> extended this task by leveraging the concept of predominant sense. The first computational approach to track and detect statistically significant linguistic shifts of words has been proposed by <a name="bbib0030" href="#bib0030" class="workspace-trigger">Kulkarni&nbsp;et&nbsp;al.&nbsp;(2015)</a>. Researchers&nbsp;(<a name="bbib0028" href="#bib0028" class="workspace-trigger">Kenter,&nbsp;Wevers, Huijnen, &amp; De&nbsp;Rijke, 2015</a>) also attempted to solve a variant of this problem which deals with monitoring shifts in vocabulary over time. Recently, <a name="bbib0025" href="#bib0025" class="workspace-trigger">Hamilton,&nbsp;Leskovec, and Jurafsky&nbsp;(2016b)</a><span> proposed a method to quantify semantic change by evaluating <a href="/topics/computer-science/word-embeddings" title="Learn more about word embeddings from ScienceDirect's AI-generated Topic Pages" class="topic-link">word embeddings</a> against known historical changes. In another work, </span><a name="bbib0024" href="#bib0024" class="workspace-trigger">Hamilton&nbsp;et&nbsp;al.&nbsp;(2016a)</a> categorized the semantic change into two types and proposed different distributional measures to detect those types. An attempt has also been made to analyze the time-series model of embedding vectors as well as time-indexed self-similarity graphs in order to hypothesize the linearity of semantic change by <a name="bbib0016" href="#bib0016" class="workspace-trigger">Eger&nbsp;and Mehler&nbsp;(2016)</a><span>. Dynamic <a href="/topics/computer-science/bayesian-model" title="Learn more about Bayesian model from ScienceDirect's AI-generated Topic Pages" class="topic-link">Bayesian model</a> of diachronic meaning change has been proposed by </span><a name="bbib0020" href="#bib0020" class="workspace-trigger">Frermann&nbsp;and Lapata&nbsp;(2016)</a> where they have shown novel sense detection task as one of their applications. The probabilistic language model for time-stamped text data which tracks the semantic evolution of individual words over time has also been tried out&nbsp;(<a name="bbib0002" href="#bib0002" class="workspace-trigger">Bamler &amp; Mandt,&nbsp;2017</a>). Recently, researchers have also tried to investigate the reasons behind word sense evolution and have come up with computational models based on chaining&nbsp;(<a name="bbib0043" href="#bib0043" class="workspace-trigger">Ramiro,&nbsp;Srinivasan, Malt, &amp; Xu, 2018</a>). Researchers also attempt to apply dynamic word embeddings as well to detect language evolution. <a name="bbib0046" href="#bib0046" class="workspace-trigger">Rudolph&nbsp;and Blei&nbsp;(2018)</a><span> develop dynamic embeddings, building on <a href="/topics/computer-science/exponential-family" title="Learn more about exponential family from ScienceDirect's AI-generated Topic Pages" class="topic-link">exponential family</a> embeddings to capture how the meanings of words change over time. </span><a name="bbib0057" href="#bib0057" class="workspace-trigger">Yao,&nbsp;Sun, Ding, Rao, and Xiong&nbsp;(2018)</a> develop a dynamic statistical model to learn time-aware word vector representation. Researchers also attempt to analyze temporal word analogy by effectively modeling with diachronic word embeddings, provided that the independent embedding spaces from each time period are appropriately transformed into a common vector space&nbsp;(<a name="bbib0048" href="#bib0048" class="workspace-trigger">Szymanski,&nbsp;2017</a>). In a recent study, <a name="bbib0013" href="#bib0013" class="workspace-trigger">Di&nbsp;Carlo,&nbsp;Bianchi, and Palmonari&nbsp;(2019)</a> proposed a new heuristic to train temporal word embeddings based on the word2vec model which talks about using atemporal vectors as a reference, i.e., as a compass, when training the representations specific to a given time interval and they evaluated this heuristic for temporal word analogy task.</p><p id="p0021">As per the surveys made in this stream of literature&nbsp;(<a name="bbib0031" href="#bib0031" class="workspace-trigger">Kutuzov, Øvrelid, Szymanski, Velldal, 2018</a>, <a name="bbib0049" href="#bib0049" class="workspace-trigger">Tahmasebi, Borin, Jatowt, 2018</a>, <a name="bbib0051" href="#bib0051" class="workspace-trigger">Tang, 2018</a>), researchers have tried to formulate the task of tracking semantic shifts differently. Given a corpora containing texts from different time periods, some researchers have tried to locate words with different meaning in different time periods&nbsp;(<a name="bbib0012" href="#bib0012" class="workspace-trigger">Cook, Lau, McCarthy, Baldwin, 2014</a>, <a name="bbib0034" href="#bib0034" class="workspace-trigger">Lau, Cook, McCarthy, Newman, Baldwin, 2012</a>, <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra, Mitra, Riedl, Biemann, Mukherjee, Goyal, 2014</a>), some attempted to trace the dynamics of the relationship between the words&nbsp;(<a name="bbib0018" href="#bib0018" class="workspace-trigger">Erk, Pado, 2007</a>, <a name="bbib0023" href="#bib0023" class="workspace-trigger">Gulordava, Baroni, 2011</a>, <a name="bbib0027" href="#bib0027" class="workspace-trigger">Jatowt, Duh, 2014</a>, <a name="bbib0037" href="#bib0037" class="workspace-trigger">Mihalcea, Nastase, 2012</a>) whereas some tried to discover the general trends in semantic shifts depicting probable linguistic reasons&nbsp;(<a name="bbib0016" href="#bib0016" class="workspace-trigger">Eger, Mehler, 2016</a>, <a name="bbib0024" href="#bib0024" class="workspace-trigger">Hamilton, Leskovec, Jurafsky, 2016a</a>, <a name="bbib0025" href="#bib0025" class="workspace-trigger">Hamilton, Leskovec, Jurafsky, 2016b</a>, <a name="bbib0030" href="#bib0030" class="workspace-trigger">Kulkarni, Al-Rfou, Perozzi, Skiena, 2015</a>). Recently, a new line of research problem which deals with detecting temporal word analogy has also been attempted&nbsp;(<a name="bbib0013" href="#bib0013" class="workspace-trigger">Di Carlo, Bianchi, Palmonari, 2019</a>, <a name="bbib0048" href="#bib0048" class="workspace-trigger">Szymanski, 2017</a>). Researchers have not only tried to attempt this problem of semantic shift of words from different perspectives with different goals, but they have also tried to formulate solutions to such problems using different methodologies. Starting from simple corpus statistics based approaches&nbsp;(<a name="bbib0023" href="#bib0023" class="workspace-trigger">Gulordava, Baroni, 2011</a>, <a name="bbib0050" href="#bib0050" class="workspace-trigger">Tahmasebi, Risse, Dietze, 2011</a><span>), researchers have gradually moved toward <a href="/topics/computer-science/probabilistic-approach" title="Learn more about probabilistic approaches from ScienceDirect's AI-generated Topic Pages" class="topic-link">probabilistic approaches</a>&nbsp;(</span><a name="bbib0002" href="#bib0002" class="workspace-trigger">Bamler, Mandt, 2017</a>, <a name="bbib0017" href="#bib0017" class="workspace-trigger">Erk, 2006</a>, <a name="bbib0020" href="#bib0020" class="workspace-trigger">Frermann, Lapata, 2016</a>, <a name="bbib0037" href="#bib0037" class="workspace-trigger">Mihalcea, Nastase, 2012</a>), topic modelling based approaches&nbsp;(<a name="bbib0012" href="#bib0012" class="workspace-trigger">Cook, Lau, McCarthy, Baldwin, 2014</a>, <a name="bbib0034" href="#bib0034" class="workspace-trigger">Lau, Cook, McCarthy, Newman, Baldwin, 2012</a>), and network based approaches&nbsp;(<a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al., 2014</a>). Recently, a trend of using dynamic neural embeddings has been observed among the researchers&nbsp;(<a name="bbib0013" href="#bib0013" class="workspace-trigger">Di Carlo, Bianchi, Palmonari, 2019</a>, <a name="bbib0016" href="#bib0016" class="workspace-trigger">Eger, Mehler, 2016</a>, <a name="bbib0027" href="#bib0027" class="workspace-trigger">Jatowt, Duh, 2014</a>, <a name="bbib0030" href="#bib0030" class="workspace-trigger">Kulkarni, Al-Rfou, Perozzi, Skiena, 2015</a>, <a name="bbib0048" href="#bib0048" class="workspace-trigger">Szymanski, 2017</a>, <a name="bbib0057" href="#bib0057" class="workspace-trigger">Yao, Sun, Ding, Rao, Xiong, 2018</a>).</p><p id="p0022">Nevertheless, in majority of these previous works, researchers tried to model the way a word’s sense changes over time and validated their models using words known to have undergone sense change. In some attempts, authors tried to find out how or why the semantic shifts happen as well. In contrast to most of these attempts, we pose the problem as detecting the set of words which have come up with a novel sense between old time point (<em>t<sub>old</sub></em>) and new time point (<em>t<sub>new</sub></em>) with high precision, provided we have large text corpus from both <em>t<sub>old</sub></em> and <em>t<sub>new</sub></em>. Therefore we point out two such baselines&nbsp;(<a name="bbib0033" href="#bib0033" class="workspace-trigger">Lau, Cook, McCarthy, Gella, Baldwin, 2014</a>, <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra, Mitra, Riedl, Biemann, Mukherjee, Goyal, 2014</a>) with a similar objective. We describe these baselines in <a name="bsec0009" href="#sec0009" class="workspace-trigger">Section&nbsp;3</a>.</p></section><section id="sec0009"><h2 id="sctt0012" class="u-h3 u-margin-l-top u-margin-xs-bottom">3. Baselines</h2><p id="p0023">In this section, we describe the two baselines that are relevant to our work.</p><section id="sec0010"><h3 id="sctt0013" class="u-h4 u-margin-m-top u-margin-xs-bottom">3.1. Baseline 1: (<a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al., 2014</a>)</h3><p id="p0024">In <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a>, the authors proposed an unsupervised and automated method to identify word sense changes. Their analysis is only focused on noun words. A brief summary of their work is described below for the ease of the readability of this paper.</p><section id="sec0011"><h4 id="sctt0014" class="u-margin-m-top u-margin-xs-bottom">3.1.1. Datasets and graph construction</h4><div><p id="p0025"><span>The authors used the Google books corpus, consisting of texts from over 3.4 million digitized English books. These books were published between 1520 and 2008, mostly after 1800. The authors constructed distributional thesauri (DT) networks from the Google books <a href="/topics/computer-science/syntactics" title="Learn more about syntactic from ScienceDirect's AI-generated Topic Pages" class="topic-link">syntactic</a> n-grams data&nbsp;(</span><a name="bbib0021" href="#bib0021" class="workspace-trigger">Goldberg &amp; Orwant,&nbsp;2013</a>). The DT network contains, for each word, a list of words that are similar with respect to their bigram distribution&nbsp;(<a name="bbib0045" href="#bib0045" class="workspace-trigger">Riedl &amp; Biemann,&nbsp;2013</a><span>). In particular, they first extracted each word and a set of <a href="/topics/computer-science/its-context" title="Learn more about its context from ScienceDirect's AI-generated Topic Pages" class="topic-link">its context</a> features like part-of-speech tag, neighboring set of words, frequency, etc. Next, they calculated the lexicographer’s mutual information (LMI)&nbsp;(</span><a name="bbib0029" href="#bib0029" class="workspace-trigger">Kilgarriff,&nbsp;Rychly, Smrz, &amp; Tugwell, 2004</a>)<a name="bfn0002" href="#fn0002" class="workspace-trigger"><sup>2</sup></a> between a word and its features and took the top 1000 ranked features for each word. In the network, each word is a node and there is a weighted edge between a pair of words where the weight of the edge is defined as the number of features that these two words share in common. A snapshot of the DT is shown in <a name="bfig0001" href="#fig0001" class="workspace-trigger">Fig.&nbsp;1</a><span>. To study word sense changes over time, they divided the dataset across eight time periods; accordingly DT networks for each of these time periods were constructed separately. The basic idea is that if a word undergoes sense change, it can be detected by comparing its senses from two different time periods. The <a href="/topics/computer-science/unsupervised-method" title="Learn more about unsupervised method from ScienceDirect's AI-generated Topic Pages" class="topic-link">unsupervised method</a> for inducing word senses in each time period is described below.</span></p><figure class="figure text-xs" id="fig0001"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0306457319303474-gr1.jpg" height="347" alt="Fig. 1" aria-describedby="cap0001"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0306457319303474-gr1_lrg.jpg" target="_blank" download="" title="Download high-res image (312KB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (312KB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0306457319303474-gr1.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0001"><p id="sp0005"><span class="label">Fig. 1</span>. A sample snapshot of Distributional Thesaurus Network from the time period 2002–2005 where each node represents a word and the weight of the edge is defined as the number of context features that these two words share in common. Here the word ‘bank’ with some top distributionally similar words and the connections among them are shown.</p></span></span></figure></div></section><section id="sec0012"><h4 id="sctt0015" class="u-margin-m-top u-margin-xs-bottom">3.1.2. Unsupervised sense induction</h4><div><p id="p0027">In order to get the induced sense clusters in an unsupervised way, Chinese Whispers algorithm&nbsp;(<a name="bbib0004" href="#bib0004" class="workspace-trigger">Biemann,&nbsp;2006</a>) has been used. The algorithm produces a set of clusters for each target word by decomposing its neighborhood in the DT network. The hypothesis is that different clusters signify different senses of a target word. The clusters for a target word ‘float’ is shown in <a name="bfig0002" href="#fig0002" class="workspace-trigger">Fig.&nbsp;2</a>. The authors then compare the sense clusters extracted across two different time periods to obtain suitable signals of sense change.</p><figure class="figure text-xs" id="fig0002"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0306457319303474-gr2.jpg" height="287" alt="Fig. 2" aria-describedby="cap0002"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0306457319303474-gr2_lrg.jpg" target="_blank" download="" title="Download high-res image (414KB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (414KB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0306457319303474-gr2.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0002"><p id="sp0006"><span class="label">Fig. 2</span>. Chinese Whisper clusters for the target word ‘float’ extracted from Google books <a href="/topics/computer-science/syntactics" title="Learn more about syntactic from ScienceDirect's AI-generated Topic Pages" class="topic-link">syntactic</a> n-gram corpus of both the time periods (1909–1953 and 2002–2005). A new sense of the word ‘float’ has emerged with the ‘programming’ related new cluster (C23) in 2002–2005.</p></span></span></figure></div></section><section id="sec0013"><h4 id="sctt0016" class="u-margin-m-top u-margin-xs-bottom">3.1.3. Sense change detection</h4><p id="p0028">Let us assume that the Chinese Whispers algorithm is run over DTs corresponding to two different time periods, <em>t<sub>i</sub></em> and <em>t<sub>j</sub></em>. Now, assume that for a given word <em>w</em>, the algorithm gives two different sets of clusters, <em>C<sub>i</sub></em> and <em>C<sub>j</sub></em>, such that <em>m</em> sense clusters are obtained in <em>t<sub>i</sub></em> and <em>n</em> sense clusters are obtained in <em>t<sub>j</sub></em>. Accordingly, let <em>C<sub>i</sub></em> = <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-68-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>s</mi><msub is=&quot;true&quot;><mi is=&quot;true&quot;>i</mi><mn is=&quot;true&quot;>1</mn></msub></msub><mo is=&quot;true&quot;>,</mo></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.282ex" height="1.972ex" viewBox="0 -530.3 1413.3 849.3" role="img" focusable="false" style="vertical-align: -0.741ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-73"></use></g><g is="true" transform="translate(469,-150)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(244,-107)"><use transform="scale(0.5)" xlink:href="#MJMAIN-31"></use></g></g></g><g is="true" transform="translate(1134,0)"><use xlink:href="#MJMAIN-2C"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">i</mi><mn is="true">1</mn></msub></msub><mo is="true">,</mo></mrow></math></span></span><script type="math/mml" id="MathJax-Element-68"><math><mrow is="true"><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">i</mi><mn is="true">1</mn></msub></msub><mo is="true">,</mo></mrow></math></script></span> <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-69-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>s</mi><msub is=&quot;true&quot;><mi is=&quot;true&quot;>i</mi><mn is=&quot;true&quot;>2</mn></msub></msub><mo is=&quot;true&quot;>,</mo></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.282ex" height="1.972ex" viewBox="0 -530.3 1413.3 849.3" role="img" focusable="false" style="vertical-align: -0.741ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-73"></use></g><g is="true" transform="translate(469,-150)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(244,-107)"><use transform="scale(0.5)" xlink:href="#MJMAIN-32"></use></g></g></g><g is="true" transform="translate(1134,0)"><use xlink:href="#MJMAIN-2C"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">i</mi><mn is="true">2</mn></msub></msub><mo is="true">,</mo></mrow></math></span></span><script type="math/mml" id="MathJax-Element-69"><math><mrow is="true"><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">i</mi><mn is="true">2</mn></msub></msub><mo is="true">,</mo></mrow></math></script></span>..., <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-70-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>s</mi><msub is=&quot;true&quot;><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>m</mi></msub></msub></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.075ex" height="1.972ex" viewBox="0 -530.3 1323.8 849.3" role="img" focusable="false" style="vertical-align: -0.741ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-73"></use></g><g is="true" transform="translate(469,-150)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(244,-107)"><use transform="scale(0.5)" xlink:href="#MJMATHI-6D"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">i</mi><mi is="true">m</mi></msub></msub></math></span></span><script type="math/mml" id="MathJax-Element-70"><math><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">i</mi><mi is="true">m</mi></msub></msub></math></script></span> and <em>C<sub>j</sub></em> = <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-71-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>s</mi><msub is=&quot;true&quot;><mi is=&quot;true&quot;>j</mi><mn is=&quot;true&quot;>1</mn></msub></msub><mo is=&quot;true&quot;>,</mo></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.392ex" height="2.218ex" viewBox="0 -530.3 1460.6 954.9" role="img" focusable="false" style="vertical-align: -0.986ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-73"></use></g><g is="true" transform="translate(469,-150)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-6A"></use></g><g is="true" transform="translate(291,-170)"><use transform="scale(0.5)" xlink:href="#MJMAIN-31"></use></g></g></g><g is="true" transform="translate(1182,0)"><use xlink:href="#MJMAIN-2C"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">j</mi><mn is="true">1</mn></msub></msub><mo is="true">,</mo></mrow></math></span></span><script type="math/mml" id="MathJax-Element-71"><math><mrow is="true"><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">j</mi><mn is="true">1</mn></msub></msub><mo is="true">,</mo></mrow></math></script></span> <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-72-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>s</mi><msub is=&quot;true&quot;><mi is=&quot;true&quot;>j</mi><mn is=&quot;true&quot;>2</mn></msub></msub><mo is=&quot;true&quot;>,</mo></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.392ex" height="2.218ex" viewBox="0 -530.3 1460.6 954.9" role="img" focusable="false" style="vertical-align: -0.986ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-73"></use></g><g is="true" transform="translate(469,-150)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-6A"></use></g><g is="true" transform="translate(291,-170)"><use transform="scale(0.5)" xlink:href="#MJMAIN-32"></use></g></g></g><g is="true" transform="translate(1182,0)"><use xlink:href="#MJMAIN-2C"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">j</mi><mn is="true">2</mn></msub></msub><mo is="true">,</mo></mrow></math></span></span><script type="math/mml" id="MathJax-Element-72"><math><mrow is="true"><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">j</mi><mn is="true">2</mn></msub></msub><mo is="true">,</mo></mrow></math></script></span>..., <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-73-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>s</mi><msub is=&quot;true&quot;><mi is=&quot;true&quot;>j</mi><mi is=&quot;true&quot;>n</mi></msub></msub><mo is=&quot;true&quot;>,</mo></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.509ex" height="2.218ex" viewBox="0 -530.3 1510.6 954.9" role="img" focusable="false" style="vertical-align: -0.986ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-73"></use></g><g is="true" transform="translate(469,-150)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-6A"></use></g><g is="true" transform="translate(291,-170)"><use transform="scale(0.5)" xlink:href="#MJMATHI-6E"></use></g></g></g><g is="true" transform="translate(1232,0)"><use xlink:href="#MJMAIN-2C"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">j</mi><mi is="true">n</mi></msub></msub><mo is="true">,</mo></mrow></math></span></span><script type="math/mml" id="MathJax-Element-73"><math><mrow is="true"><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">j</mi><mi is="true">n</mi></msub></msub><mo is="true">,</mo></mrow></math></script></span> where <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-74-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>s</mi><msub is=&quot;true&quot;><mi is=&quot;true&quot;>k</mi><mi is=&quot;true&quot;>z</mi></msub></msub></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.887ex" height="1.972ex" viewBox="0 -530.3 1243.2 849.3" role="img" focusable="false" style="vertical-align: -0.741ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-73"></use></g><g is="true" transform="translate(469,-150)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-6B"></use></g><g is="true" transform="translate(368,-107)"><use transform="scale(0.5)" xlink:href="#MJMATHI-7A"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">k</mi><mi is="true">z</mi></msub></msub></math></span></span><script type="math/mml" id="MathJax-Element-74"><math><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">k</mi><mi is="true">z</mi></msub></msub></math></script></span> denotes <em>z<sup>th</sup></em> sense cluster for word <em>w</em> during time interval <em>t<sub>k</sub></em>. There are four types of sense changes that can happen for a target word – <em>split, join, birth</em> and <em>death</em>. These sense changes are defined below.<dl class="list"><dt class="list-label">•</dt><dd class="list-description"><p id="p0029"><strong>split</strong>: A sense cluster <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-75-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>s</mi><msub is=&quot;true&quot;><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>z</mi></msub></msub></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.598ex" height="1.972ex" viewBox="0 -530.3 1118.8 849.3" role="img" focusable="false" style="vertical-align: -0.741ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-73"></use></g><g is="true" transform="translate(469,-150)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(244,-107)"><use transform="scale(0.5)" xlink:href="#MJMATHI-7A"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">i</mi><mi is="true">z</mi></msub></msub></math></span></span><script type="math/mml" id="MathJax-Element-75"><math><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">i</mi><mi is="true">z</mi></msub></msub></math></script></span> in <em>t<sub>i</sub></em> splits into two (or more) sense clusters, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-76-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>s</mi><msub is=&quot;true&quot;><mi is=&quot;true&quot;>j</mi><msub is=&quot;true&quot;><mi is=&quot;true&quot;>p</mi><mn is=&quot;true&quot;>1</mn></msub></msub></msub></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.446ex" height="2.586ex" viewBox="0 -530.3 1483.9 1113.4" role="img" focusable="false" style="vertical-align: -1.354ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-73"></use></g><g is="true" transform="translate(469,-150)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-6A"></use></g><g is="true" transform="translate(291,-170)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-70"></use></g><g is="true" transform="translate(251,-162)"><use transform="scale(0.5)" xlink:href="#MJMAIN-31"></use></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">j</mi><msub is="true"><mi is="true">p</mi><mn is="true">1</mn></msub></msub></msub></math></span></span><script type="math/mml" id="MathJax-Element-76"><math><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">j</mi><msub is="true"><mi is="true">p</mi><mn is="true">1</mn></msub></msub></msub></math></script></span> and <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-77-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>s</mi><msub is=&quot;true&quot;><mi is=&quot;true&quot;>j</mi><msub is=&quot;true&quot;><mi is=&quot;true&quot;>p</mi><mn is=&quot;true&quot;>2</mn></msub></msub></msub></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.446ex" height="2.586ex" viewBox="0 -530.3 1483.9 1113.4" role="img" focusable="false" style="vertical-align: -1.354ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-73"></use></g><g is="true" transform="translate(469,-150)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-6A"></use></g><g is="true" transform="translate(291,-170)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-70"></use></g><g is="true" transform="translate(251,-162)"><use transform="scale(0.5)" xlink:href="#MJMAIN-32"></use></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">j</mi><msub is="true"><mi is="true">p</mi><mn is="true">2</mn></msub></msub></msub></math></span></span><script type="math/mml" id="MathJax-Element-77"><math><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">j</mi><msub is="true"><mi is="true">p</mi><mn is="true">2</mn></msub></msub></msub></math></script></span> in <em>t<sub>j</sub></em>.</p></dd><dt class="list-label">•</dt><dd class="list-description"><p id="p0030"><strong>join</strong>: Two sense clusters <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-78-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>s</mi><msub is=&quot;true&quot;><mi is=&quot;true&quot;>i</mi><msub is=&quot;true&quot;><mi is=&quot;true&quot;>z</mi><mn is=&quot;true&quot;>1</mn></msub></msub></msub></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.292ex" height="2.341ex" viewBox="0 -530.3 1417.5 1007.7" role="img" focusable="false" style="vertical-align: -1.109ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-73"></use></g><g is="true" transform="translate(469,-150)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(244,-107)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-7A"></use></g><g is="true" transform="translate(232,-162)"><use transform="scale(0.5)" xlink:href="#MJMAIN-31"></use></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">i</mi><msub is="true"><mi is="true">z</mi><mn is="true">1</mn></msub></msub></msub></math></span></span><script type="math/mml" id="MathJax-Element-78"><math><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">i</mi><msub is="true"><mi is="true">z</mi><mn is="true">1</mn></msub></msub></msub></math></script></span> and <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-79-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>s</mi><msub is=&quot;true&quot;><mi is=&quot;true&quot;>i</mi><msub is=&quot;true&quot;><mi is=&quot;true&quot;>z</mi><mn is=&quot;true&quot;>2</mn></msub></msub></msub></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.292ex" height="2.341ex" viewBox="0 -530.3 1417.5 1007.7" role="img" focusable="false" style="vertical-align: -1.109ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-73"></use></g><g is="true" transform="translate(469,-150)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(244,-107)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-7A"></use></g><g is="true" transform="translate(232,-162)"><use transform="scale(0.5)" xlink:href="#MJMAIN-32"></use></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">i</mi><msub is="true"><mi is="true">z</mi><mn is="true">2</mn></msub></msub></msub></math></span></span><script type="math/mml" id="MathJax-Element-79"><math><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">i</mi><msub is="true"><mi is="true">z</mi><mn is="true">2</mn></msub></msub></msub></math></script></span> in <em>t<sub>i</sub></em> join to make a single cluster <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-80-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>s</mi><msub is=&quot;true&quot;><mi is=&quot;true&quot;>j</mi><mi is=&quot;true&quot;>p</mi></msub></msub></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.749ex" height="2.341ex" viewBox="0 -530.3 1183.6 1007.7" role="img" focusable="false" style="vertical-align: -1.109ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-73"></use></g><g is="true" transform="translate(469,-150)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-6A"></use></g><g is="true" transform="translate(291,-170)"><use transform="scale(0.5)" xlink:href="#MJMATHI-70"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">j</mi><mi is="true">p</mi></msub></msub></math></span></span><script type="math/mml" id="MathJax-Element-80"><math><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">j</mi><mi is="true">p</mi></msub></msub></math></script></span> in <em>t<sub>j</sub></em>.</p></dd><dt class="list-label">•</dt><dd class="list-description"><p id="p0031"><strong>birth</strong>: A new sense cluster <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-81-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>s</mi><msub is=&quot;true&quot;><mi is=&quot;true&quot;>j</mi><mi is=&quot;true&quot;>p</mi></msub></msub></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.749ex" height="2.341ex" viewBox="0 -530.3 1183.6 1007.7" role="img" focusable="false" style="vertical-align: -1.109ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-73"></use></g><g is="true" transform="translate(469,-150)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-6A"></use></g><g is="true" transform="translate(291,-170)"><use transform="scale(0.5)" xlink:href="#MJMATHI-70"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">j</mi><mi is="true">p</mi></msub></msub></math></span></span><script type="math/mml" id="MathJax-Element-81"><math><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">j</mi><mi is="true">p</mi></msub></msub></math></script></span> appears in <em>t<sub>j</sub></em>, which was absent in <em>t<sub>i</sub></em>.</p></dd><dt class="list-label">•</dt><dd class="list-description"><p id="p0032"><strong>death</strong>: A sense cluster <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-82-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>s</mi><msub is=&quot;true&quot;><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>z</mi></msub></msub></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.598ex" height="1.972ex" viewBox="0 -530.3 1118.8 849.3" role="img" focusable="false" style="vertical-align: -0.741ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-73"></use></g><g is="true" transform="translate(469,-150)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(244,-107)"><use transform="scale(0.5)" xlink:href="#MJMATHI-7A"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">i</mi><mi is="true">z</mi></msub></msub></math></span></span><script type="math/mml" id="MathJax-Element-82"><math><msub is="true"><mi is="true">s</mi><msub is="true"><mi is="true">i</mi><mi is="true">z</mi></msub></msub></math></script></span> in <em>t<sub>i</sub></em> dies out and does not appear in <em>t<sub>j</sub></em>.</p></dd></dl></p><p id="p0033">A sense cluster is considered as ‘birth’ if at least 80% words of that cluster are novel, i.e., they do not appear in any of the clusters of the old time periods. For example, in <a name="bfig0002" href="#fig0002" class="workspace-trigger">Fig.&nbsp;2</a>, the programming related cluster of the target word ‘float’ represents a ‘birth’ sense. For split, each split cluster should have at least 30% words of the source cluster and the total intersection of all the split clusters should be &nbsp;&gt;&nbsp; 80%. For join and death, the same parameters are used with the interchange of the source and the target clusters.</p><p id="p0034">Note that, as our main focus is to detect novel sense of a word, we are concerned with only ‘birth’ cases for our study.</p></section><section id="sec0014"><h4 id="sctt0017" class="u-margin-m-top u-margin-xs-bottom">3.1.4. Multi-stage filtering</h4><p id="p0035">The authors then apply multi-stage filtering in order to obtain meaningful candidate words.</p><p id="p0036"><strong>Stage 1</strong>: They apply Chinese Whisper three times over the two different time periods. They obtain the candidate word lists using their algorithm for the three runs, then take the intersection to output those words and clusters, which came up in all the three runs. Being non-deterministic in nature, the Chinese Whisper algorithm might produce different clustering in different runs. Therefore running it multiple times and taking an intersection is helpful to reduce the effect of non-determinism.</p><p id="p0037"><strong>Stage 2</strong>: As they focus only on nouns, they keep the candidate words tagged with ‘NN’ or ‘NNS’.</p><p id="p0038"><strong>Stage 3</strong>: They sort the target words based on their frequency counts and consider only the middle 60% of the list which is the most informative part for this type of analysis. Note that, the authors remove the words in the low-frequency range as there may not be sufficient evidence in the dataset to detect a sense change and rare words usually only have a single sense. On the other hand, words in the high-frequency range tend to be less topic-oriented and thus, appear in very different contexts even when conveying the same (mostly abstract) sense&nbsp;(<a name="bbib0032" href="#bib0032" class="workspace-trigger">Kwong, 1998</a>, <a name="bbib0035" href="#bib0035" class="workspace-trigger">Luhn, 1958</a>). For evaluation, the authors selected 49 candidate ‘birth’ words from a total of 2789 candidate ‘birth’ words while comparing 1909–1953 DT with the 2002–2005 DT. Using manual evaluation, 31 words were found to be true positives and 18 words were false positives. In our work, we take these 49 candidate words and show that network features can be useful to discriminate the true positives from the false positives.</p></section></section><section id="sec0015"><h3 id="sctt0018" class="u-h4 u-margin-m-top u-margin-xs-bottom">3.2. Baseline 2: <a name="bbib0033" href="#bib0033" class="workspace-trigger">Lau&nbsp;et&nbsp;al.&nbsp;(2014)</a></h3><p id="p0039"><span>The authors proposed an unsupervised approach based on topic modeling for sense induction and showed novel sense identification as one of its applications. For a candidate word, Hierarchical <a href="/topics/computer-science/dirichlet-process" title="Learn more about Dirichlet Process from ScienceDirect's AI-generated Topic Pages" class="topic-link">Dirichlet Process</a>&nbsp;(</span><a name="bbib0052" href="#bib0052" class="workspace-trigger">Teh,&nbsp;Jordan, Beal, &amp; Blei, 2006</a>) is run over a corpus containing occurrences of that word to induce topics. The induced topics are represented as word multinomials, and are expressed by the top-<em>N</em><span> words in descending order of <a href="/topics/computer-science/conditional-probability" title="Learn more about conditional probability from ScienceDirect's AI-generated Topic Pages" class="topic-link">conditional probability</a><span>. Each topic is represented as a sense of the target word. The words having the highest probability in each topic represent the sense clusters. The authors treated the novel sense detection task as identifying those sense clusters, which did not align with any of the recorded senses in a sense repository. They used Jensen-Shannon (JS) divergence measure to compute the alignment between a sense cluster and a synset. First, they computed JS divergence between the <a href="/topics/computer-science/multinomial-distribution" title="Learn more about multinomial distribution from ScienceDirect's AI-generated Topic Pages" class="topic-link">multinomial distribution</a> (over words) of the topic cluster and that of the synset, and converted the divergence value into a similarity score. Similarity between topic cluster </span></span><em>t<sub>j</sub></em> and synset <em>s<sub>i</sub></em> is defined as<span class="display"><span id="eq0001" class="formula"><span class="label">(1)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-83-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>s</mi><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>m</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>t</mi><mi is=&quot;true&quot;>j</mi></msub><mo is=&quot;true&quot;>,</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>s</mi><mi is=&quot;true&quot;>i</mi></msub><mo is=&quot;true&quot;>)</mo></mrow><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>1</mn><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>&amp;#x2212;</mo><mi is=&quot;true&quot;>J</mi><mi is=&quot;true&quot;>S</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>T</mi><mo is=&quot;true&quot;>&amp;#x2225;</mo><mi is=&quot;true&quot;>S</mi><mo is=&quot;true&quot;>)</mo></mrow></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="28.66ex" height="2.831ex" viewBox="0 -847.3 12339.5 1219.1" role="img" focusable="false" style="vertical-align: -0.864ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-73"></use></g><g is="true" transform="translate(469,0)"><use xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(815,0)"><use xlink:href="#MJMATHI-6D"></use></g><g is="true" transform="translate(1860,0)"><use xlink:href="#MJMAIN-28" is="true"></use><g is="true" transform="translate(389,0)"><g is="true"><use xlink:href="#MJMATHI-74"></use></g><g is="true" transform="translate(361,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6A"></use></g></g><g is="true" transform="translate(1142,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(1587,0)"><g is="true"><use xlink:href="#MJMATHI-73"></use></g><g is="true" transform="translate(469,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g></g><use xlink:href="#MJMAIN-29" is="true" x="2401" y="0"></use></g><g is="true" transform="translate(4929,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(5985,0)"><use xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(6708,0)"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(7708,0)"><use xlink:href="#MJMATHI-4A"></use></g><g is="true" transform="translate(8342,0)"><use xlink:href="#MJMATHI-53"></use></g><g is="true" transform="translate(9154,0)"><g is="true"><use xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(389,0)"><use xlink:href="#MJMATHI-54"></use></g><g is="true" transform="translate(1371,0)"><use xlink:href="#MJMAIN-2225"></use></g><g is="true" transform="translate(2150,0)"><use xlink:href="#MJMATHI-53"></use></g><g is="true" transform="translate(2795,0)"><use xlink:href="#MJMAIN-29"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">s</mi><mi is="true">i</mi><mi is="true">m</mi><mrow is="true"><mo is="true">(</mo><msub is="true"><mi is="true">t</mi><mi is="true">j</mi></msub><mo is="true">,</mo><msub is="true"><mi is="true">s</mi><mi is="true">i</mi></msub><mo is="true">)</mo></mrow><mo linebreak="goodbreak" is="true">=</mo><mn is="true">1</mn><mo linebreak="goodbreak" is="true">−</mo><mi is="true">J</mi><mi is="true">S</mi><mrow is="true"><mo is="true">(</mo><mi is="true">T</mi><mo is="true">∥</mo><mi is="true">S</mi><mo is="true">)</mo></mrow></mrow></math></span></span><script type="math/mml" id="MathJax-Element-83"><math><mrow is="true"><mi is="true">s</mi><mi is="true">i</mi><mi is="true">m</mi><mrow is="true"><mo is="true">(</mo><msub is="true"><mi is="true">t</mi><mi is="true">j</mi></msub><mo is="true">,</mo><msub is="true"><mi is="true">s</mi><mi is="true">i</mi></msub><mo is="true">)</mo></mrow><mo linebreak="goodbreak" is="true">=</mo><mn is="true">1</mn><mo linebreak="goodbreak" is="true">−</mo><mi is="true">J</mi><mi is="true">S</mi><mrow is="true"><mo is="true">(</mo><mi is="true">T</mi><mo is="true">∥</mo><mi is="true">S</mi><mo is="true">)</mo></mrow></mrow></math></script></span></span></span>where <em>T</em> and <em>S</em> are the multinomial distributions over words for topic <em>t<sub>j</sub></em> and synset <em>s<sub>i</sub></em>, respectively, and <em>JS</em>(<em>X</em>∥<em>Y</em>) is the Jensen-Shannon divergence for the distribution <em>X</em> and <em>Y</em>. Since we define novel senses while comparing sense clusters across two time periods, we use the same JS measure to detect novel sense of a target word. A sense cluster in the newer time period denotes a new sense (‘birth’) only if its maximum similarity with any of the clusters in older time period is below a threshold, which we have set to 0.35 based on empirical observation.</p><p id="p0040">In <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a>, the authors reported a total of 2789 candidate ‘birth’ words while comparing 1909–1953 DT with 2002–2005 DT and 2468 candidate ‘birth’ words while comparing 1909–1953 DT with 2006–2008 DT. We take all these reported ‘birth’ cases as target words and apply our approach to improve the quality of the detected ‘birth’ senses. We have also followed the procedure described above for <a name="bbib0033" href="#bib0033" class="workspace-trigger">Lau&nbsp;et&nbsp;al.&nbsp;(2014)</a> over the same set of candidate words. Then we take 100 random samples from each of these two separate set-ups(1909–1953&nbsp;vs 2002–2005 and 1909–1953&nbsp;vs 2006–2008) and compare all three approaches in terms of precision-recall measure over this set using manual evaluation of the reported results.</p></section></section><section id="sec0016"><h2 id="sctt0019" class="u-h3 u-margin-l-top u-margin-xs-bottom">4. Proposed network-centric approach</h2><div><p id="p0041"><a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a> manually evaluated 49 candidate ‘birth’ words from a total of 2789 candidate ‘birth’ words while comparing 1909–1953 DT with the 2002–2005 DT among which 31 words were found to be having come up with novel sense and 18 words are not having novel sense. We first study these 49 candidate ‘birth’ words and show that network features can be useful to discriminate the true positives from the false positives. For each of these candidate words <em>w</em>, we take the ‘birth’ cluster from 2002 to 2005, which is represented by a set of words <em>S</em>. According to our hypothesis, if the words in set <em>S</em> together represent a new sense for <em>w</em> in 2002–2005 which is not present in 1909–1953, the network connection among these words (including <em>w</em>) would be much stronger in the 2002–2005 DT than the 1909–1953 DT. The strength of this connection can be measured if we construct induced subgraphs of <em>S</em> from the two DTs and measure the network properties of these subgraphs; the difference would be more prominent for the actual ‘birth’ cases (true positives) than for the false ‘birth’ signals (false positives). Note that by definition, the nodes in an induced subgraph from a DT will be the words in <em>S</em> and there will be an edge between two words if and only if the edge exists in the original DT; we ignore the weight of the edge henceforth. Thus, the difference between the two subgraphs (one each from the older and newer DTs) will only be in the edge connections. <a name="bfig0003" href="#fig0003" class="workspace-trigger">Fig.&nbsp;3</a> shows one true positive (‘register’) and one false positive (‘quotes’) word from the set of 49 words and shows the induced subgraphs obtained by a subset of their ‘birth’ clusters across the two time periods. Note that, the target words are not present in the figure. This figure basically depicts, how the network connections among the words in the birth cluster (signifying the sense of target word) change over time. We can clearly see that connections among the words in <em>S</em> are much stronger in the newer DT than in the older ones in the case of ‘registers’, indicating the emergence of a new sense. In the case of ‘quotes’, however, the connections are not very different across the two time periods. We choose three <em>cohesion indicating</em> network properties, (i) the edge density, (ii) the structural similarity and (iii) the average path length, to capture this change.</p><figure class="figure text-xs" id="fig0003"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0306457319303474-gr3.jpg" height="174" alt="Fig. 3" aria-describedby="cap0003"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0306457319303474-gr3_lrg.jpg" target="_blank" download="" title="Download high-res image (562KB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (562KB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0306457319303474-gr3.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0003"><p id="sp0007"><span class="label">Fig. 3</span>. Induced subgraphs of the ‘birth’ clusters of ‘registers’ and ‘quotes’ for the two time periods (1909–1953 and 2002–2005). It shows that edge connections among the neighbors of ‘registers’ have increased significantly over time which leads to the emergence of ‘technology’ related sense of ‘registers’ whereas the connections among the neighbors of ‘quotes’ are almost same over time, indicating non-emergence of any novel sense.</p></span></span></figure></div><p id="p0042">Let <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-84-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>S</mi><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><mo is=&quot;true&quot;>{</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mn is=&quot;true&quot;>1</mn></msub><mo is=&quot;true&quot;>,</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mn is=&quot;true&quot;>2</mn></msub><mo is=&quot;true&quot;>,</mo><mo is=&quot;true&quot;>&amp;#x2026;</mo><mo is=&quot;true&quot;>,</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mi is=&quot;true&quot;>n</mi></msub><mo is=&quot;true&quot;>}</mo></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="21.454ex" height="2.703ex" viewBox="0 -845.5 9237.2 1163.9" role="img" focusable="false" style="vertical-align: -0.739ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-53"></use></g><g is="true" transform="translate(923,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(1979,0)"><use xlink:href="#MJMAIN-7B"></use></g><g is="true" transform="translate(2480,0)"><g is="true"><use xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(716,-150)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g></g><g is="true" transform="translate(3650,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(4095,0)"><g is="true"><use xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(716,-150)"><use transform="scale(0.707)" xlink:href="#MJMAIN-32"></use></g></g><g is="true" transform="translate(5266,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(5711,0)"><use xlink:href="#MJMAIN-2026"></use></g><g is="true" transform="translate(7050,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(7495,0)"><g is="true"><use xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(716,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6E"></use></g></g><g is="true" transform="translate(8736,0)"><use xlink:href="#MJMAIN-7D"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">S</mi><mo linebreak="goodbreak" is="true">=</mo><mo is="true">{</mo><msub is="true"><mi is="true">w</mi><mn is="true">1</mn></msub><mo is="true">,</mo><msub is="true"><mi is="true">w</mi><mn is="true">2</mn></msub><mo is="true">,</mo><mo is="true">…</mo><mo is="true">,</mo><msub is="true"><mi is="true">w</mi><mi is="true">n</mi></msub><mo is="true">}</mo></mrow></math></span></span><script type="math/mml" id="MathJax-Element-84"><math><mrow is="true"><mi is="true">S</mi><mo linebreak="goodbreak" is="true">=</mo><mo is="true">{</mo><msub is="true"><mi is="true">w</mi><mn is="true">1</mn></msub><mo is="true">,</mo><msub is="true"><mi is="true">w</mi><mn is="true">2</mn></msub><mo is="true">,</mo><mo is="true">…</mo><mo is="true">,</mo><msub is="true"><mi is="true">w</mi><mi is="true">n</mi></msub><mo is="true">}</mo></mrow></math></script></span> be the ‘birth’ cluster for <em>w</em>. Once we construct a graph induced by <em>S</em> from the DT, these network properties are measured as follows:</p><p id="p0043"><strong>Edge Density (ED):</strong> ED is given by<span class="display"><span id="eq0002" class="formula"><span class="label">(2)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-85-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>E</mi><mi is=&quot;true&quot;>D</mi><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>N</mi><mi is=&quot;true&quot;>a</mi></msub><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>/</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>N</mi><mi is=&quot;true&quot;>p</mi></msub></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="13.854ex" height="2.831ex" viewBox="0 -847.3 5965 1219.1" role="img" focusable="false" style="vertical-align: -0.864ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-45"></use></g><g is="true" transform="translate(764,0)"><use xlink:href="#MJMATHI-44"></use></g><g is="true" transform="translate(1870,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(2927,0)"><g is="true"><use xlink:href="#MJMATHI-4E"></use></g><g is="true" transform="translate(803,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-61"></use></g></g><g is="true" transform="translate(4204,0)"><use xlink:href="#MJMAIN-2F"></use></g><g is="true" transform="translate(4705,0)"><g is="true"><use xlink:href="#MJMATHI-4E"></use></g><g is="true" transform="translate(803,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-70"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">E</mi><mi is="true">D</mi><mo linebreak="goodbreak" is="true">=</mo><msub is="true"><mi is="true">N</mi><mi is="true">a</mi></msub><mo linebreak="goodbreak" is="true">/</mo><msub is="true"><mi is="true">N</mi><mi is="true">p</mi></msub></mrow></math></span></span><script type="math/mml" id="MathJax-Element-85"><math><mrow is="true"><mi is="true">E</mi><mi is="true">D</mi><mo linebreak="goodbreak" is="true">=</mo><msub is="true"><mi is="true">N</mi><mi is="true">a</mi></msub><mo linebreak="goodbreak" is="true">/</mo><msub is="true"><mi is="true">N</mi><mi is="true">p</mi></msub></mrow></math></script></span></span></span>where <em>N<sub>a</sub></em> denotes the number of actual edges between <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-86-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mn is=&quot;true&quot;>1</mn></msub><mo is=&quot;true&quot;>,</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mn is=&quot;true&quot;>2</mn></msub><mo is=&quot;true&quot;>,</mo><mo is=&quot;true&quot;>&amp;#x2026;</mo><mo is=&quot;true&quot;>,</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mi is=&quot;true&quot;>n</mi></msub></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="14.532ex" height="1.846ex" viewBox="0 -529.2 6256.6 794.8" role="img" focusable="false" style="vertical-align: -0.617ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(716,-150)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g></g><g is="true" transform="translate(1170,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(1615,0)"><g is="true"><use xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(716,-150)"><use transform="scale(0.707)" xlink:href="#MJMAIN-32"></use></g></g><g is="true" transform="translate(2785,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(3231,0)"><use xlink:href="#MJMAIN-2026"></use></g><g is="true" transform="translate(4570,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(5015,0)"><g is="true"><use xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(716,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6E"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">w</mi><mn is="true">1</mn></msub><mo is="true">,</mo><msub is="true"><mi is="true">w</mi><mn is="true">2</mn></msub><mo is="true">,</mo><mo is="true">…</mo><mo is="true">,</mo><msub is="true"><mi is="true">w</mi><mi is="true">n</mi></msub></mrow></math></span></span><script type="math/mml" id="MathJax-Element-86"><math><mrow is="true"><msub is="true"><mi is="true">w</mi><mn is="true">1</mn></msub><mo is="true">,</mo><msub is="true"><mi is="true">w</mi><mn is="true">2</mn></msub><mo is="true">,</mo><mo is="true">…</mo><mo is="true">,</mo><msub is="true"><mi is="true">w</mi><mi is="true">n</mi></msub></mrow></math></script></span> and <em>N<sub>p</sub></em> denotes the maximum possible edges between these, i.e., <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-87-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mfrac is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>n</mi><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>n</mi><mo is=&quot;true&quot;>&amp;#x2212;</mo><mn is=&quot;true&quot;>1</mn><mo is=&quot;true&quot;>)</mo></mrow><mn is=&quot;true&quot;>2</mn></mfrac></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.188ex" height="3.928ex" viewBox="0 -1214.6 2664.5 1691.1" role="img" focusable="false" style="vertical-align: -1.107ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g transform="translate(120,0)"><rect stroke="none" width="2424" height="60" x="0" y="220"></rect><g is="true" transform="translate(60,586)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-6E"></use></g><g is="true" transform="translate(424,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(700,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6E"></use></g><g is="true" transform="translate(1124,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(1675,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(2029,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-29"></use></g></g><g is="true" transform="translate(1035,-381)"><use transform="scale(0.707)" xlink:href="#MJMAIN-32"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac is="true"><mrow is="true"><mi is="true">n</mi><mo is="true">(</mo><mi is="true">n</mi><mo is="true">−</mo><mn is="true">1</mn><mo is="true">)</mo></mrow><mn is="true">2</mn></mfrac></math></span></span><script type="math/mml" id="MathJax-Element-87"><math><mfrac is="true"><mrow is="true"><mi is="true">n</mi><mo is="true">(</mo><mi is="true">n</mi><mo is="true">−</mo><mn is="true">1</mn><mo is="true">)</mo></mrow><mn is="true">2</mn></mfrac></math></script></span>. This measure indicates how densely the neighbours of the target word are connected among themselves.</p><p id="p0044"><strong>Structural Similarity (SS):</strong> For each pair of words (<em>w<sub>i</sub>, w<sub>j</sub></em>) in the cluster <em>S</em>, the structural similarity <em>SS</em>(<em>w<sub>i</sub>, w<sub>j</sub></em>) is computed as:<span class="display"><span id="eq0003" class="formula"><span class="label">(3)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-88-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>S</mi><mi is=&quot;true&quot;>S</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mi is=&quot;true&quot;>i</mi></msub><mo is=&quot;true&quot;>,</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mi is=&quot;true&quot;>j</mi></msub><mo is=&quot;true&quot;>)</mo></mrow><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><mfrac is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>N</mi><mi is=&quot;true&quot;>c</mi></msub><msqrt is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>d</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>g</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mi is=&quot;true&quot;>i</mi></msub><mo is=&quot;true&quot;>)</mo></mrow><mo is=&quot;true&quot;>*</mo><mi is=&quot;true&quot;>d</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>g</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mi is=&quot;true&quot;>j</mi></msub><mo is=&quot;true&quot;>)</mo></mrow></mrow></msqrt></mfrac></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="28.617ex" height="5.653ex" viewBox="0 -1111.4 12321.2 2434.1" role="img" focusable="false" style="vertical-align: -3.072ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-53"></use></g><g is="true" transform="translate(645,0)"><use xlink:href="#MJMATHI-53"></use></g><g is="true" transform="translate(1457,0)"><use xlink:href="#MJMAIN-28" is="true"></use><g is="true" transform="translate(389,0)"><g is="true"><use xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(716,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g></g><g is="true" transform="translate(1450,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(1895,0)"><g is="true"><use xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(716,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6A"></use></g></g><use xlink:href="#MJMAIN-29" is="true" x="3003" y="0"></use></g><g is="true" transform="translate(5128,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(5907,0)"><g transform="translate(397,0)"><rect stroke="none" width="5896" height="60" x="0" y="220"></rect><g is="true" transform="translate(2520,521)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-4E"></use></g><g is="true" transform="translate(568,-107)"><use transform="scale(0.5)" xlink:href="#MJMATHI-63"></use></g></g><g is="true" transform="translate(60,-753)"><use transform="scale(0.707)" xlink:href="#MJSZ2-221A" x="0" y="-19"></use><rect stroke="none" width="5068" height="42" x="707" y="758"></rect><g transform="translate(707,0)"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-64"></use></g><g is="true" transform="translate(370,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(700,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-67"></use></g><g is="true" transform="translate(1039,0)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(275,0)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(506,-107)"><use transform="scale(0.5)" xlink:href="#MJMATHI-69"></use></g></g><g is="true" transform="translate(1025,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-29"></use></g></g><g is="true" transform="translate(2340,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2A"></use></g><g is="true" transform="translate(2694,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-64"></use></g><g is="true" transform="translate(3064,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(3394,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-67"></use></g><g is="true" transform="translate(3734,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-28" is="true"></use><g is="true" transform="translate(275,0)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(506,-107)"><use transform="scale(0.5)" xlink:href="#MJMATHI-6A"></use></g></g><use transform="scale(0.707)" xlink:href="#MJMAIN-29" is="true" x="1497" y="0"></use></g></g></g></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">S</mi><mi is="true">S</mi><mrow is="true"><mo is="true">(</mo><msub is="true"><mi is="true">w</mi><mi is="true">i</mi></msub><mo is="true">,</mo><msub is="true"><mi is="true">w</mi><mi is="true">j</mi></msub><mo is="true">)</mo></mrow><mo linebreak="goodbreak" is="true">=</mo><mfrac is="true"><msub is="true"><mi is="true">N</mi><mi is="true">c</mi></msub><msqrt is="true"><mrow is="true"><mi is="true">d</mi><mi is="true">e</mi><mi is="true">g</mi><mrow is="true"><mo is="true">(</mo><msub is="true"><mi is="true">w</mi><mi is="true">i</mi></msub><mo is="true">)</mo></mrow><mo is="true">*</mo><mi is="true">d</mi><mi is="true">e</mi><mi is="true">g</mi><mrow is="true"><mo is="true">(</mo><msub is="true"><mi is="true">w</mi><mi is="true">j</mi></msub><mo is="true">)</mo></mrow></mrow></msqrt></mfrac></mrow></math></span></span><script type="math/mml" id="MathJax-Element-88"><math><mrow is="true"><mi is="true">S</mi><mi is="true">S</mi><mrow is="true"><mo is="true">(</mo><msub is="true"><mi is="true">w</mi><mi is="true">i</mi></msub><mo is="true">,</mo><msub is="true"><mi is="true">w</mi><mi is="true">j</mi></msub><mo is="true">)</mo></mrow><mo linebreak="goodbreak" is="true">=</mo><mfrac is="true"><msub is="true"><mi is="true">N</mi><mi is="true">c</mi></msub><msqrt is="true"><mrow is="true"><mi is="true">d</mi><mi is="true">e</mi><mi is="true">g</mi><mrow is="true"><mo is="true">(</mo><msub is="true"><mi is="true">w</mi><mi is="true">i</mi></msub><mo is="true">)</mo></mrow><mo is="true">*</mo><mi is="true">d</mi><mi is="true">e</mi><mi is="true">g</mi><mrow is="true"><mo is="true">(</mo><msub is="true"><mi is="true">w</mi><mi is="true">j</mi></msub><mo is="true">)</mo></mrow></mrow></msqrt></mfrac></mrow></math></script></span></span></span>where <em>N<sub>c</sub></em> denotes the number of common neighbors of <em>w<sub>i</sub></em> and <em>w<sub>j</sub></em> in the induced graph and <em>deg</em>(<em>w<sub>k</sub></em>) denotes the degree of <em>w<sub>k</sub></em> in the induced graph, for <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-89-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>k</mi><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><mi is=&quot;true&quot;>i</mi><mo is=&quot;true&quot;>,</mo><mi is=&quot;true&quot;>j</mi></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.104ex" height="2.458ex" viewBox="0 -792.8 3058.7 1058.4" role="img" focusable="false" style="vertical-align: -0.617ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-6B"></use></g><g is="true" transform="translate(799,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(1855,0)"><use xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(2201,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(2646,0)"><use xlink:href="#MJMATHI-6A"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">k</mi><mo linebreak="goodbreak" is="true">=</mo><mi is="true">i</mi><mo is="true">,</mo><mi is="true">j</mi></mrow></math></span></span><script type="math/mml" id="MathJax-Element-89"><math><mrow is="true"><mi is="true">k</mi><mo linebreak="goodbreak" is="true">=</mo><mi is="true">i</mi><mo is="true">,</mo><mi is="true">j</mi></mrow></math></script></span>. The average structural similarity for the cluster <em>S</em> is computed by averaging the structural similarity of all the word pairs. This measure indicates the cohesiveness among the neighborhood of the target word.</p><p id="p0045"><strong>Average Path Length (APL):</strong> To compute average path length of <em>S</em>, we first find the shortest path length between <em>w</em> and the words <em>w<sub>i</sub></em>, in the induced graph of <em>S</em>. Let <em>spl<sub>i</sub></em> denote the shortest path distance from <em>w</em> to <em>w<sub>i</sub></em>. The average path length is defined as:<span class="display"><span id="eq0004" class="formula"><span class="label">(4)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-90-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>A</mi><mi is=&quot;true&quot;>P</mi><mi is=&quot;true&quot;>L</mi><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><munder is=&quot;true&quot;><mo is=&quot;true&quot;>&amp;#x2211;</mo><mi is=&quot;true&quot;>i</mi></munder><mi is=&quot;true&quot;>s</mi><mi is=&quot;true&quot;>p</mi><msub is=&quot;true&quot;><mi is=&quot;true&quot;>l</mi><mi is=&quot;true&quot;>i</mi></msub><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>/</mo><mi is=&quot;true&quot;>n</mi></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="18.12ex" height="2.831ex" viewBox="0 -847.3 7801.8 1219.1" role="img" focusable="false" style="vertical-align: -0.864ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-41"></use></g><g is="true" transform="translate(750,0)"><use xlink:href="#MJMATHI-50"></use></g><g is="true" transform="translate(1502,0)"><use xlink:href="#MJMATHI-4C"></use></g><g is="true" transform="translate(2461,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(3517,0)"><g is="true"><use xlink:href="#MJSZ1-2211"></use></g><g is="true" transform="translate(1056,-287)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g></g><g is="true" transform="translate(5085,0)"><use xlink:href="#MJMATHI-73"></use></g><g is="true" transform="translate(5554,0)"><use xlink:href="#MJMATHI-70"></use></g><g is="true" transform="translate(6058,0)"><g is="true"><use xlink:href="#MJMATHI-6C"></use></g><g is="true" transform="translate(298,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g></g><g is="true" transform="translate(6700,0)"><use xlink:href="#MJMAIN-2F"></use></g><g is="true" transform="translate(7201,0)"><use xlink:href="#MJMATHI-6E"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">A</mi><mi is="true">P</mi><mi is="true">L</mi><mo linebreak="goodbreak" is="true">=</mo><munder is="true"><mo is="true">∑</mo><mi is="true">i</mi></munder><mi is="true">s</mi><mi is="true">p</mi><msub is="true"><mi is="true">l</mi><mi is="true">i</mi></msub><mo linebreak="goodbreak" is="true">/</mo><mi is="true">n</mi></mrow></math></span></span><script type="math/mml" id="MathJax-Element-90"><math><mrow is="true"><mi is="true">A</mi><mi is="true">P</mi><mi is="true">L</mi><mo linebreak="goodbreak" is="true">=</mo><munder is="true"><mo is="true">∑</mo><mi is="true">i</mi></munder><mi is="true">s</mi><mi is="true">p</mi><msub is="true"><mi is="true">l</mi><mi is="true">i</mi></msub><mo linebreak="goodbreak" is="true">/</mo><mi is="true">n</mi></mrow></math></script></span></span></span> where <em>n</em> is the number of words in the cluster <em>S</em>. This measure captures how the distance between the target word and the words in the birth cluster changes over time in the network. If the words in the birth cluster come close over time, it signifies that the target word is emerging with a sense captured by the birth cluster.</p><div><p id="p0046"><a name="btbl0001" href="#tbl0001" class="workspace-trigger">Table&nbsp;1</a> notes the values obtained for these network properties for the induced subgraphs of the reported ‘birth’ clusters for ‘registers’ and ‘quotes’ across the two time periods. The fractional changes observed for the three network properties show a clear demarcation between the two cases. Fractional change (Δ) of any network measure <em>P</em> is defined as,<span class="display"><span id="eq0005" class="formula"><span class="label">(5)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-91-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mstyle mathvariant=&quot;normal&quot; is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x394;</mi></mstyle><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>P</mi><mo is=&quot;true&quot;>)</mo></mrow><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>P</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>t</mi><mn is=&quot;true&quot;>2</mn></msub><mo is=&quot;true&quot;>)</mo></mrow><mo linebreak=&quot;badbreak&quot; is=&quot;true&quot;>&amp;#x2212;</mo><mi is=&quot;true&quot;>P</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>t</mi><mn is=&quot;true&quot;>1</mn></msub><mo is=&quot;true&quot;>)</mo></mrow><mo is=&quot;true&quot;>)</mo></mrow><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>/</mo><mi is=&quot;true&quot;>P</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>t</mi><mn is=&quot;true&quot;>1</mn></msub><mo is=&quot;true&quot;>)</mo></mrow></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="32.682ex" height="2.709ex" viewBox="0 -847.3 14071.6 1166.2" role="img" focusable="false" style="vertical-align: -0.741ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMAIN-394"></use></g></g><g is="true" transform="translate(1000,0)"><g is="true"><use xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(389,0)"><use xlink:href="#MJMATHI-50"></use></g><g is="true" transform="translate(1141,0)"><use xlink:href="#MJMAIN-29"></use></g></g><g is="true" transform="translate(2808,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(3864,0)"><g is="true"><use xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(389,0)"><use xlink:href="#MJMATHI-50"></use></g><g is="true" transform="translate(1307,0)"><g is="true"><use xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(389,0)"><g is="true"><use xlink:href="#MJMATHI-74"></use></g><g is="true" transform="translate(361,-150)"><use transform="scale(0.707)" xlink:href="#MJMAIN-32"></use></g></g><g is="true" transform="translate(1204,0)"><use xlink:href="#MJMAIN-29"></use></g></g><g is="true" transform="translate(3124,0)"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(4125,0)"><use xlink:href="#MJMATHI-50"></use></g><g is="true" transform="translate(5043,0)"><g is="true"><use xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(389,0)"><g is="true"><use xlink:href="#MJMATHI-74"></use></g><g is="true" transform="translate(361,-150)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g></g><g is="true" transform="translate(1204,0)"><use xlink:href="#MJMAIN-29"></use></g></g><g is="true" transform="translate(6637,0)"><use xlink:href="#MJMAIN-29"></use></g></g><g is="true" transform="translate(11058,0)"><use xlink:href="#MJMAIN-2F"></use></g><g is="true" transform="translate(11558,0)"><use xlink:href="#MJMATHI-50"></use></g><g is="true" transform="translate(12477,0)"><g is="true"><use xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(389,0)"><g is="true"><use xlink:href="#MJMATHI-74"></use></g><g is="true" transform="translate(361,-150)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g></g><g is="true" transform="translate(1204,0)"><use xlink:href="#MJMAIN-29"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mstyle mathvariant="normal" is="true"><mi is="true">Δ</mi></mstyle><mrow is="true"><mo is="true">(</mo><mi is="true">P</mi><mo is="true">)</mo></mrow><mo linebreak="goodbreak" is="true">=</mo><mrow is="true"><mo is="true">(</mo><mi is="true">P</mi><mrow is="true"><mo is="true">(</mo><msub is="true"><mi is="true">t</mi><mn is="true">2</mn></msub><mo is="true">)</mo></mrow><mo linebreak="badbreak" is="true">−</mo><mi is="true">P</mi><mrow is="true"><mo is="true">(</mo><msub is="true"><mi is="true">t</mi><mn is="true">1</mn></msub><mo is="true">)</mo></mrow><mo is="true">)</mo></mrow><mo linebreak="goodbreak" is="true">/</mo><mi is="true">P</mi><mrow is="true"><mo is="true">(</mo><msub is="true"><mi is="true">t</mi><mn is="true">1</mn></msub><mo is="true">)</mo></mrow></mrow></math></span></span><script type="math/mml" id="MathJax-Element-91"><math><mrow is="true"><mstyle mathvariant="normal" is="true"><mi is="true">Δ</mi></mstyle><mrow is="true"><mo is="true">(</mo><mi is="true">P</mi><mo is="true">)</mo></mrow><mo linebreak="goodbreak" is="true">=</mo><mrow is="true"><mo is="true">(</mo><mi is="true">P</mi><mrow is="true"><mo is="true">(</mo><msub is="true"><mi is="true">t</mi><mn is="true">2</mn></msub><mo is="true">)</mo></mrow><mo linebreak="badbreak" is="true">−</mo><mi is="true">P</mi><mrow is="true"><mo is="true">(</mo><msub is="true"><mi is="true">t</mi><mn is="true">1</mn></msub><mo is="true">)</mo></mrow><mo is="true">)</mo></mrow><mo linebreak="goodbreak" is="true">/</mo><mi is="true">P</mi><mrow is="true"><mo is="true">(</mo><msub is="true"><mi is="true">t</mi><mn is="true">1</mn></msub><mo is="true">)</mo></mrow></mrow></math></script></span></span></span> where <em>t</em><sub>1</sub> and <em>t</em><sub>2</sub> are old and new time periods respectively. The change observed for the ‘birth’ cluster of ‘registers’ is significantly higher than that in ‘quotes’<a name="bfn0003" href="#fn0003" class="workspace-trigger"><sup>3</sup></a>.</p><div class="tables colsep-0 frame-topbot rowsep-0" id="tbl0001"><span class="captions"><span id="cap0006"><p id="sp0010"><span class="label">Table 1</span>. The network properties of the induced subgraphs of a true positive (‘registers’) and a false positive (‘quotes’) for the time periods 1909–1953 (<em>t</em><sub>1</sub>) and 2002–2005 (<em>t</em><sub>2</sub>). The fractional changes (Δ) in network properties are significantly higher for ‘registers’ compared to ‘quotes’.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col" class="align-left valign-top">Word</th><th scope="col" class="align-left valign-top">ED (<em>t</em><sub>1</sub>)</th><th scope="col" class="align-left valign-top">ED (<em>t</em><sub>2</sub>)</th><th scope="col" class="align-left valign-top">SS (<em>t</em><sub>1</sub>)</th><th scope="col" class="align-left valign-top">SS (<em>t</em><sub>2</sub>)</th><th scope="col" class="align-left valign-top">APL (<em>t</em><sub>1</sub>)</th><th scope="col" class="align-left valign-top">APL (<em>t</em><sub>2</sub>)</th><th scope="col" class="align-left valign-top">Δ (ED, SS, APL)</th></tr></thead><tbody><tr><td class="align-left valign-top"><em>registers</em></td><td class="align-left valign-top">0.108</td><td class="align-left valign-top">0.546</td><td class="align-left valign-top">0.076</td><td class="align-left valign-top">0.516</td><td class="align-left valign-top">1.9</td><td class="align-left valign-top">1</td><td class="align-left valign-top">4.045, 5.771, -0.9</td></tr><tr><td class="align-left valign-top">quotes</td><td class="align-left valign-top">0.858</td><td class="align-left valign-top">0.833</td><td class="align-left valign-top">0.835</td><td class="align-left valign-top">0.622</td><td class="align-left valign-top">1.72</td><td class="align-left valign-top">1</td><td class="align-left valign-top">-0.029, -0.255, -0.72</td></tr></tbody></table></div></div></div><div><p id="p0047">We now compute these parameter values for all the 49 candidate cases. The mean values obtained for the true positives (TP) and false positives (FP) are shown in <a name="btbl0002" href="#tbl0002" class="workspace-trigger">Table&nbsp;2</a>. The findings are consistent with those obtained for ‘registers’ and ‘quotes’.</p><div class="tables colsep-0 frame-topbot rowsep-0" id="tbl0002"><span class="captions"><span id="cap0007"><p id="sp0011"><span class="label">Table 2</span>. Mean values of the network properties of the induced subgraphs of 31 true positives and 18 false positives for the time periods 1909–1953 (<em>t</em><sub>1</sub>) and 2002–2005 (<em>t</em><sub>2</sub>). The mean fractional changes (Δ) in network properties are significantly higher for the true positives (TP) as compared to the false positives (FP) which indicate that the words emerged with new senses have undergone a drastic change in network connections in their neighborhood over time.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col" class="align-left valign-top">Word</th><th scope="col" class="align-left valign-top">ED (<em>t</em><sub>1</sub>)</th><th scope="col" class="align-left valign-top">ED (<em>t</em><sub>2</sub>)</th><th scope="col" class="align-left valign-top">SS (<em>t</em><sub>1</sub>)</th><th scope="col" class="align-left valign-top">SS (<em>t</em><sub>2</sub>)</th><th scope="col" class="align-left valign-top">APL (<em>t</em><sub>1</sub>)</th><th scope="col" class="align-left valign-top">APL (<em>t</em><sub>2</sub>)</th><th scope="col" class="align-left valign-top">Δ (ED, SS, APL)</th></tr></thead><tbody><tr><td class="align-left valign-top"><em>TP</em></td><td class="align-left valign-top">0.34</td><td class="align-left valign-top">0.772</td><td class="align-left valign-top">0.311</td><td class="align-left valign-top">0.647</td><td class="align-left valign-top">1.941</td><td class="align-left valign-top">1</td><td class="align-left valign-top">2.388, 4.654, -0.941</td></tr><tr><td class="align-left valign-top">FP</td><td class="align-left valign-top">0.576</td><td class="align-left valign-top">0.828</td><td class="align-left valign-top">0.574</td><td class="align-left valign-top">0.681</td><td class="align-left valign-top">1.828</td><td class="align-left valign-top">1</td><td class="align-left valign-top">0.747, 0.507, -0.828</td></tr></tbody></table></div></div></div><p id="p0048"><span><span>We, therefore, use the fractional changes in the three network properties over time as three features to classify the remaining candidate ‘birth’ words into true positives (actual ‘birth’) or false positives (false ‘birth’). We use different <a href="/topics/computer-science/classification-machine-learning" title="Learn more about classifiers from ScienceDirect's AI-generated Topic Pages" class="topic-link">classifiers</a> like Naive Bayes, </span><a href="/topics/computer-science/support-vector-machine" title="Learn more about Support Vector Machine from ScienceDirect's AI-generated Topic Pages" class="topic-link">Support Vector Machine</a> (SVM), </span><a href="/topics/computer-science/random-decision-forest" title="Learn more about Random Forest from ScienceDirect's AI-generated Topic Pages" class="topic-link">Random Forest</a>, etc. for this purpose and report the result of SVM, which was the best performing classifier.</p><section id="sec0017"><h3 id="sctt0020" class="u-h4 u-margin-m-top u-margin-xs-bottom">4.1. Investigation using network representation learning approaches</h3><p id="p0049">In addition to the proposed three metrics inspired by network science, we also explore the applicability of network representation learning methods in this task. Recall that, we have the DT networks both from the old (<em>DT<sub>old</sub></em>) and the new (<em>DT<sub>new</sub></em>) time periods. First, we apply network representation learning methods to obtain continuous feature representations for nodes in networks for both the time periods. As discussed in <a name="bsec0016" href="#sec0016" class="workspace-trigger">Section&nbsp;4</a>, for each candidate word <em>w</em>, we have the ‘birth’ cluster from 2002 to 2005, which is represented by a set of words <em>S</em>. Intuitively, if the words in set <em>S</em> together represent a new sense for <em>w</em> in 2002–2005 which is not present in 1909–1953, the relative similarity in the vector space between the words in <em>S</em> among themselves as well as with the target words would be much higher in the 2002–2005 DT in comparison to the 1909–1953 DT. In order to measure these similarities, we propose the following two metrics.</p><p id="p0050"><strong>Intra-cluster Average Similarity (IAS):</strong> To compute this metric for <em>S</em><span>, we first find the pairwise <a href="/topics/computer-science/cosine-similarity" title="Learn more about cosine similarity from ScienceDirect's AI-generated Topic Pages" class="topic-link">cosine similarity</a> (</span><em>CSim</em>) between the words in <em>S</em>. Then we consider the average of these cosine similarities. IAS is defined as:<span class="display"><span id="eq0006" class="formula"><span class="label">(6)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-92-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>I</mi><mi is=&quot;true&quot;>A</mi><mi is=&quot;true&quot;>S</mi><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><mfrac is=&quot;true&quot;><mn is=&quot;true&quot;>2</mn><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>|</mo><mi is=&quot;true&quot;>S</mi><mo is=&quot;true&quot;>|</mo><mo is=&quot;true&quot;>*</mo><mo is=&quot;true&quot;>|</mo><mi is=&quot;true&quot;>S</mi><mo is=&quot;true&quot;>&amp;#x2212;</mo><mn is=&quot;true&quot;>1</mn><mo is=&quot;true&quot;>|</mo></mrow></mfrac><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>*</mo><munder is=&quot;true&quot;><mo is=&quot;true&quot;>&amp;#x2211;</mo><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mi is=&quot;true&quot;>i</mi></msub><mo is=&quot;true&quot;>,</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mi is=&quot;true&quot;>j</mi></msub><mo is=&quot;true&quot;>&amp;#x2208;</mo><mi is=&quot;true&quot;>S</mi><mo is=&quot;true&quot;>,</mo><mi is=&quot;true&quot;>i</mi><mo linebreak=&quot;badbreak&quot; is=&quot;true&quot;>&amp;lt;</mo><mi is=&quot;true&quot;>j</mi></mrow></munder><mi is=&quot;true&quot;>C</mi><mi is=&quot;true&quot;>S</mi><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>m</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mi is=&quot;true&quot;>i</mi></msub><mo is=&quot;true&quot;>,</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mi is=&quot;true&quot;>j</mi></msub><mo is=&quot;true&quot;>)</mo></mrow></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="44.022ex" height="3.813ex" viewBox="0 -952.9 18953.8 1641.7" role="img" focusable="false" style="vertical-align: -1.6ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-49"></use></g><g is="true" transform="translate(504,0)"><use xlink:href="#MJMATHI-41"></use></g><g is="true" transform="translate(1255,0)"><use xlink:href="#MJMATHI-53"></use></g><g is="true" transform="translate(2178,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(2956,0)"><g transform="translate(397,0)"><rect stroke="none" width="3078" height="60" x="0" y="220"></rect><g is="true" transform="translate(1362,409)"><use transform="scale(0.707)" xlink:href="#MJMAIN-32"></use></g><g is="true" transform="translate(60,-441)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-7C"></use></g><g is="true" transform="translate(196,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-53"></use></g><g is="true" transform="translate(653,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-7C"></use></g><g is="true" transform="translate(850,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2A"></use></g><g is="true" transform="translate(1204,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-7C"></use></g><g is="true" transform="translate(1401,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-53"></use></g><g is="true" transform="translate(1857,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(2408,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(2761,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-7C"></use></g></g></g></g><g is="true" transform="translate(6775,0)"><use xlink:href="#MJMAIN-2A"></use></g><g is="true" transform="translate(7498,0)"><g is="true"><use xlink:href="#MJSZ1-2211"></use></g><g is="true" transform="translate(1056,-287)"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(506,-107)"><use transform="scale(0.5)" xlink:href="#MJMATHI-69"></use></g></g><g is="true" transform="translate(750,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(947,0)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(506,-107)"><use transform="scale(0.5)" xlink:href="#MJMATHI-6A"></use></g></g><g is="true" transform="translate(1730,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2208"></use></g><g is="true" transform="translate(2202,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-53"></use></g><g is="true" transform="translate(2659,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(2855,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(3100,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-3C"></use></g><g is="true" transform="translate(3650,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6A"></use></g></g></g><g is="true" transform="translate(12764,0)"><use xlink:href="#MJMATHI-43"></use></g><g is="true" transform="translate(13524,0)"><use xlink:href="#MJMATHI-53"></use></g><g is="true" transform="translate(14170,0)"><use xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(14515,0)"><use xlink:href="#MJMATHI-6D"></use></g><g is="true" transform="translate(15560,0)"><use xlink:href="#MJMAIN-28" is="true"></use><g is="true" transform="translate(389,0)"><g is="true"><use xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(716,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g></g><g is="true" transform="translate(1450,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(1895,0)"><g is="true"><use xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(716,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6A"></use></g></g><use xlink:href="#MJMAIN-29" is="true" x="3003" y="0"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">I</mi><mi is="true">A</mi><mi is="true">S</mi><mo linebreak="goodbreak" is="true">=</mo><mfrac is="true"><mn is="true">2</mn><mrow is="true"><mo is="true">|</mo><mi is="true">S</mi><mo is="true">|</mo><mo is="true">*</mo><mo is="true">|</mo><mi is="true">S</mi><mo is="true">−</mo><mn is="true">1</mn><mo is="true">|</mo></mrow></mfrac><mo linebreak="goodbreak" is="true">*</mo><munder is="true"><mo is="true">∑</mo><mrow is="true"><msub is="true"><mi is="true">w</mi><mi is="true">i</mi></msub><mo is="true">,</mo><msub is="true"><mi is="true">w</mi><mi is="true">j</mi></msub><mo is="true">∈</mo><mi is="true">S</mi><mo is="true">,</mo><mi is="true">i</mi><mo linebreak="badbreak" is="true">&lt;</mo><mi is="true">j</mi></mrow></munder><mi is="true">C</mi><mi is="true">S</mi><mi is="true">i</mi><mi is="true">m</mi><mrow is="true"><mo is="true">(</mo><msub is="true"><mi is="true">w</mi><mi is="true">i</mi></msub><mo is="true">,</mo><msub is="true"><mi is="true">w</mi><mi is="true">j</mi></msub><mo is="true">)</mo></mrow></mrow></math></span></span><script type="math/mml" id="MathJax-Element-92"><math><mrow is="true"><mi is="true">I</mi><mi is="true">A</mi><mi is="true">S</mi><mo linebreak="goodbreak" is="true">=</mo><mfrac is="true"><mn is="true">2</mn><mrow is="true"><mo is="true">|</mo><mi is="true">S</mi><mo is="true">|</mo><mo is="true">*</mo><mo is="true">|</mo><mi is="true">S</mi><mo is="true">−</mo><mn is="true">1</mn><mo is="true">|</mo></mrow></mfrac><mo linebreak="goodbreak" is="true">*</mo><munder is="true"><mo is="true">∑</mo><mrow is="true"><msub is="true"><mi is="true">w</mi><mi is="true">i</mi></msub><mo is="true">,</mo><msub is="true"><mi is="true">w</mi><mi is="true">j</mi></msub><mo is="true">∈</mo><mi is="true">S</mi><mo is="true">,</mo><mi is="true">i</mi><mo linebreak="badbreak" is="true">&lt;</mo><mi is="true">j</mi></mrow></munder><mi is="true">C</mi><mi is="true">S</mi><mi is="true">i</mi><mi is="true">m</mi><mrow is="true"><mo is="true">(</mo><msub is="true"><mi is="true">w</mi><mi is="true">i</mi></msub><mo is="true">,</mo><msub is="true"><mi is="true">w</mi><mi is="true">j</mi></msub><mo is="true">)</mo></mrow></mrow></math></script></span></span></span></p><p id="p0051"><strong>Average Similarity with Target word (AST):</strong> To compute this metric for <em>S</em>, we first find the cosine similarity (<em>CSim</em>) between the target word <em>w</em> and the words in <em>S</em>. Then, we consider the average of these cosine similarities. AST is defined as:<span class="display"><span id="eq0007" class="formula"><span class="label">(7)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-93-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>A</mi><mi is=&quot;true&quot;>S</mi><mi is=&quot;true&quot;>T</mi><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><mfrac is=&quot;true&quot;><mn is=&quot;true&quot;>1</mn><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>|</mo><mi is=&quot;true&quot;>S</mi><mo is=&quot;true&quot;>|</mo></mrow></mfrac><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>*</mo><munder is=&quot;true&quot;><mo is=&quot;true&quot;>&amp;#x2211;</mo><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mi is=&quot;true&quot;>i</mi></msub><mo is=&quot;true&quot;>&amp;#x2208;</mo><mi is=&quot;true&quot;>S</mi></mrow></munder><mi is=&quot;true&quot;>C</mi><mi is=&quot;true&quot;>S</mi><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>m</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>w</mi><mo is=&quot;true&quot;>,</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mi is=&quot;true&quot;>i</mi></msub><mo is=&quot;true&quot;>)</mo></mrow></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="33.421ex" height="3.813ex" viewBox="0 -952.9 14389.6 1641.7" role="img" focusable="false" style="vertical-align: -1.6ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-41"></use></g><g is="true" transform="translate(750,0)"><use xlink:href="#MJMATHI-53"></use></g><g is="true" transform="translate(1396,0)"><use xlink:href="#MJMATHI-54"></use></g><g is="true" transform="translate(2378,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(3156,0)"><g transform="translate(397,0)"><rect stroke="none" width="970" height="60" x="0" y="220"></rect><g is="true" transform="translate(308,409)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(60,-441)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-7C"></use></g><g is="true" transform="translate(196,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-53"></use></g><g is="true" transform="translate(653,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-7C"></use></g></g></g></g><g is="true" transform="translate(4867,0)"><use xlink:href="#MJMAIN-2A"></use></g><g is="true" transform="translate(5589,0)"><g is="true"><use xlink:href="#MJSZ1-2211"></use></g><g is="true" transform="translate(1056,-287)"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(506,-107)"><use transform="scale(0.5)" xlink:href="#MJMATHI-69"></use></g></g><g is="true" transform="translate(750,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2208"></use></g><g is="true" transform="translate(1222,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-53"></use></g></g></g><g is="true" transform="translate(8591,0)"><use xlink:href="#MJMATHI-43"></use></g><g is="true" transform="translate(9351,0)"><use xlink:href="#MJMATHI-53"></use></g><g is="true" transform="translate(9997,0)"><use xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(10342,0)"><use xlink:href="#MJMATHI-6D"></use></g><g is="true" transform="translate(11388,0)"><g is="true"><use xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(389,0)"><use xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(1106,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(1551,0)"><g is="true"><use xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(716,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g></g><g is="true" transform="translate(2611,0)"><use xlink:href="#MJMAIN-29"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">A</mi><mi is="true">S</mi><mi is="true">T</mi><mo linebreak="goodbreak" is="true">=</mo><mfrac is="true"><mn is="true">1</mn><mrow is="true"><mo is="true">|</mo><mi is="true">S</mi><mo is="true">|</mo></mrow></mfrac><mo linebreak="goodbreak" is="true">*</mo><munder is="true"><mo is="true">∑</mo><mrow is="true"><msub is="true"><mi is="true">w</mi><mi is="true">i</mi></msub><mo is="true">∈</mo><mi is="true">S</mi></mrow></munder><mi is="true">C</mi><mi is="true">S</mi><mi is="true">i</mi><mi is="true">m</mi><mrow is="true"><mo is="true">(</mo><mi is="true">w</mi><mo is="true">,</mo><msub is="true"><mi is="true">w</mi><mi is="true">i</mi></msub><mo is="true">)</mo></mrow></mrow></math></span></span><script type="math/mml" id="MathJax-Element-93"><math><mrow is="true"><mi is="true">A</mi><mi is="true">S</mi><mi is="true">T</mi><mo linebreak="goodbreak" is="true">=</mo><mfrac is="true"><mn is="true">1</mn><mrow is="true"><mo is="true">|</mo><mi is="true">S</mi><mo is="true">|</mo></mrow></mfrac><mo linebreak="goodbreak" is="true">*</mo><munder is="true"><mo is="true">∑</mo><mrow is="true"><msub is="true"><mi is="true">w</mi><mi is="true">i</mi></msub><mo is="true">∈</mo><mi is="true">S</mi></mrow></munder><mi is="true">C</mi><mi is="true">S</mi><mi is="true">i</mi><mi is="true">m</mi><mrow is="true"><mo is="true">(</mo><mi is="true">w</mi><mo is="true">,</mo><msub is="true"><mi is="true">w</mi><mi is="true">i</mi></msub><mo is="true">)</mo></mrow></mrow></math></script></span></span></span></p><p id="p0052">We use the fractional change (Δ) (as described in <a name="beq0005" href="#eq0005" class="workspace-trigger">Eq.&nbsp;(5)</a>), of these two measures as features to classify the candidate ‘birth’ words into true positives (actual ‘birth’) or false positives (false ‘birth’).</p><p id="p0053">Now, from the DT network of each time period, in order to prepare the vector representations for each node, we explore two state-of-the-art network representation learning models as discussed below.</p><p id="p0054"><strong>Deepwalk:</strong> Deepwalk&nbsp;(<a name="bbib0042" href="#bib0042" class="workspace-trigger">Perozzi&nbsp;et&nbsp;al., 2014</a><span>) learns social representations of a graph’s vertices by modeling a stream of short <a href="/topics/computer-science/random-walks" title="Learn more about random walks from ScienceDirect's AI-generated Topic Pages" class="topic-link">random walks</a>. Social representations signify latent features of the vertices that capture neighborhood similarity and community membership. Using local information from the truncated random walks as input, this method learns a representation that encodes structural regularities.</span></p><p id="p0055"><strong>node2vec:</strong> node2vec&nbsp;(<a name="bbib0022" href="#bib0022" class="workspace-trigger">Grover &amp; Leskovec,&nbsp;2016</a>) is an algorithmic framework for scalable feature learning in networks, that maximizes the likelihood of preserving network neighborhoods of nodes in a <em>d</em><span>-dimensional feature space. This algorithm can learn representations that organize nodes based on their network roles and/or communities they belong to by developing a family of <a href="/topics/computer-science/biased-random-walks" title="Learn more about biased random walks from ScienceDirect's AI-generated Topic Pages" class="topic-link">biased random walks</a>, which efficiently explore diverse neighborhoods of a given node.</span></p></section><section id="sec0018"><h3 id="sctt0021" class="u-h4 u-margin-m-top u-margin-xs-bottom">4.2. Investigation using fastText embeddings</h3><p id="p0056">We further investigate the usefulness of embeddings obtained directly from corpus compared to the embeddings obtained using network embeddings from network representation of corpus. We obtain fastText embeddings&nbsp;(<a name="bbib0006" href="#bib0006" class="workspace-trigger">Bojanowski&nbsp;et&nbsp;al., 2017</a>) from both the Google book corpus of old and new time periods. We use the same metrics (IAS, AST) as proposed in <a name="bsec0017" href="#sec0017" class="workspace-trigger">Section&nbsp;4.1</a><span> as features to be plugged into a classifier, but in order to compute those two metrics, we use the fastText embeddings of words in place of network embeddings (Deepwalk, node2vec). We use the <a href="/topics/computer-science/vector-dimension" title="Learn more about vector dimension from ScienceDirect's AI-generated Topic Pages" class="topic-link">vector dimension</a> of 128 to be consistent with the analysis using network embeddings.</span></p></section></section><section id="sec0019"><h2 id="sctt0022" class="u-h3 u-margin-l-top u-margin-xs-bottom">5. Experimental results</h2><p id="p0057">For experimental evaluation, we start with the ‘birth’ cases reported by <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a> – 2740 cases (after removing the 49 cases used in training) for 1909–1953 - 2002–2005 (<em>T</em><sub>1</sub>)and 2468 cases for 1909–1953 - 2006–2008 (<em>T</em><sub>2</sub>). We first discuss how the gold standard dataset is prepared in <a name="bsec0020" href="#sec0020" class="workspace-trigger">Section&nbsp;5.1</a>. In <a name="bsec0021" href="#sec0021" class="workspace-trigger">Section&nbsp;5.2</a>, we run <a name="bbib0033" href="#bib0033" class="workspace-trigger">Lau&nbsp;et&nbsp;al.&nbsp;(2014)</a><span><span> over these birth cases to detect ‘novel’ sense as per Lau et&nbsp;al.’s algorithm. Separately, we also apply the proposed <a href="/topics/computer-science/support-vector-machine" title="Learn more about SVM from ScienceDirect's AI-generated Topic Pages" class="topic-link">SVM</a> </span><a href="/topics/computer-science/classification" title="Learn more about classification from ScienceDirect's AI-generated Topic Pages" class="topic-link">classification</a> model as a filtering step to obtain ‘filtered birth’ cases. This helps in designing a </span><em>comparative evaluation</em> of these algorithms as follows. From both the time period pairs (<em>T</em><sub>1</sub> and <em>T</em><sub>2</sub>), we take 100 random samples from the birth cases reported by <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a> and get them evaluated against gold standard dataset prepared by human annotators. For the same 100 random samples, we now use the outputs of <a name="bbib0033" href="#bib0033" class="workspace-trigger">Lau&nbsp;et&nbsp;al.&nbsp;(2014)</a> and the proposed approach and estimate the precision as well as recall of these. Note that, for our proposed SVM based model, even though we use these random 100 samples from both <em>T</em><sub>1</sub> and <em>T</em><sub>2</sub> for testing, the training set is fixed to the 49 birth cases taken from <em>T</em><sub>1</sub> provided by <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a>. This comparative evaluation shows, how much we achieve by applying our proposed model on top of the approach of <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a>. We also investigate how good our model performs if we apply it independent of <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a>. Next, we do an extensive feature analysis to explore the importance of each of the network measures. In <a name="bsec0024" href="#sec0024" class="workspace-trigger">Section&nbsp;5.3</a> we analyze the usefulness of features obtained using Deepwalk and node2vec independently as well as in combination with the proposed network features. Next, in <a name="bsec0028" href="#sec0028" class="workspace-trigger">Section&nbsp;5.4</a><span> we do the same analysis using <a href="/topics/computer-science/word-embeddings" title="Learn more about word embeddings from ScienceDirect's AI-generated Topic Pages" class="topic-link">word embeddings</a> obtained using fastText. As a final step, we perform an error analysis of our proposed approach in </span><a name="bsec0029" href="#sec0029" class="workspace-trigger">Section&nbsp;5.5</a>.</p><section id="sec0020"><h3 id="sctt0023" class="u-h4 u-margin-m-top u-margin-xs-bottom">5.1. Gold standard preparation</h3><div><p id="p0058">As far as we are aware of the literature, there is a scarcity of gold standard datasets, which in turn makes the evaluation task difficult for this particular problem of novel sense detection. This concern is also discussed in detail in the recent survey papers&nbsp;(<a name="bbib0031" href="#bib0031" class="workspace-trigger">Kutuzov, Øvrelid, Szymanski, Velldal, 2018</a>, <a name="bbib0049" href="#bib0049" class="workspace-trigger">Tahmasebi, Borin, Jatowt, 2018</a><span>). Therefore, we prepare a gold standard dataset using human annotations and perform all the evaluations against this gold standard dataset. Each of the candidate words is judged by three evaluators. These evaluators are graduate/post-graduate students, having a good background in <a href="/topics/computer-science/natural-language-processing" title="Learn more about Natural Language Processing from ScienceDirect's AI-generated Topic Pages" class="topic-link">Natural Language Processing</a> and well versed with the English language. They are unaware of each other, making the annotation process completely blind and independent. Evaluators are shown the detected ‘birth’ cluster from the newer time period and all the clusters from the older time period. They are asked to make a binary judgment as to whether the ‘birth’ cluster indicates a new sense of the candidate word, which is not present in any of the sense clusters of the previous time point.</span><a name="bfn0004" href="#fn0004" class="workspace-trigger"><sup>4</sup></a> Majority decision is taken in the disagreement. In total, we prepared annotations for a set of as large as <strong>365</strong> words (only nouns taken from Distributional Thesaurus)<a name="bfn0005" href="#fn0005" class="workspace-trigger"><sup>5</sup></a> which we believe is significant given the tedious manual judgment involved. In this process of manual annotation, we obtain an inter-annotator agreement (Fleiss’ <em>κ</em>&nbsp;(<a name="bbib0019" href="#bib0019" class="workspace-trigger">Fleiss,&nbsp;1971</a>)) of <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-94-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mn mathvariant=&quot;bold&quot; is=&quot;true&quot;>0</mn><mo is=&quot;true&quot;>.</mo><mn mathvariant=&quot;bold&quot; is=&quot;true&quot;>745</mn><mo is=&quot;true&quot;>,</mo></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.027ex" height="2.336ex" viewBox="0 -740.1 3025.7 1005.7" role="img" focusable="false" style="vertical-align: -0.617ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMAINB-30"></use></g><g is="true" transform="translate(575,0)"><use xlink:href="#MJMAIN-2E"></use></g><g is="true" transform="translate(1020,0)"><use xlink:href="#MJMAINB-37"></use><use xlink:href="#MJMAINB-34" x="575" y="0"></use><use xlink:href="#MJMAINB-35" x="1151" y="0"></use></g><g is="true" transform="translate(2747,0)"><use xlink:href="#MJMAIN-2C"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mn mathvariant="bold" is="true">0</mn><mo is="true">.</mo><mn mathvariant="bold" is="true">745</mn><mo is="true">,</mo></mrow></math></span></span><script type="math/mml" id="MathJax-Element-94"><math><mrow is="true"><mn mathvariant="bold" is="true">0</mn><mo is="true">.</mo><mn mathvariant="bold" is="true">745</mn><mo is="true">,</mo></mrow></math></script></span> which is <em>substantial</em>&nbsp;(<a name="bbib0054" href="#bib0054" class="workspace-trigger">Viera,&nbsp;Garrett&nbsp;et&nbsp;al., 2005</a>). <a name="btbl0003" href="#tbl0003" class="workspace-trigger">Table&nbsp;3</a> shows three example words from <em>T</em><sub>1</sub>, their ‘birth’ clusters as reported in <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a> and the manual evaluation result. The first three cases belong to computer or technology related sense of ‘sender’, ‘directories’ and ‘float’, which were absent from time point 1909–1953. On the other hand, the ‘birth’ clusters of ‘celebrity’ and ‘quiz’ represent an old sense which was also present in 1909–1953. Similarly, <a name="btbl0004" href="#tbl0004" class="workspace-trigger">Table&nbsp;4</a> shows manual evaluations results for three example cases, along with their novel sense as captured by <a name="bbib0033" href="#bib0033" class="workspace-trigger">Lau&nbsp;et&nbsp;al.&nbsp;(2014)</a>. This gold standard dataset is also one of our significant contributions and we make it publicly available to facilitate further research.</p><div class="tables colsep-0 frame-topbot rowsep-0" id="tbl0003"><span class="captions"><span id="cap0008"><p id="sp0012"><span class="label">Table 3</span>. Example ‘birth’ clusters reported in <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a> and manual evaluation. For each word, ‘birth’ cluster represents the words in the Chinese Whisper cluster which is flagged as a new sense by the model.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col" class="align-left valign-top">Word</th><th scope="col" class="align-left valign-top">‘birth’ cluster</th><th scope="col" class="align-left valign-top">Manual Evaluation</th></tr></thead><tbody><tr><td class="align-left valign-top"><em>sender</em></td><td class="align-left valign-top">server, handler, proxy, host, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-95-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.797ex" viewBox="0 -205.4 1172.5 343" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-95"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top"><strong>Yes</strong>, Network transfer related sense</td></tr><tr><td class="align-left valign-top"><em>directories</em></td><td class="align-left valign-top">file, cache, folder, repository, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-96-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.797ex" viewBox="0 -205.4 1172.5 343" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-96"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top"><strong>Yes</strong>, Digital storage related sense</td></tr><tr><td class="align-left valign-top"><em>float</em></td><td class="align-left valign-top">integers, type, array, double, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-97-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.797ex" viewBox="0 -205.4 1172.5 343" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-97"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top"><strong>Yes</strong>, Data type related sense</td></tr><tr><td class="align-left valign-top"><em>celebrity</em></td><td class="align-left valign-top">actor, musician, hero, politician, athlete, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-98-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.797ex" viewBox="0 -205.4 1172.5 343" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-98"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top"><strong>No</strong></td></tr><tr><td class="align-left valign-top"><em>quiz</em></td><td class="align-left valign-top">contest, prize, contests, games, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-99-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.797ex" viewBox="0 -205.4 1172.5 343" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-99"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top"><strong>No</strong></td></tr></tbody></table></div></div><div class="tables colsep-0 frame-topbot rowsep-0" id="tbl0004"><span class="captions"><span id="cap0009"><p id="sp0013"><span class="label">Table 4</span>. Example novel senses as per <a name="bbib0033" href="#bib0033" class="workspace-trigger">Lau&nbsp;et&nbsp;al.&nbsp;(2014)</a> and manual evaluation. ‘Novel sense’ represents the list of words which indicates a new sense as per <a name="bbib0033" href="#bib0033" class="workspace-trigger">Lau&nbsp;et&nbsp;al.&nbsp;(2014)</a>.</p></span></span><div class="groups"><table><tbody><tr><td class="align-left valign-top"><strong>Word</strong></td><td class="align-left valign-top"><strong>Novel sense</strong></td><td class="align-left valign-top"><strong>Manual Evaluation</strong></td></tr><tr><td class="align-left valign-top"><em>adapter</em></td><td class="align-left valign-top">connectivity, tools, system, address, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-100-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.797ex" viewBox="0 -205.4 1172.5 343" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-100"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top"><strong>Yes</strong>, Technology related sense</td></tr><tr><td class="align-left valign-top"><em>clicks</em></td><td class="align-left valign-top">link, page, user, visitor, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-101-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.797ex" viewBox="0 -205.4 1172.5 343" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-101"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top"><strong>Yes</strong>, Internet related sense</td></tr><tr><td class="align-left valign-top"><em>pampering</em></td><td class="align-left valign-top">advice, expert, condition, delicate, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-102-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.797ex" viewBox="0 -205.4 1172.5 343" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-102"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top"><strong>No</strong></td></tr></tbody></table></div></div></div></section><section id="sec0021"><h3 id="sctt0024" class="u-h4 u-margin-m-top u-margin-xs-bottom">5.2. Comparative evaluation</h3><div><p id="p0059">Only 32 and 23 words out of the 100 random samples from two time point pairs are evaluated to be actual ‘birth’s, respectively, thus giving precision scores of 0.32 and 0.23 for <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a>. Evaluation results for the same set of random samples after applying the approach outlined in <a name="bbib0033" href="#bib0033" class="workspace-trigger">Lau&nbsp;et&nbsp;al.&nbsp;(2014)</a> are presented in <a name="btbl0005" href="#tbl0005" class="workspace-trigger">Table&nbsp;5</a>. Since the reported novel sense cluster can in principle be different from the ‘birth’ sense reported by the method of <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a> for the same word, we get the novel sense cases manually evaluated by 3 annotators (42 and 28 cases for the two time periods, respectively). Note that for these 100 random samples (that are all marked ‘true’ by <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a>), it is possible to find an upper bound on the recall of <a name="bbib0033" href="#bib0033" class="workspace-trigger">Lau&nbsp;et&nbsp;al.&nbsp;(2014)</a>’s approach automatically. While the low recall might be justified because this is a different approach, even the precision is found to be in the same range as that of <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a>.</p><div class="tables colsep-0 frame-topbot rowsep-0" id="tbl0005"><span class="captions"><span id="cap0010"><p id="sp0014"><span class="label">Table 5</span>. Evaluation of the approach presented in <a name="bbib0033" href="#bib0033" class="workspace-trigger">Lau&nbsp;et&nbsp;al.&nbsp;(2014)</a> with accuracy for 100 random samples for <em>T</em><sub>1</sub> (1909–1953&nbsp;vs 2002–2005) and <em>T</em><sub>2</sub> (1909–1953&nbsp;vs 2006–2008).</p></span></span><div class="groups"><table><thead><tr><th scope="col" class="align-left valign-top">Time-</th><th scope="col" class="align-left rowsep-1" colspan="4"><a name="bbib0033" href="#bib0033" class="workspace-trigger">Lau&nbsp;et&nbsp;al.&nbsp;(2014)</a></th></tr><tr class="rowsep-1"><th scope="col" class="align-left valign-top">point</th><th scope="col" class="align-left valign-top"># Novel senses</th><th scope="col" class="align-left valign-top">Precision</th><th scope="col" class="align-left valign-top">Recall</th><th scope="col" class="align-left valign-top">F-measure</th></tr></thead><tbody><tr><td class="align-left valign-top"><em>T</em><sub>1</sub></td><td class="align-left valign-top">1189</td><td class="align-left valign-top">0.21</td><td class="align-left valign-top">0.28</td><td class="align-left valign-top">0.24</td></tr><tr><td class="align-left valign-top"><em>T</em><sub>2</sub></td><td class="align-left valign-top">787</td><td class="align-left valign-top">0.28</td><td class="align-left valign-top">0.35</td><td class="align-left valign-top">0.31</td></tr></tbody></table></div></div></div><div><p id="p0060"><a name="btbl0006" href="#tbl0006" class="workspace-trigger">Table&nbsp;6</a> presents the evaluation results for the same set of 100 random samples after using the proposed SVM filtering. We see that the filtering using SVM classification improves the precision for both the time point pairs (<em>T</em><sub>1</sub> and <em>T</em><sub>2</sub>) significantly, boosting it from the range of 0.23-0.32 to 0.74-0.86. Note that, as per our calculations, indeed the recall of <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a> would be 100% (as we are taking random samples for annotation from the set of reported ‘birth’ cases by <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a> only). Even then <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a>’s F-measure ranges from 0.37-0.48 while ours is 0.67-0.68. <a name="btbl0007" href="#tbl0007" class="workspace-trigger">Table&nbsp;7</a> represents some of the examples which were declared as ‘birth’ by <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a> but SVM filtering correctly flagged them as ‘false birth’. The feature values in the third column clearly show that the network around the words in the detected ‘birth’ clusters did not change much and therefore, the SVM approach could correctly flag these. Considering the small training set (49 reported ‘birth cases’ by <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a>), the results are highly encouraging. We also obtain decent recall values for the two time point pairs, giving an overall F-measure of 0.67-0.68.</p><div class="tables colsep-0 frame-topbot rowsep-0" id="tbl0006"><span class="captions"><span id="cap0011"><p id="sp0015"><span class="label">Table 6</span>. Evaluation of the SVM-based filtering with accuracy reported for 100 random samples for <em>T</em><sub>1</sub> (1909–1953&nbsp;vs 2002–2005) and <em>T</em><sub>2</sub> (1909–1953&nbsp;vs 2006–2008).</p></span></span><div class="groups"><table><thead><tr><th scope="col" class="align-left valign-top">Time-</th><th scope="col" class="align-left rowsep-1" colspan="4">SVM filtering</th></tr><tr class="rowsep-1"><th scope="col" class="align-left valign-top">point</th><th scope="col" class="align-left valign-top"># birth cases</th><th scope="col" class="align-left valign-top">Precision</th><th scope="col" class="align-left valign-top">Recall</th><th scope="col" class="align-left valign-top">F-measure</th></tr></thead><tbody><tr><td class="align-left valign-top"><em>T</em><sub>1</sub></td><td class="align-left valign-top">318</td><td class="align-left valign-top"><strong>0.86</strong></td><td class="align-left valign-top">0.56</td><td class="align-left valign-top">0.68</td></tr><tr><td class="align-left valign-top"><em>T</em><sub>2</sub></td><td class="align-left valign-top">329</td><td class="align-left valign-top"><strong>0.74</strong></td><td class="align-left valign-top">0.61</td><td class="align-left valign-top">0.67</td></tr></tbody></table></div></div><div class="tables colsep-0 frame-topbot rowsep-0" id="tbl0007"><span class="captions"><span id="cap0012"><p id="sp0016"><span class="label">Table 7</span>. Example cases, which <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a><span> declared as true ‘birth’ but <a href="/topics/computer-science/support-vector-machine" title="Learn more about SVM from ScienceDirect's AI-generated Topic Pages" class="topic-link">SVM</a> filtering correctly filtered.</span></p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col" class="align-left valign-top">Word</th><th scope="col" class="align-left valign-top">‘birth’ cluster</th><th scope="col" class="align-left valign-top">Δ(ED, SS, APL)</th></tr></thead><tbody><tr><td class="align-left valign-top">mantra</td><td class="align-left valign-top">dharma, deity, guru, deities, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-103-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.797ex" viewBox="0 -205.4 1172.5 343" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-103"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top">0.2, −0.03, −0.3</td></tr><tr><td class="align-left valign-top">slogan</td><td class="align-left valign-top">motto, initials, symbol, trademark, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-104-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.797ex" viewBox="0 -205.4 1172.5 343" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-104"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top">−0.03, −0.26, −0.72</td></tr><tr><td class="align-left valign-top">teddy</td><td class="align-left valign-top">dolls, puppies, pet, mama, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-105-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.797ex" viewBox="0 -205.4 1172.5 343" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-105"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top">−0.016, −0.25, −0.83</td></tr></tbody></table></div></div></div><section id="sec0022"><h4 id="sctt0025" class="u-margin-m-top u-margin-xs-bottom">5.2.1. Feature analysis</h4><div><p id="p0061">We, therefore, move onto further feature analysis of the proposed approach. To validate the usefulness of all three proposed features, we first check the Pearson’s correlation among the three features and then perform feature leave-one-out experiments. <a name="btbl0008" href="#tbl0008" class="workspace-trigger">Table&nbsp;8</a><span> represents the feature <a href="/topics/computer-science/correlation-matrix" title="Learn more about correlation matrix from ScienceDirect's AI-generated Topic Pages" class="topic-link">correlation matrix</a> which shows that the three features are not significantly correlated. Next, we observe the results of feature leave-one-out experiment for </span><em>T</em><sub>1</sub> and <em>T</em><sub>2</sub> in <a name="btbl0013" href="#tbl0013" class="workspace-trigger">Table&nbsp;13</a> and <a name="btbl0014" href="#tbl0014" class="workspace-trigger">Table&nbsp;14</a> respectively. We find that the F1-score drops as we leave out one of the features. While {<em>ED, SS</em>} turns out to be the best for precision, {<em>SS, APL</em>} gives the best recall. <a name="btbl0011" href="#tbl0011" class="workspace-trigger">Table&nbsp;11</a> provides three examples to illustrate the importance of using all three features. For the word ‘newsweek’, using {<em>ED, APL</em>} and for the word ‘caring’, using {<em>ED, SS</em>} could not detect those as ‘birth’. Only when all the three features are used, these cases are correctly detected as ‘birth’. Edge density, on the other hand, is very crucial for improving precision. For instance, when only {<em>SS, APL</em>} are used, words like ‘moderators’ are wrongly flagged as ‘true’. Such cases are filtered out when all the three features are used.</p><div class="tables colsep-0 frame-topbot rowsep-0" id="tbl0008"><span class="captions"><span id="cap0013"><p id="sp0017"><span class="label">Table 8</span>. The Pearson’s <a href="/topics/computer-science/correlation-matrix" title="Learn more about correlation matrix from ScienceDirect's AI-generated Topic Pages" class="topic-link">correlation matrix</a> for the three complex network measures (ED, SS, APL).</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col" class="align-left valign-top"></th><th scope="col" class="align-left valign-top">ED</th><th scope="col" class="align-left valign-top">SS</th><th scope="col" class="align-left valign-top">APL</th></tr></thead><tbody><tr><td class="align-left valign-top">ED</td><td class="align-left valign-top">1</td><td class="align-left valign-top">0.243</td><td class="align-left valign-top">−0.474</td></tr><tr><td class="align-left valign-top">SS</td><td class="align-left valign-top">0.243</td><td class="align-left valign-top">1</td><td class="align-left valign-top">−0.026</td></tr><tr><td class="align-left valign-top">APL</td><td class="align-left valign-top">−0.474</td><td class="align-left valign-top">−0.026</td><td class="align-left valign-top">1</td></tr></tbody></table></div></div></div></section><section id="sec0023"><h4 id="sctt0026" class="u-margin-m-top u-margin-xs-bottom">5.2.2. Extensive analysis of our proposed approach</h4><div><p id="p0062">We first take 60 random samples each from the filtered ‘birth’ cases reported by the SVM filtering for the two time period pairs, <em>T</em><sub>1</sub> (from 318 cases) and <em>T</em><sub>2</sub> (from 329 cases). The precision values of this evaluation are found to be <strong>0.87</strong> (52/60) and <strong>0.75</strong> (45/60) respectively, quite consistent with those reported in <a name="btbl0006" href="#tbl0006" class="workspace-trigger">Table&nbsp;6</a>. We do another experiment in order to estimate the performance of our model for detecting novel sense, independent of the method of <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a>. We take 100 random words from the two time point pairs (<em>T</em><sub>1</sub> and <em>T</em><sub>2</sub>), along with all the induced clusters from the newer time period and run the proposed SVM filtering approach to flag the novel ‘birth’ senses. According to our model, for <em>T</em><sub>1</sub> and <em>T</em><sub>2</sub> respectively, 13 out of predicted 24 words and 13 out of 21 predicted words are flagged to be having novel sense achieving precision values of <strong>0.54</strong> and <strong>0.62</strong> on manual evaluation, which itself is quite decent. Note that, for some cases, multiple clusters of a single word have been flagged as novel senses and we observe that these clusters hold a similar sense. For both of these experiments we use the same set of 49 reported ‘birth cases’ by <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a><span> to train the SVM <a href="/topics/computer-science/classification-machine-learning" title="Learn more about classifier from ScienceDirect's AI-generated Topic Pages" class="topic-link">classifier</a> (</span><a name="btbl0009" href="#tbl0009" class="workspace-trigger">Tables&nbsp;9</a> and <a name="btbl0010" href="#tbl0010" class="workspace-trigger">10</a>).</p><div class="tables colsep-0 frame-topbot rowsep-0" id="tbl0009"><span class="captions"><span id="cap0014"><p id="sp0018"><span class="label">Table 9</span>. Feature leave-one-out results (<em>T</em><sub>1</sub>).</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col" class="align-left valign-top">Features used</th><th scope="col" class="align-left valign-top">Precision</th><th scope="col" class="align-left valign-top">Recall</th><th scope="col" class="align-left valign-top">F-measure</th></tr></thead><tbody><tr><td class="align-left valign-top">Δ(ED, SS)</td><td class="align-left valign-top">0.85</td><td class="align-left valign-top">0.53</td><td class="align-left valign-top">0.65</td></tr><tr><td class="align-left valign-top">Δ(ED, APL)</td><td class="align-left valign-top">0.84</td><td class="align-left valign-top">0.5</td><td class="align-left valign-top">0.62</td></tr><tr><td class="align-left valign-top">Δ(SS, APL)</td><td class="align-left valign-top">0.81</td><td class="align-left valign-top">0.56</td><td class="align-left valign-top">0.66</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL)</td><td class="align-left valign-top"><strong>0.86</strong></td><td class="align-left valign-top">0.56</td><td class="align-left valign-top"><strong>0.68</strong></td></tr></tbody></table></div></div><div class="tables colsep-0 frame-topbot rowsep-0" id="tbl0010"><span class="captions"><span id="cap0015"><p id="sp0019"><span class="label">Table 10</span>. Feature leave-one-out results (<em>T</em><sub>2</sub>).</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col" class="align-left valign-top">Features used</th><th scope="col" class="align-left valign-top">Precision</th><th scope="col" class="align-left valign-top">Recall</th><th scope="col" class="align-left valign-top">F-measure</th></tr></thead><tbody><tr><td class="align-left valign-top">Δ(ED, SS)</td><td class="align-left valign-top">0.72</td><td class="align-left valign-top">0.56</td><td class="align-left valign-top">0.63</td></tr><tr><td class="align-left valign-top">Δ(ED, APL)</td><td class="align-left valign-top">0.73</td><td class="align-left valign-top">0.6</td><td class="align-left valign-top">0.66</td></tr><tr><td class="align-left valign-top">Δ(SS, APL)</td><td class="align-left valign-top">0.66</td><td class="align-left valign-top">0.61</td><td class="align-left valign-top">0.63</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL)</td><td class="align-left valign-top"><strong>0.74</strong></td><td class="align-left valign-top">0.61</td><td class="align-left valign-top"><strong>0.67</strong></td></tr></tbody></table></div></div><div class="tables colsep-0 frame-topbot rowsep-0" id="tbl0011"><span class="captions"><span id="cap0016"><p id="sp0020"><span class="label">Table 11</span>. Example cases to show the utility of all the features (<em>T</em><sub>1</sub>). The true positive cases like ‘newsweek’ and ‘caring’ get successfully detected whereas ‘moderators’ gets successfully detected as false positive if all the three features are considered together.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col" class="align-left valign-top">Word</th><th scope="col" class="align-left valign-top">‘birth’ cluster</th><th scope="col" class="align-left valign-top">Δ(ED, SS, APL)</th></tr></thead><tbody><tr><td class="align-left valign-top"><em>newsweek</em></td><td class="align-left valign-top">probation, counseling, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-106-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.797ex" viewBox="0 -205.4 1172.5 343" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-106"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top">0.82, 1.58, −1.3</td></tr><tr><td class="align-left valign-top"><em>caring</em></td><td class="align-left valign-top">insightful, wise, benevolent, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-107-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.797ex" viewBox="0 -205.4 1172.5 343" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-107"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top">0.2, 0.13, −2.21</td></tr><tr><td class="align-left valign-top">moderators</td><td class="align-left valign-top">correlate, function, determinant, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-108-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.797ex" viewBox="0 -205.4 1172.5 343" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-108"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top">0.56, 0.44, −1.78</td></tr></tbody></table></div></div></div></section></section><section id="sec0024"><h3 id="sctt0027" class="u-h4 u-margin-m-top u-margin-xs-bottom">5.3. Evaluation of features obtained from network embeddings</h3><section id="sec0025"><h4 id="sctt0028" class="u-margin-m-top u-margin-xs-bottom">5.3.1. Deepwalk</h4><div><p id="p0063"><span>We explore the effect of fractional change of IAS and AST over time by plugging them as features into the SVM classifier. We first try to find out the best hyper-parameter settings for the feature combination of IAS and AST by grid search. We try out different values of the primary hyper-parameters (dimension of vectors, number of <a href="/topics/computer-science/random-walks" title="Learn more about random walks from ScienceDirect's AI-generated Topic Pages" class="topic-link">random walks</a> to start at each node, length of random walk starting at each node) to obtain the best settings. We experiment with dimension of vectors: (</span><em>d</em>) = {80, 128, 300}; number of random walks to start at each node (<em>nrw</em>) = {10, 20}; length of random walk starting at each node (<em>lrw</em>) = {10, 20, 40, 80}. From the results presented in <a name="btbl0012" href="#tbl0012" class="workspace-trigger">Table&nbsp;12</a>, we see for <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-109-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>d</mi><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>128</mn><mo is=&quot;true&quot;>,</mo><mi is=&quot;true&quot;>n</mi><mi is=&quot;true&quot;>r</mi><mi is=&quot;true&quot;>w</mi><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>10</mn><mo is=&quot;true&quot;>,</mo><mi is=&quot;true&quot;>l</mi><mi is=&quot;true&quot;>r</mi><mi is=&quot;true&quot;>w</mi><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>40</mn></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="28.23ex" height="2.458ex" viewBox="0 -792.8 12154.5 1058.4" role="img" focusable="false" style="vertical-align: -0.617ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-64"></use></g><g is="true" transform="translate(801,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(1857,0)"><use xlink:href="#MJMAIN-31"></use><use xlink:href="#MJMAIN-32" x="500" y="0"></use><use xlink:href="#MJMAIN-38" x="1001" y="0"></use></g><g is="true" transform="translate(3359,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(3804,0)"><use xlink:href="#MJMATHI-6E"></use></g><g is="true" transform="translate(4404,0)"><use xlink:href="#MJMATHI-72"></use></g><g is="true" transform="translate(4856,0)"><use xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(5850,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(6906,0)"><use xlink:href="#MJMAIN-31"></use><use xlink:href="#MJMAIN-30" x="500" y="0"></use></g><g is="true" transform="translate(7907,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(8352,0)"><use xlink:href="#MJMATHI-6C"></use></g><g is="true" transform="translate(8651,0)"><use xlink:href="#MJMATHI-72"></use></g><g is="true" transform="translate(9102,0)"><use xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(10097,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(11153,0)"><use xlink:href="#MJMAIN-34"></use><use xlink:href="#MJMAIN-30" x="500" y="0"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">d</mi><mo linebreak="goodbreak" is="true">=</mo><mn is="true">128</mn><mo is="true">,</mo><mi is="true">n</mi><mi is="true">r</mi><mi is="true">w</mi><mo linebreak="goodbreak" is="true">=</mo><mn is="true">10</mn><mo is="true">,</mo><mi is="true">l</mi><mi is="true">r</mi><mi is="true">w</mi><mo linebreak="goodbreak" is="true">=</mo><mn is="true">40</mn></mrow></math></span></span><script type="math/mml" id="MathJax-Element-109"><math><mrow is="true"><mi is="true">d</mi><mo linebreak="goodbreak" is="true">=</mo><mn is="true">128</mn><mo is="true">,</mo><mi is="true">n</mi><mi is="true">r</mi><mi is="true">w</mi><mo linebreak="goodbreak" is="true">=</mo><mn is="true">10</mn><mo is="true">,</mo><mi is="true">l</mi><mi is="true">r</mi><mi is="true">w</mi><mo linebreak="goodbreak" is="true">=</mo><mn is="true">40</mn></mrow></math></script></span> we get the best consistent performance over <em>T</em><sub>1</sub> and <em>T</em><sub>2</sub> and hence we continue with this hyper-parameter setting (<strong>BDHS</strong>) for further analysis.</p><div class="tables colsep-0 frame-topbot rowsep-0" id="tbl0012"><span class="captions"><span id="cap0017"><p id="sp0021"><span class="label">Table 12</span>. Comparison of performance of (Δ(IAS, AST)) with varying hyper-parameters. All the measures are for <em>T</em><sub>1</sub> and <em>T</em><sub>2</sub><span> when we use Deepwalk for producing network embeddings. d - dimension of vectors, nrw - number of <a href="/topics/computer-science/random-walks" title="Learn more about random walks from ScienceDirect's AI-generated Topic Pages" class="topic-link">random walks</a> to start at each node, lrw - length of random walk starting at each node.</span></p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col" class="align-left valign-top">Time-point</th><th scope="col" class="align-left valign-top">d</th><th scope="col" class="align-left valign-top">lrw</th><th scope="col" class="align-left valign-top">nrw</th><th scope="col" class="align-left valign-top">Precision</th><th scope="col" class="align-left valign-top">Recall</th><th scope="col" class="align-left valign-top">F-measure</th></tr></thead><tbody><tr><td class="align-left"></td><td class="align-left valign-top"><u>300</u></td><td class="align-left valign-top">40</td><td class="align-left valign-top">10</td><td class="align-left valign-top">0.82</td><td class="align-left valign-top"><strong>0.56</strong></td><td class="align-left valign-top"><strong>0.67</strong></td></tr><tr><td class="align-left"></td><td class="align-left valign-top"><u>128</u></td><td class="align-left valign-top">40</td><td class="align-left valign-top">10</td><td class="align-left valign-top"><strong>0.85</strong></td><td class="align-left valign-top">0.53</td><td class="align-left valign-top">0.65</td></tr><tr><td class="align-left"></td><td class="align-left valign-top"><u>80</u></td><td class="align-left valign-top">40</td><td class="align-left valign-top">10</td><td class="align-left valign-top">0.32</td><td class="align-left valign-top">1</td><td class="align-left valign-top">0.48</td></tr><tr><td class="align-left"></td><td class="align-left valign-top">128</td><td class="align-left valign-top"><u>80</u></td><td class="align-left valign-top">10</td><td class="align-left valign-top">0.77</td><td class="align-left valign-top">0.53</td><td class="align-left valign-top">0.63</td></tr><tr><td class="align-left valign-top"><em>T</em><sub>1</sub></td><td class="align-left valign-top">128</td><td class="align-left valign-top"><u>20</u></td><td class="align-left valign-top">10</td><td class="align-left valign-top">0.53</td><td class="align-left valign-top">0.62</td><td class="align-left valign-top">0.57</td></tr><tr><td class="align-left"></td><td class="align-left valign-top">128</td><td class="align-left valign-top"><u>10</u></td><td class="align-left valign-top">10</td><td class="align-left valign-top">0.32</td><td class="align-left valign-top">1</td><td class="align-left valign-top">0.48</td></tr><tr><td class="align-left"></td><td class="align-left valign-top">128</td><td class="align-left valign-top">40</td><td class="align-left valign-top"><u>20</u></td><td class="align-left valign-top">0.81</td><td class="align-left valign-top">0.53</td><td class="align-left valign-top">0.64</td></tr><tr><td class="align-left"></td><td class="align-left valign-top"><u>300</u></td><td class="align-left valign-top">40</td><td class="align-left valign-top">10</td><td class="align-left valign-top">0.56</td><td class="align-left valign-top">0.56</td><td class="align-left valign-top">0.56</td></tr><tr><td class="align-left"></td><td class="align-left valign-top"><u>128</u></td><td class="align-left valign-top">40</td><td class="align-left valign-top">10</td><td class="align-left valign-top">0.61</td><td class="align-left valign-top"><strong>0.61</strong></td><td class="align-left valign-top">0.61</td></tr><tr><td class="align-left"></td><td class="align-left valign-top"><u>80</u></td><td class="align-left valign-top">40</td><td class="align-left valign-top">10</td><td class="align-left valign-top">0.23</td><td class="align-left valign-top">1</td><td class="align-left valign-top">0.37</td></tr><tr><td class="align-left"></td><td class="align-left valign-top">128</td><td class="align-left valign-top"><u>80</u></td><td class="align-left valign-top">10</td><td class="align-left valign-top"><strong>0.64</strong></td><td class="align-left valign-top"><strong>0.61</strong></td><td class="align-left valign-top"><strong>0.62</strong></td></tr><tr><td class="align-left valign-top"><em>T</em><sub>2</sub></td><td class="align-left valign-top">128</td><td class="align-left valign-top"><u>20</u></td><td class="align-left valign-top">10</td><td class="align-left valign-top">0.73</td><td class="align-left valign-top">0.48</td><td class="align-left valign-top">0.58</td></tr><tr><td class="align-left"></td><td class="align-left valign-top">128</td><td class="align-left valign-top"><u>10</u></td><td class="align-left valign-top">10</td><td class="align-left valign-top">0.69</td><td class="align-left valign-top">0.48</td><td class="align-left valign-top">0.56</td></tr><tr><td class="align-left"></td><td class="align-left valign-top">128</td><td class="align-left valign-top">40</td><td class="align-left valign-top"><u>20</u></td><td class="align-left valign-top">0.62</td><td class="align-left valign-top">0.56</td><td class="align-left valign-top">0.59</td></tr></tbody></table></div></div><div class="tables colsep-0 frame-topbot rowsep-0" id="tbl0013"><span class="captions"><span id="cap0018"><p id="sp0022"><span class="label">Table 13</span>. Comparison of performance of simple complex network measures (Δ(ED, SS, APL)) vs features computed using Network Embedding (<strong>Deepwalk</strong>) (Δ(IAS, AST)). It also shows the performance of the combination of two types of features. All the measures are for <strong><em>T<sub>1</sub></em></strong><span>. The hyper-parameter used for Deepwalk training - dimension of vectors (d) = 128; number of <a href="/topics/computer-science/random-walks" title="Learn more about random walks from ScienceDirect's AI-generated Topic Pages" class="topic-link">random walks</a> to start at each node (nrw) = 10; length of random walk starting at each node (lrw) = 40.</span></p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col" class="align-left valign-top">Features used</th><th scope="col" class="align-left valign-top">Precision</th><th scope="col" class="align-left valign-top">Recall</th><th scope="col" class="align-left valign-top">F-measure</th></tr></thead><tbody><tr><td class="align-left valign-top">Δ(IAS, AST)</td><td class="align-left valign-top">0.85</td><td class="align-left valign-top">0.53</td><td class="align-left valign-top">0.65</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, IAS)</td><td class="align-left valign-top">0.85</td><td class="align-left valign-top">0.53</td><td class="align-left valign-top">0.65</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, AST)</td><td class="align-left valign-top"><strong>0.91</strong></td><td class="align-left valign-top"><strong>0.62</strong></td><td class="align-left valign-top"><strong>0.74</strong></td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, IAS, AST)</td><td class="align-left valign-top">0.9</td><td class="align-left valign-top">0.59</td><td class="align-left valign-top">0.72</td></tr></tbody></table></div></div><div class="tables colsep-0 frame-topbot rowsep-0" id="tbl0014"><span class="captions"><span id="cap0019"><p id="sp0023"><span class="label">Table 14</span>. Comparison of performance of simple complex network measures (Δ(ED, SS, APL)) vs Features computed using Network Embedding (<strong>Deepwalk</strong>) (Δ(IAS, AST)). It also shows the performance of combination of two types of features. All the measures are for <strong><em>T<sub>2</sub></em></strong><span>. The hyper-parameter used for Deepwalk training - dimension of vectors (d) = 128; number of <a href="/topics/computer-science/random-walks" title="Learn more about random walks from ScienceDirect's AI-generated Topic Pages" class="topic-link">random walks</a> to start at each node (nrw) = 10; length of random walk starting at each node (lrw) = 40.</span></p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col" class="align-left valign-top">Features used</th><th scope="col" class="align-left valign-top">Precision</th><th scope="col" class="align-left valign-top">Recall</th><th scope="col" class="align-left valign-top">F-measure</th></tr></thead><tbody><tr><td class="align-left valign-top">Δ(IAS, AST)</td><td class="align-left valign-top">0.61</td><td class="align-left valign-top">0.61</td><td class="align-left valign-top">0.61</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, IAS)</td><td class="align-left valign-top"><strong>0.74</strong></td><td class="align-left valign-top"><strong>0.61</strong></td><td class="align-left valign-top"><strong>0.67</strong></td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, AST)</td><td class="align-left valign-top">0.62</td><td class="align-left valign-top">0.56</td><td class="align-left valign-top">0.59</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, IAS, AST)</td><td class="align-left valign-top">0.6</td><td class="align-left valign-top">0.52</td><td class="align-left valign-top">0.56</td></tr></tbody></table></div></div></div><p id="p0064">We observe from the first rows of <a name="btbl0013" href="#tbl0013" class="workspace-trigger">Tables&nbsp;13</a> and <a name="btbl0014" href="#tbl0014" class="workspace-trigger">14</a>, that for both the time period pairs (<em>T</em><sub>1</sub> and <em>T</em><sub>2</sub>, respectively), using only features obtained using Deepwalk (with best possible hyper-parameter setting) - IAS and AST, does not help improving the performance when compared to the settings in which only network measures are used (<a name="btbl0006" href="#tbl0006" class="workspace-trigger">Table&nbsp;6</a>). We next try to combine the simple network features (ED, SS and APL) with IAS and AST as well in different combinations and present the results in <a name="btbl0013" href="#tbl0013" class="workspace-trigger">Tables&nbsp;13</a> and <a name="btbl0014" href="#tbl0014" class="workspace-trigger">14</a> for <em>T</em><sub>1</sub> and <em>T</em><sub>2</sub>, respectively. We observe that even though the combination of ED, SS, APL, AST gives the best overall performance beating the performance of the model using only network measures (ED, SS, APL) for <em>T</em><sub>1</sub>, it shows inconsistent performance for <em>T</em><sub>2</sub> producing poorer performance while compared with the model where only network measures (ED, SS, APL) are used.</p></section><section id="sec0026"><h4 id="sctt0029" class="u-margin-m-top u-margin-xs-bottom">5.3.2. node2vec</h4><div><p id="p0065">We further investigate the usefulness of IAS and AST while those are computed from the network embeddings obtained from node2vec. The results for both time period pairs (<em>T</em><sub>1</sub> and <em>T</em><sub>2</sub>) are presented in <a name="btbl0015" href="#tbl0015" class="workspace-trigger">Table&nbsp;15</a> and <a name="btbl0016" href="#tbl0016" class="workspace-trigger">Table&nbsp;16</a>, respectively. We observe that even though appending AST to (ED, SS, APL) improves the precision for both the time period pairs (<em>T</em><sub>1</sub> and <em>T</em><sub>2</sub>), it leads to decrease of F-measure while compared with using only the network measures. We obtain these results for the default hyper-parameter settings of node2vec as follows: number of random walks to start at each node = 10; length of random walk starting at each node = 80; skipgram window size = 10; Inout = 1; Return = 1. We also try with the hyper-parameter settings for which we get the best results for Deepwalk (<strong>BDHS</strong>) by setting skipgram window size = 5 and the length of random walk starting at each node = 40, the results of which are presented in the last rows of <a name="btbl0015" href="#tbl0015" class="workspace-trigger">Tables&nbsp;15</a> and <a name="btbl0016" href="#tbl0016" class="workspace-trigger">16</a> for <em>T</em><sub>1</sub> and <em>T</em><sub>2</sub>, respectively. We observe that even in this hyper-parameter setup, node2vec produces poor F-measure score compared to the model using only complex network measures.</p><div class="tables colsep-0 frame-topbot rowsep-0" id="tbl0015"><span class="captions"><span id="cap0020"><p id="sp0024"><span class="label">Table 15</span>. Comparison of performance of simple complex network measures (Δ(ED, SS, APL)) vs combination with features computed using network embedding (<strong>node2vec</strong>) (Δ(IAS, AST)). All the measures are for <strong><em>T<sub>1</sub></em></strong>. The default hyper-parameters used for node2vec training - dimension of vectors (<em>d</em><span>) = 128; number of <a href="/topics/computer-science/random-walks" title="Learn more about random walks from ScienceDirect's AI-generated Topic Pages" class="topic-link">random walks</a> to start at each node (nrw) = 10; length of random walk starting at each node (lrw) = 40. Only the last row shows the performance of the best combination of complex network features and network embedding (</span><strong>node2vec</strong>) features (Δ(ED, SS, APL, AST)) with node2vec trained with the best hyper-parameter setting of Deepwalk (BDHS).</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col" class="align-left valign-top">Features used</th><th scope="col" class="align-left valign-top">Precision</th><th scope="col" class="align-left valign-top">Recall</th><th scope="col" class="align-left valign-top">F-measure</th></tr></thead><tbody><tr><td class="align-left valign-top">Δ(ED, SS, APL)</td><td class="align-left valign-top">0.86</td><td class="align-left valign-top"><strong>0.56</strong></td><td class="align-left valign-top"><strong>0.68</strong></td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, IAS)</td><td class="align-left valign-top">0.85</td><td class="align-left valign-top">0.53</td><td class="align-left valign-top">0.65</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, AST)</td><td class="align-left valign-top">0.89</td><td class="align-left valign-top">0.5</td><td class="align-left valign-top">0.64</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, IAS, AST)</td><td class="align-left valign-top">0.89</td><td class="align-left valign-top">0.5</td><td class="align-left valign-top">0.64</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, AST) [BDHS]</td><td class="align-left valign-top"><strong>0.9</strong></td><td class="align-left valign-top">0.53</td><td class="align-left valign-top">0.67</td></tr></tbody></table></div></div><div class="tables colsep-0 frame-topbot rowsep-0" id="tbl0016"><span class="captions"><span id="cap0021"><p id="sp0025"><span class="label">Table 16</span>. Comparison of performance of simple complex network measures (Δ(ED, SS, APL)) vs combination with features computed using Network Embedding (<strong>node2vec</strong>) (Δ(IAS, AST)). All the measures are for <strong><em>T<sub>2</sub></em></strong><span>. The hyper-parameters used for node2vec training - dimension of vectors (d) = 128; number of <a href="/topics/computer-science/random-walks" title="Learn more about random walks from ScienceDirect's AI-generated Topic Pages" class="topic-link">random walks</a> to start at each node (nrw) = 10; length of random walk starting at each node (lrw) = 40. Only the last row shows the performance of the best combination of complex network features and network embedding (</span><strong>node2vec</strong>) features (Δ(ED, SS, APL, AST)) with node2vec trained with the best hyper-parameter setting of Deepwalk (BDHS).</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col" class="align-left valign-top">Features used</th><th scope="col" class="align-left valign-top">Precision</th><th scope="col" class="align-left valign-top">Recall</th><th scope="col" class="align-left valign-top">F-measure</th></tr></thead><tbody><tr><td class="align-left valign-top">Δ(ED, SS, APL)</td><td class="align-left valign-top"><strong>0.74</strong></td><td class="align-left valign-top"><strong>0.61</strong></td><td class="align-left valign-top"><strong>0.67</strong></td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, IAS)</td><td class="align-left valign-top"><strong>0.74</strong></td><td class="align-left valign-top"><strong>0.61</strong></td><td class="align-left valign-top"><strong>0.67</strong></td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, AST)</td><td class="align-left valign-top">0.76</td><td class="align-left valign-top">0.56</td><td class="align-left valign-top">0.65</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, IAS, AST)</td><td class="align-left valign-top">0.75</td><td class="align-left valign-top">0.52</td><td class="align-left valign-top">0.62</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, AST) [BDHS]</td><td class="align-left valign-top">0.7</td><td class="align-left valign-top"><strong>0.61</strong></td><td class="align-left valign-top">0.65</td></tr></tbody></table></div></div></div><p id="p0066">We see in all the experiments using network embeddings (for both Deepwalk and node2vec) that no combination of features produces the best performance consistently for both <em>T</em><sub>1</sub> and <em>T</em><sub>2</sub>. As we are mapping network to vector space, there is a chance that we are missing some information which leads to inconsistent feature values for <em>T</em><sub>1</sub> and <em>T</em><sub>2</sub>, causing inconsistent performances. On the other hand, simple network measures perfectly capture the change in the networks which leads to consistent feature values producing a consistent performance for <em>T</em><sub>1</sub> and <em>T</em><sub>2</sub>.</p></section><section id="sec0027"><h4 id="sctt0030" class="u-margin-m-top u-margin-xs-bottom">5.3.3. Combination of Deepwalk and node2vec</h4><div><p id="p0067">So far we have discussed the usefulness of features obtained using Deepwalk and node2vec independently. In this section, we try to further combine the two features (IAS, AST) obtained both using Deepwalk and node2vec (naming them IASD, ASTD and IASN, ASTN respectively) along with simple network measures (ED, SS, APL). To validate the usefulness of all seven features, we first check the Pearson’s correlation among the seven features, the heatmap of which is presented in <a name="bfig0004" href="#fig0004" class="workspace-trigger">Fig.&nbsp;4</a>. Then we perform feature leave-one-out experiments for network embedding features with the proposed three network measures taken into consideration for all the combinations. From the results presented in <a name="btbl0017" href="#tbl0017" class="workspace-trigger">Tables&nbsp;17</a> and <a name="btbl0018" href="#tbl0018" class="workspace-trigger">18</a>, we do not find any single feature combination which beats the performance of simple network measures (ED, SS, APL) consistently for both <em>T</em><sub>1</sub> and <em>T</em><sub>2</sub>.</p><figure class="figure text-xs" id="fig0004"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0306457319303474-gr4.jpg" height="312" alt="Fig. 4" aria-describedby="cap0004"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0306457319303474-gr4_lrg.jpg" target="_blank" download="" title="Download high-res image (211KB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (211KB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0306457319303474-gr4.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0004"><p id="sp0008"><span class="label">Fig. 4</span>. The heatmap of Pearson’s correlation among three network measures (ED, SS, APL), two Deepwalk measures (IASD, ASTD) and two node2vec measures (IASN, ASTN).</p></span></span></figure><div class="tables colsep-0 frame-topbot rowsep-0" id="tbl0017"><span class="captions"><span id="cap0022"><p id="sp0026"><span class="label">Table 17</span>. Comparison of performance of the complex network measures (Δ(ED, SS, APL)) vs combination with features computed using <strong>Deepwalk</strong> (Δ (IASD, ASTD)) and <strong>node2vec</strong> (Δ (IASN, ASTN)). All the measures are for <strong><em>T<sub>1</sub></em></strong>.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col" class="align-left valign-top">Features used</th><th scope="col" class="align-left valign-top">Precision</th><th scope="col" class="align-left valign-top">Recall</th><th scope="col" class="align-left valign-top">F-measure</th></tr></thead><tbody><tr><td class="align-left valign-top">Δ(ED, SS, APL)</td><td class="align-left valign-top">0.86</td><td class="align-left valign-top">0.56</td><td class="align-left valign-top">0.68</td></tr><tr><td class="align-left valign-top">Δ(IASD, ASTD, IASN, ASTN)</td><td class="align-left valign-top">0.57</td><td class="align-left valign-top"><strong>0.62</strong></td><td class="align-left valign-top">0.6</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, IASD, ASTD)</td><td class="align-left valign-top"><strong>0.9</strong></td><td class="align-left valign-top">0.59</td><td class="align-left valign-top"><strong>0.72</strong></td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, IASD, ASTD, IASN)</td><td class="align-left valign-top"><strong>0.9</strong></td><td class="align-left valign-top">0.53</td><td class="align-left valign-top">0.67</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, IASD, ASTD, ASTN)</td><td class="align-left valign-top">0.89</td><td class="align-left valign-top">0.5</td><td class="align-left valign-top">0.64</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, IASN, ASTN)</td><td class="align-left valign-top">0.89</td><td class="align-left valign-top">0.5</td><td class="align-left valign-top">0.64</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, IASN, ASTN, IASD)</td><td class="align-left valign-top">0.89</td><td class="align-left valign-top">0.5</td><td class="align-left valign-top">0.64</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, IASN, ASTN, ASTD)</td><td class="align-left valign-top">0.89</td><td class="align-left valign-top">0.5</td><td class="align-left valign-top">0.64</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, IASN, ASTN, IASD, ASTD)</td><td class="align-left valign-top">0.88</td><td class="align-left valign-top">0.47</td><td class="align-left valign-top">0.61</td></tr></tbody></table></div></div><div class="tables colsep-0 frame-topbot rowsep-0" id="tbl0018"><span class="captions"><span id="cap0023"><p id="sp0027"><span class="label">Table 18</span>. Comparison of performance of simple complex network measures (Δ(ED, SS, APL)) vs combination with features computed using <strong>Deepwalk</strong> (Δ(IASD, ASTD)) and <strong>node2vec</strong> (Δ(IASN, ASTN)). All the measures are for <strong><em>T<sub>2</sub></em></strong>.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col" class="align-left valign-top">Features used</th><th scope="col" class="align-left valign-top">Precision</th><th scope="col" class="align-left valign-top">Recall</th><th scope="col" class="align-left valign-top">F-measure</th></tr></thead><tbody><tr><td class="align-left valign-top">Δ(ED, SS, APL)</td><td class="align-left valign-top">0.74</td><td class="align-left valign-top">0.61</td><td class="align-left valign-top"><strong>0.67</strong></td></tr><tr><td class="align-left valign-top">Δ(IASD, ASTD, IASN, ASTN)</td><td class="align-left valign-top">0.51</td><td class="align-left valign-top"><strong>0.87</strong></td><td class="align-left valign-top">0.64</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, IASD, ASTD)</td><td class="align-left valign-top">0.6</td><td class="align-left valign-top">0.52</td><td class="align-left valign-top">0.56</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, IASD, ASTD, IASN)</td><td class="align-left valign-top">0.67</td><td class="align-left valign-top">0.52</td><td class="align-left valign-top">0.58</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, IASD, ASTD, ASTN)</td><td class="align-left valign-top">0.63</td><td class="align-left valign-top">0.52</td><td class="align-left valign-top">0.57</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, IASN, ASTN)</td><td class="align-left valign-top"><strong>0.75</strong></td><td class="align-left valign-top">0.52</td><td class="align-left valign-top">0.62</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, IASN, ASTN, IASD)</td><td class="align-left valign-top"><strong>0.75</strong></td><td class="align-left valign-top">0.52</td><td class="align-left valign-top">0.62</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, IASN, ASTN, ASTD)</td><td class="align-left valign-top">0.63</td><td class="align-left valign-top">0.52</td><td class="align-left valign-top">0.57</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, IASN, ASTN, IASD, ASTD)</td><td class="align-left valign-top">0.71</td><td class="align-left valign-top">0.52</td><td class="align-left valign-top">0.6</td></tr></tbody></table></div></div></div><p id="p0068">All these analysis using network embeddings shows that even though network representation learning methods are supposed to capture network properties better by embedding the nodes in the network to a vector space, for a task like novel word sense detection explicit complex network features prove to be more useful, despite they are more efficient to compute. We see the same trend even when we try to obtain the embeddings directly from the corpus using fastText (described in <a name="bsec0028" href="#sec0028" class="workspace-trigger">Section&nbsp;5.4</a>), leading to the fact that a carefully curated small set of network measures can be more useful than high dimensional embeddings for this task of novel sense detection.</p></section></section><section id="sec0028"><h3 id="sctt0031" class="u-h4 u-margin-m-top u-margin-xs-bottom">5.4. Evaluation of features obtained from fastText embeddings</h3><div><p id="p0069">In this analysis we investigate whether embeddings obtained directly from corpus using fastText&nbsp;(<a name="bbib0006" href="#bib0006" class="workspace-trigger">Bojanowski&nbsp;et&nbsp;al., 2017</a>) can help boosting the performance for this task. The results for <em>T</em><sub>1</sub> and <em>T</em><sub>2</sub> are presented in <a name="btbl0019" href="#tbl0019" class="workspace-trigger">Table&nbsp;19</a> and <a name="btbl0020" href="#tbl0020" class="workspace-trigger">Table&nbsp;20</a>, respectively. We see that using only IAS and AST does not help to improve the F-measure compared to using only the network measures, whereas when both these types of features are merged, it helps to boost the performance in different combinations for different time period pairs (<em>T</em><sub>1</sub> and <em>T</em><sub>2</sub>).</p><div class="tables colsep-0 frame-topbot rowsep-0" id="tbl0019"><span class="captions"><span id="cap0024"><p id="sp0028"><span class="label">Table 19</span>. Comparison of performance of simple complex network measures (Δ(ED, SS, APL)) vs combination with features computed using <strong>fastText</strong> (Δ(IAS, AST)). All the measures are for <strong><em>T<sub>1</sub></em></strong>. The hyper-parameter used for node2vec training - dimension of vectors (d) = 128.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col" class="align-left valign-top">Features used</th><th scope="col" class="align-left valign-top">Precision</th><th scope="col" class="align-left valign-top">Recall</th><th scope="col" class="align-left valign-top">F-measure</th></tr></thead><tbody><tr><td class="align-left valign-top">Δ(ED, SS, APL)</td><td class="align-left valign-top"><strong>0.86</strong></td><td class="align-left valign-top"><strong>0.56</strong></td><td class="align-left valign-top"><strong>0.68</strong></td></tr><tr><td class="align-left valign-top">Δ(IAS, AST)</td><td class="align-left valign-top">0.67</td><td class="align-left valign-top">0.45</td><td class="align-left valign-top">0.54</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, IAS)</td><td class="align-left valign-top">0.85</td><td class="align-left valign-top">0.55</td><td class="align-left valign-top">0.67</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, AST)</td><td class="align-left valign-top">0.84</td><td class="align-left valign-top">0.52</td><td class="align-left valign-top">0.64</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, IAS, AST)</td><td class="align-left valign-top">0.89</td><td class="align-left valign-top">0.52</td><td class="align-left valign-top">0.65</td></tr></tbody></table></div></div><div class="tables colsep-0 frame-topbot rowsep-0" id="tbl0020"><span class="captions"><span id="cap0025"><p id="sp0029"><span class="label">Table 20</span>. Comparison of performance of simple complex network measures (Δ(ED, SS, APL)) vs combination with features computed using <strong>fastText</strong> (Δ(IAS, AST)). All the measures are for <strong><em>T<sub>2</sub></em></strong>. The hyper-parameter used for node2vec training - dimension of vectors (d) = 128.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col" class="align-left valign-top">Features used</th><th scope="col" class="align-left valign-top">Precision</th><th scope="col" class="align-left valign-top">Recall</th><th scope="col" class="align-left valign-top">F-measure</th></tr></thead><tbody><tr><td class="align-left valign-top">Δ(ED, SS, APL)</td><td class="align-left valign-top">0.74</td><td class="align-left valign-top">0.61</td><td class="align-left valign-top">0.67</td></tr><tr><td class="align-left valign-top">Δ(IAS, AST)</td><td class="align-left valign-top">0.86</td><td class="align-left valign-top">0.52</td><td class="align-left valign-top">0.65</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, IAS)</td><td class="align-left valign-top">0.74</td><td class="align-left valign-top">0.61</td><td class="align-left valign-top">0.67</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, AST)</td><td class="align-left valign-top">0.75</td><td class="align-left valign-top">0.65</td><td class="align-left valign-top">0.70</td></tr><tr><td class="align-left valign-top">Δ(ED, SS, APL, IAS, AST)</td><td class="align-left valign-top"><strong>0.79</strong></td><td class="align-left valign-top"><strong>0.65</strong></td><td class="align-left valign-top"><strong>0.71</strong></td></tr></tbody></table></div></div></div></section><section id="sec0029"><h3 id="sctt0032" class="u-h4 u-margin-m-top u-margin-xs-bottom">5.5. Error analysis</h3><div><p id="p0070">We further analyze the cases, which are labeled as ‘true birth’ by the SVM but are evaluated as ‘false’ by the human evaluators. We find that in most of such cases, the sense cluster reported as ‘birth’ contained many new terms (and therefore, the network properties have undergone change) but the implied sense was already present in one of the previous clusters with <em>very few common words</em> (and therefore, the new cluster contained &nbsp;&gt;&nbsp;80% new words and is being reported as ‘birth’ in <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a>). Two such examples are given in <a name="btbl0021" href="#tbl0021" class="workspace-trigger">Table&nbsp;21</a>. The split-join algorithm proposed in <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a> needs to be adapted for such cases.</p><div class="tables colsep-0 frame-topbot rowsep-0" id="tbl0021"><span class="captions"><span id="cap0026"><p id="sp0030"><span class="label">Table 21</span>. <span>Example ‘false positives’ after <a href="/topics/computer-science/support-vector-machine" title="Learn more about SVM from ScienceDirect's AI-generated Topic Pages" class="topic-link">SVM</a> filtering (</span><em>T</em><sub>1</sub>). These words are flagged ‘true birth’ by SVM but manually evaluated as ‘false’.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col" class="align-left valign-top">Word</th><th scope="col" class="align-left valign-top">‘birth’ cluster</th><th scope="col" class="align-left valign-top">Old cluster</th></tr></thead><tbody><tr><td class="align-left valign-top">aftercare</td><td class="align-left valign-top">care, clinic, outpatient, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-110-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.797ex" viewBox="0 -205.4 1172.5 343" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-110"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top">treatment, therapy, hospitalization, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-111-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.797ex" viewBox="0 -205.4 1172.5 343" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-111"><math><mo is="true">…</mo></math></script></span></td></tr><tr><td class="align-left valign-top">electrophoresis</td><td class="align-left valign-top">labeling, analysis, profiling, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-112-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.797ex" viewBox="0 -205.4 1172.5 343" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-112"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top">analysis, counting, procedure, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-113-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.797ex" viewBox="0 -205.4 1172.5 343" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-113"><math><mo is="true">…</mo></math></script></span></td></tr></tbody></table></div></div></div><div><p id="p0071">We also analyze the ‘true negatives’ cases, which are labeled as ‘false birth’ by the SVM filtering but are evaluated as ‘true’ by the human evaluators. Two such examples are given in <a name="btbl0022" href="#tbl0022" class="workspace-trigger">Table&nbsp;22</a><span>. By looking at the feature values of these cases, it is clear that the <a href="/topics/computer-science/network-structure" title="Learn more about network structure from ScienceDirect's AI-generated Topic Pages" class="topic-link">network structure</a> of the induced subgraph is not changing much, yet they undergo sense change. The probable reason could be that the target word was not in the network of the induced subgraph in the old time point and enters into it in the new time point. Our SVM model is unable to detect this single node injection in a network so far. Handling these cases would be an immediate future step to improve the recall of the system.</span></p><div class="tables colsep-0 frame-topbot rowsep-0" id="tbl0022"><span class="captions"><span id="cap0027"><p id="sp0031"><span class="label">Table 22</span>. <span>Example cases, labeled by <a href="/topics/computer-science/support-vector-machine" title="Learn more about SVM from ScienceDirect's AI-generated Topic Pages" class="topic-link">SVM</a> as ‘false birth’ but flagged as ‘true birth’ by annotators (</span><em>T</em><sub>1</sub><span>). The fractional change of the network measures is very low, leading to erroneous <a href="/topics/computer-science/classification" title="Learn more about classification from ScienceDirect's AI-generated Topic Pages" class="topic-link">classification</a> by SVM.</span></p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col" class="align-left valign-top">Word</th><th scope="col" class="align-left valign-top">‘birth’ cluster</th><th scope="col" class="align-left valign-top">Δ(ED, SS, APL)</th></tr></thead><tbody><tr><td class="align-left valign-top">baseplate</td><td class="align-left valign-top">flywheel, cylinder, bearings, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-114-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.797ex" viewBox="0 -205.4 1172.5 343" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-114"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top">0.06, −0.08, −0.84</td></tr><tr><td class="align-left valign-top">grating</td><td class="align-left valign-top">beam, signal, pulse, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-115-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.797ex" viewBox="0 -205.4 1172.5 343" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-115"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top">0.2, −0.05, −0.88</td></tr></tbody></table></div></div></div><p id="p0072">We also observe that even though for time point <em>T</em><sub>1</sub>, we get good results for feature combination Δ(ED, SS, APL, AST) while using Deepwalk, it fails to improve the performance for <em>T</em><sub>2</sub>. Therefore, we dig into the reason behind the fall in the performance for <em>T</em><sub>2</sub> and do error analysis. Note that, the training set is from <em>T</em><sub>1</sub><span> and while the mean of Δ(AST) for ‘true birth’ cases is 1.02, the value is 0.52 for ‘false birth’ cases. However, there are examples like ‘tans’, ‘guitarist’, ‘conformist’, etc., which are correctly predicted as ‘false’ by the <a href="/topics/computer-science/classifier-model" title="Learn more about classifier model from ScienceDirect's AI-generated Topic Pages" class="topic-link">classifier model</a> using only complex network measures (Δ(ED, SS, APL)) as features, but are wrongly flagged as ‘true’ when we add Δ(AST) to the feature set. On analysis, we find that the Δ(AST) values for these cases are 1.93, 2.33 and 1.68, respectively. Similarly, target words like ‘regularization’, ‘rewarming’ are correctly predicted as ‘true’ by the classifier model using only the complex network measures (Δ(ED, SS, APL)) as features, but are wrongly flagged as ‘false’ when we add Δ(AST) to the feature set, because of the low values, 0.59 and 0.44, respectively. Network embedding frameworks attempt to put nodes with similar network properties close in the vector space and the properties include both the local and global neighborhood structures. As the training set is from </span><em>T</em><sub>1</sub> and test set is from <em>T</em><sub>2</sub>, it seems that the network pattern, especially the global pattern which is captured by network embedding feature (AST), does not change in the same way for <em>T</em><sub>1</sub> and <em>T</em><sub>2</sub> leading to different range of feature values for both the classes in training and test set whereas the local neighborhood changing pattern captured by complex network measures are close for <em>T</em><sub>1</sub> and <em>T</em><sub>2</sub>, leading to decent performance.</p></section></section><section id="sec0030"><h2 id="sctt0033" class="u-h3 u-margin-l-top u-margin-xs-bottom">6. Detection of known shifts</h2><p id="p0073">So far, we have reported experiments on discovering novel senses from data and measured the accuracy of our method using manual evaluation. In this section, we evaluate the diachronic validity of our method on another task of detecting known shifts. We test whether our proposed method is able to capture the known historical shifts in meaning. For this purpose, we create a reference list <em>L</em> of <strong>15</strong> words that have been suggested by prior work&nbsp;(<a name="bbib0016" href="#bib0016" class="workspace-trigger">Eger, Mehler, 2016</a>, <a name="bbib0024" href="#bib0024" class="workspace-trigger">Hamilton, Leskovec, Jurafsky, 2016a</a>, <a name="bbib0025" href="#bib0025" class="workspace-trigger">Hamilton, Leskovec, Jurafsky, 2016b</a>) as having undergone a linguistic change and emerging with a novel sense. Note that, we focus only on nouns that emerge with a novel sense between 1900 and 1990. The goal of this task is to find out the number of cases for which our method is able to detect a novel sense from the list <em>L</em>, which in turn would prove the robustness of our method.</p><p id="p0074"><strong>Data:</strong> Consistent with the prior work, we use the Corpus of Historical American (COHA).<a name="bfn0006" href="#fn0006" class="workspace-trigger"><sup>6</sup></a> COHA corpus is carefully created to be genre balanced and is a well constructed prototype of American English over 200 years, from the time period 1810 to 2000. We extract the raw text data of two time slices: 1880–1900 and 1990–2000 for our experiment.</p><div><p id="p0075"><strong>Experiment details and results:</strong> We first construct distributional thesauri (DT) networks&nbsp;(<a name="bbib0045" href="#bib0045" class="workspace-trigger">Riedl &amp; Biemann,&nbsp;2013</a>) for the COHA corpus at two different time periods, 1880–1900 and 1990–2000. We apply Chinese Whispers algorithm&nbsp;(<a name="bbib0005" href="#bib0005" class="workspace-trigger">Biemann &amp; Bosch,&nbsp;2011</a>) to produce a set of clusters for each target word in the DT network. The Chinese Whispers clusters for the target word ‘web’ are shown in <a name="bfig0005" href="#fig0005" class="workspace-trigger">Fig.&nbsp;5</a>. Note that we have reported only some of the representative words for each cluster. Each of the clusters represents a particular sense of the target. We now compare the sense clusters extracted across two different time periods to obtain the suitable signals of sense change following the approach proposed in <a name="bbib0038" href="#bib0038" class="workspace-trigger">Mitra&nbsp;et&nbsp;al.&nbsp;(2014)</a><span><span>. After getting the novel sense clusters, we pick up 50 random samples, of which 25 cases are flagged as ‘true birth’ while the other 25 cases are flagged as ‘false birth’ by manual evaluation. We use these 50 samples as our training set for <a href="/topics/computer-science/classification" title="Learn more about classification from ScienceDirect's AI-generated Topic Pages" class="topic-link">classification</a> using </span><a href="/topics/computer-science/support-vector-machine" title="Learn more about SVM from ScienceDirect's AI-generated Topic Pages" class="topic-link">SVM</a>. Some of the examples of this training set are presented in </span><a name="btbl0023" href="#tbl0023" class="workspace-trigger">Table&nbsp;23</a>. We ensure that none of the words in the list <em>L</em><span> is present in the training set. Using this training set for our proposed SVM <a href="/topics/computer-science/classification-machine-learning" title="Learn more about classifier from ScienceDirect's AI-generated Topic Pages" class="topic-link">classifier</a>, we are successfully able to detect </span><strong>80%</strong> of the cases (12 out of 15) from the list <em>L</em> as having a novel sense. <a name="btbl0024" href="#tbl0024" class="workspace-trigger">Table&nbsp;24</a> presents all of these detected words along with the novel senses and the discriminative network feature. Our method is unable to detect three cases -‘gay’, ‘guy’ and ‘bush’. For ‘gay’, since there is no sense cluster in the older time period with ‘gay’ being a noun, cluster comparison does not even detect the ‘birth’ cluster of ‘gay’. The ‘birth’ sense clusters for ‘guy’, ‘bush’ in the new time period, as detected by split-join algorithm contain general terms like “someone, anyone, men, woman, mother, son” and “cloud, air, sky, sunlight” respectively. As the network around these words did not change much over time, our method found it difficult to detect. Note that even though COHA corpus is substantially smaller than the Google n-grams corpus, our approach produces promising results, showing the usability of the proposed method with corpora of limited size as well.</p><figure class="figure text-xs" id="fig0005"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0306457319303474-gr5.jpg" height="276" alt="Fig. 5" aria-describedby="cap0005"><ol class="links-for-figure"><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0306457319303474-gr5_lrg.jpg" target="_blank" download="" title="Download high-res image (356KB)"><span class="anchor-text">Download : <span class="download-link-title">Download high-res image (356KB)</span></span></a></li><li><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0306457319303474-gr5.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text">Download : <span class="download-link-title">Download full-size image</span></span></a></li></ol></span><span class="captions"><span id="cap0005"><p id="sp0009"><span class="label">Fig. 5</span>. Chinese Whisper clusters for the target word ‘web’ extracted from COHA corpus for the time periods 1880–1900 and 1990–2000.</p></span></span></figure><div class="tables colsep-0 frame-topbot rowsep-0" id="tbl0023"><span class="captions"><span id="cap0028"><p id="sp0032"><span class="label">Table 23</span>. Example cases from the training set used for the experiment on detecting known shifts. Evaluation has been done by annotators.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col" class="align-left valign-top">Word</th><th scope="col" class="align-left valign-top">‘birth’ cluster</th><th scope="col" class="align-left valign-top">Manual Evaluation</th></tr></thead><tbody><tr><td class="align-left valign-top"><em>caller</em></td><td class="align-left valign-top">phone, message, operator, customer, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-116-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.799ex" viewBox="0 -205.9 1172.5 343.9" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-116"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top"><strong>Yes</strong>, communication system related sense</td></tr><tr><td class="align-left valign-top"><em>courier</em></td><td class="align-left valign-top">transport, purchase, company, delivery, <span class="math"><span class="MathJax_Preview" style="display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-117-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.799ex" viewBox="0 -205.9 1172.5 343.9" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-117"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top"><strong>Yes</strong>, marketing related sense</td></tr><tr><td class="align-left valign-top">public</td><td class="align-left valign-top">student, economist, general, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-118-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.799ex" viewBox="0 -205.9 1172.5 343.9" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-118"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top"><strong>No</strong></td></tr><tr><td class="align-left valign-top">richness</td><td class="align-left valign-top">joy, happiness, stress, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-119-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.799ex" viewBox="0 -205.9 1172.5 343.9" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-119"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top"><strong>No</strong></td></tr></tbody></table></div></div><div class="tables colsep-0 frame-topbot rowsep-0" id="tbl0024"><span class="captions"><span id="cap0029"><p id="sp0033"><span class="label">Table 24</span>. Example cases from COHA corpus, having linguistic shifts as suggested by prior literature and correctly detected by our approach. The <a href="/topics/computer-science/discriminative-feature" title="Learn more about discriminative feature from ScienceDirect's AI-generated Topic Pages" class="topic-link">discriminative feature</a> shows the network measure which has changed the most over time.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col" class="align-left valign-top">Word</th><th scope="col" class="align-left valign-top">‘birth’ cluster</th><th scope="col" class="align-left valign-top">Discriminative feature</th></tr></thead><tbody><tr><td class="align-left valign-top">virus</td><td class="align-left valign-top">weapon, system, aircraft <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-120-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.799ex" viewBox="0 -205.9 1172.5 343.9" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-120"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top">Δ(SSM)</td></tr><tr><td class="align-left valign-top">cell</td><td class="align-left valign-top">network, satellite, phone, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-121-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.799ex" viewBox="0 -205.9 1172.5 343.9" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-121"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top">Δ(SSM)</td></tr><tr><td class="align-left valign-top">monitor</td><td class="align-left valign-top">computer, TV, screen, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-122-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.799ex" viewBox="0 -205.9 1172.5 343.9" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-122"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top">Δ(ED)</td></tr><tr><td class="align-left valign-top">axis</td><td class="align-left valign-top">missile, fire, satellite, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-123-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.799ex" viewBox="0 -205.9 1172.5 343.9" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-123"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top">Δ(ED)</td></tr><tr><td class="align-left valign-top">broadcast</td><td class="align-left valign-top">TV, cable, service, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-124-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.799ex" viewBox="0 -205.9 1172.5 343.9" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-124"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top">Δ(APL)</td></tr><tr><td class="align-left valign-top">check</td><td class="align-left valign-top">wage, donation, fee, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-125-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.799ex" viewBox="0 -205.9 1172.5 343.9" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-125"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top">Δ(APL)</td></tr><tr><td class="align-left valign-top">film</td><td class="align-left valign-top">show, concert, script, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-126-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.799ex" viewBox="0 -205.9 1172.5 343.9" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-126"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top">Δ(ED)</td></tr><tr><td class="align-left valign-top">focus</td><td class="align-left valign-top">concern, ambition, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-127-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.799ex" viewBox="0 -205.9 1172.5 343.9" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-127"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top">Δ(APL)</td></tr><tr><td class="align-left valign-top">major</td><td class="align-left valign-top">university, discipline, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-128-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.799ex" viewBox="0 -205.9 1172.5 343.9" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-128"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top">Δ(APL)</td></tr><tr><td class="align-left valign-top">program</td><td class="align-left valign-top">project, database, testing, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-129-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.799ex" viewBox="0 -205.9 1172.5 343.9" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-129"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top">Δ(ED)</td></tr><tr><td class="align-left valign-top">record</td><td class="align-left valign-top">tape, card, disc, copy <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-130-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.799ex" viewBox="0 -205.9 1172.5 343.9" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-130"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top">Δ(SSM)</td></tr><tr><td class="align-left valign-top">web</td><td class="align-left valign-top">Web, Internet, network <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-131-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo is=&quot;true&quot;>&amp;#x2026;</mo></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="0.799ex" viewBox="0 -205.9 1172.5 343.9" role="img" focusable="false" style="vertical-align: -0.32ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><use xlink:href="#MJMAIN-2026"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo is="true">…</mo></math></span></span><script type="math/mml" id="MathJax-Element-131"><math><mo is="true">…</mo></math></script></span></td><td class="align-left valign-top">Δ(ED)</td></tr></tbody></table></div></div></div></section><section id="sec0031"><h2 id="sctt0034" class="u-h3 u-margin-l-top u-margin-xs-bottom">7. Conclusion</h2><p id="p0076"><span><span><span>In this study, we dealt with the task of improving the performance of novel sense detection task by borrowing concepts from <a href="/topics/computer-science/complex-network-theory" title="Learn more about complex network theory from ScienceDirect's AI-generated Topic Pages" class="topic-link">complex network theory</a>, which is an attempt of first of its kind. In order to improve the precision of detecting words evolved with a new sense over time, we demonstrated how the change in the network properties of the induced subgraphs from a sense cluster can be used. In addition, to investigate the superiority of complex network measures in this task, we explore the measures computed from the network representation learning framework as well. Manual evaluation over two different time period pairs shows that the proposed </span><a href="/topics/computer-science/support-vector-machine" title="Learn more about SVM from ScienceDirect's AI-generated Topic Pages" class="topic-link">SVM</a><span> <a href="/topics/computer-science/classification" title="Learn more about classification from ScienceDirect's AI-generated Topic Pages" class="topic-link">classification</a><span> approach boosts the precision values from 0.23–0.32 to 0.74–0.86 with a decent F-measure value of 0.67–0.68 when fed with only complex network measures. Even though the combination of complex network measures and network embedding measures improve the precision further to 0.76–0.91 in different scenarios, the F-measure falls significantly proving the superiority of complex network measures over network embedding measures. Note that, using only network embedding measures as features to the <a href="/topics/computer-science/classification-models" title="Learn more about classification model from ScienceDirect's AI-generated Topic Pages" class="topic-link">classification model</a> leads to very poor performance compared to the model using only complex network measures. This study also shows that if we can intelligently apply complex network theory to come up with some intuitive measures to be used in a problem dealing with only local </span></span></span><a href="/topics/computer-science/network-structure" title="Learn more about network structures from ScienceDirect's AI-generated Topic Pages" class="topic-link">network structures</a>, it can produce better or comparable performance than the network embedding measures which is otherwise computationally heavy to compute. Finally, from the experiments on the COHA corpus, we have also shown that our approach can reliably detect the words known to have sense shifts. The gold standard dataset prepared by us for validating novel sense detection is one of our main contributions and is made available publicly</span><a name="bfn0007" href="#fn0007" class="workspace-trigger"><sup>7</sup></a>.</p><p id="p0077">In future, we plan to apply our methodology to different genres of corpus, like <a href="/topics/computer-science/social-network-data" title="Learn more about social network data from ScienceDirect's AI-generated Topic Pages" class="topic-link">social network data</a>, several product or movie reviews data which are becoming an increasingly popular source for opinion tracking, to identify short-term changes in word senses or usages. These analyses would also provide insights into the evolution of language in a short span of time. Our ultimate goal is to prepare a generalized framework for accurate detection of sense change across languages and investigate the triggering factors behind language evolution as well.</p></section><section id="sec0031a"><h2 id="sctt0034a" class="u-h3 u-margin-l-top u-margin-xs-bottom">CRediT authorship contribution statement</h2><p id="p0077a"><strong>Abhik Jana:</strong><span> Conceptualization, <a href="/topics/computer-science/data-curation" title="Learn more about Data curation from ScienceDirect's AI-generated Topic Pages" class="topic-link">Data curation</a>, Writing - original draft, Investigation, Software, Validation, Writing - review &amp; editing. </span><strong>Animesh Mukherjee:</strong> Conceptualization, Investigation, Supervision, Writing - review &amp; editing. <strong>Pawan Goyal:</strong> Conceptualization, Investigation, Supervision, Writing - review &amp; editing.</p></section></div><div class="Appendices"><section id="sec0032"><h2 id="sctt0036" class="u-h3 u-margin-l-top u-margin-xs-bottom">Appendix A. Supplementary materials</h2><p id="p0079"><span class="display"><span class="e-component e-component-mmc1" id="ecom0001"><span class="article-attachment"><a class="icon-link" href="https://ars.els-cdn.com/content/image/1-s2.0-S0306457319303474-mmc1.xml" title="Download XML file (361B)" target="_blank" rel="noreferrer noopener"><svg focusable="false" viewBox="0 0 95 128" width="17.8125" height="24" class="icon icon-document"><path d="m35.6 1e1c-5.38 0-10.62 1.92-14.76 5.4-9.1 7.68-18.84 20.14-18.84 32.1v70.5h9e1v-108zm0 1e1h46.4v88h-7e1v-49c0-6.08 4.92-11 11-11h17v-2e1h-6c-2.2 0-4 1.8-4 4v6h-7c-3.32 0-6.44 0.78-9.22 2.16 2.46-5.62 7.28-11.86 13.5-17.1 2.34-1.98 5.3-3.06 8.32-3.06z"></path></svg></a><a class="anchor download-link u-font-sans" href="https://ars.els-cdn.com/content/image/1-s2.0-S0306457319303474-mmc1.xml" target="_blank" download="" title="Download XML file (361B)"><span class="anchor-text">Download : <span class="download-link-title">Download XML file (361B)</span></span></a></span><span class="captions"><span id="cap0030"><p id="sp0003"><span class="label">Supplementary Data S1</span>. <span>Supplementary Raw Research Data. This is <a href="/topics/computer-science/open-data" title="Learn more about open data from ScienceDirect's AI-generated Topic Pages" class="topic-link">open data</a> under the CC BY license </span><a href="http://creativecommons.org/licenses/by/4.0/" target="_blank" rel="noreferrer noopener">http://creativecommons.org/licenses/by/4.0/</a></p></span></span></span></span></p></section></div></div>
