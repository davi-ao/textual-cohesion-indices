In recent years, much attention has been given to the study of frames in the field of communication research, particularly focusing on how the news media frame issues in text. Framing analysis is salient in understanding the potential of the media to influence public opinion (Entman, 1991, Bardhan, 2001). The subject has garnered a huge appeal across the communication and media disciplines including, but not limited to, policy, media content, and cultural studies (Joachim, 2003, Shah et al., 2002, Hoerl et al., 2009, Yeo et al., 2007, Ryan et al., 2001).
Framing, in this context, is interpreted as the ”central organizing idea for making sense of an issue or conflict and suggesting what is at stake (Gamson, 1989, Koch, 1998).” The main challenge is to identify and asses the latent schemes that emerge from a reporting of an issue and recognize them in the most optimized, reliable, and accurate way.
Early framing studies were particularly qualitative in nature using entirely hermeneutic approaches. As such, most of these analyzes were highly dependent on the experts doing the exegesis. Hence, such subjective procedure could potentially cast doubts on the reliability and accuracy of the interpretation (Scheufele and Scheufele, 2010, Van Gorp, 2005); moreover, issues on replicability plague the evaluation measures.
More recent studies, on the other hand, address these issues using more exact quantitative models (Miller, 1997, Miller et al., 1998). Quantitative framing researchers argue that the methods provided are more precise and straightforward and are repeatable – usually done with the aide of “devices” as frame indicators (Koella, 2003). Most of these techniques are computer-assisted, which is the exact antithesis of the more traditional approach. Typically, the methods utilize frequency-statistics of certain keywords and their loci in the body of the texts (Legara et al., 2010, Murphy, 2001). Although the approach improves reliability, criticisms regarding its validity have been raised since it has been shown that some infrequently occurring words in the text could actually be “central to the meaning of a text”; and, by filtering in only the most frequently occurring words in the examination, a significant amount of nontrivial information can be lost in the process (Scheufele and Scheufele, 2010, Matthes and Kohring, 2008).
Although much has been done in expanding its domain, existing risks vis-à-vis the reliability and validity of framing protocols are still of major concern. Due to this fuzzy nature of frames, naming and quantifying them have proven to be quite complex, which calls for a multi-disciplinary approach involving both domain and computation experts.
On the other hand, the science of networks has emerged to be a leading approach in probing signatures of complex systems inherent in both nature and society. Networks have been shown to detect cryptic patterns that contain germane information about such systems, e.g. DNA nuecleotides sequence data (Sinatra, Condorelli, & Latora, 2010), dissimilarity between poem and prose (Roxas & Tapang, 2010). In this study, one of the main challenges in applying network theory is in deciphering the hidden patterns through the use of the most appropriate symbolic representations of the compendium of data. It is important to correctly detect the “fundamental units carrying information” in constructing the networks (Sinatra et al., 2010).
Here, we investigate and improve upon existing framing analysis protocols and tackle them in the context of network theory. The research is relevant on two levels: social and methodological. The procedures performed here utilize text from media coverage of a vehemently debated issue in most, if not all, developing countries – the issue on population, reproductive health, and family planning. The population issue has consternated governments of developing countries when concerns are retracted to issues on poverty and women’s health. Particularly, we look into the Philippine news coverage. The Philippines is a developing country that is predominantly Catholic (80% of the population), and is ranked fourth (4) worldwide in terms of total population and population density and has been noted by the United States Census Bureau as a fast growing country (Central Intelligence Agency Online Factbook, 2012).
On the methodological significance, detecting media frames has produced a significant number of theories, techniques, and procedures. However, there are very few studies that compares the consistency of the results generated by these various methods because typically only one framing procedure is used to dissect an issue. Here, we utilize and compare three distinct methods in the study of media framing and compare their consistencies, advantages and procedural differences.
This study covers a total of 346 news articles related to issues on population, family planning, reproductive health, and contraception. The period covered runs from 1987 to 2007. Data were taken from three of the most widely circulated broadsheets in the Philippines namely, the Philippine Daily Inquirer (PDI), the Philippine Star (PS), and the Manila Bulletin (MB).
Perhaps the most traditional method used to find frames is through the perusal of texts by experts of both the issues under study and the field of communication research. A singular holistic approach (SHA) to framing, which is deductive in nature, was carried out. Here, a single frame was considered as a lone reference to a whole article. Coders defined six frames after methodically familiarizing the topic through a careful review of a small sample of text on the issue. The pre-defined frame themes are as follows: the population and development frame (F1), the family planning as conflict between government and church frame (F2), the women’s and reproductive health frame (F3), the population management threatens morals and values frame (F4), the population growth and demographic trends frame (F5), and others. Communication research assistants were then instructed to classify each document in the corpus to a single dominant frame (chosen from the six pre-defined ones). Table 1 summarizes the number of articles classified in the six frames.
In Section 4, frames are treated as a collection of elements comprising an issue, which makes the analysis more guided. Essentially, frames are dissected into several parts that are interconnected to each other. This notion was first introduced by Kohring and Matthes (2002) and the conceptual basis behind the technique stemmed from the widely-accepted definition of framing given by Entman: “the process of highlighting some select aspects of a news or an article to publicize a specific problem definition, causal interpretation, moral evaluation, and/or treatment recommendation for the item described” (Entman, 1993). These elements are thought to constitute a frame theme. It should be noted that depending on the issue at hand, there can be multiple cases of each of these elements.
Content analytic variables (CAVs) were then infused in the analysis making the classification more systematic. As an example, for the frame element problem definition, the corresponding CAVs are: topic/theme, actor, and proponent. Table 2 summarizes the frame elements and the associated CAVs. These CAVs are further anatomized into single binary variables, resulting to a total of 71 variables (see Table 3, Table 4, Table 5, Table 6). Coders then analyze each article based on the binary CAVs. A sample coding sheet is shown in Table 7 where columns represent the CAV scores while rows represent the cases.
Since by definition a frame is a collection of frame elements, it is presumed that such consists of a unique set of binary variables that form a dominant pattern, which emerges out of the CAVs’ interconnectivity. Matthes and Kohring (2008) emphasized that this procedure has an added complexity since it calls for an optimized clustering procedure of frame elements. In fact, MK disclosed that one of the liabilities in their method of using k-means clustering is that “problems may occur when conducting cluster analysis of frame element” since it does not have a systematic way of determining the optimal number of clusters (Matthes & Kohring, 2008).
One of the strengths of using complex networks in clustering analysis is its ability to extract these latent patterns without prior knowledge about the number of clusters that need to be extracted. This fundamentally addresses the clustering issue raised by MK.
Hence, we construct a network from the corpus A<math><mrow is="true"><mi mathvariant="script" is="true">A</mi></mrow></math> of n = 346 articles, i.e. A≡{α1,α2,…,αn=346}<math><mrow is="true"><mi mathvariant="script" is="true">A</mi><mo is="true">≡</mo><mo stretchy="false" is="true">{</mo><msub is="true"><mrow is="true"><mi is="true">α</mi></mrow><mrow is="true"><mn is="true">1</mn></mrow></msub><mtext is="true">,</mtext><msub is="true"><mrow is="true"><mi is="true">α</mi></mrow><mrow is="true"><mn is="true">2</mn></mrow></msub><mtext is="true">,</mtext><mo is="true">…</mo><mtext is="true">,</mtext><msub is="true"><mrow is="true"><mi is="true">α</mi></mrow><mrow is="true"><mi is="true">n</mi><mo is="true">=</mo><mn is="true">346</mn></mrow></msub><mo stretchy="false" is="true">}</mo></mrow></math>, and then perform contemporary clustering methods from network theory.
Each article αi in the ensemble is described by a set Vi≡{ν1,ν2,…,νj=71}<math><mrow is="true"><msub is="true"><mrow is="true"><mi mathvariant="script" is="true">V</mi></mrow><mrow is="true"><mi is="true">i</mi></mrow></msub><mo is="true">≡</mo><mo stretchy="false" is="true">{</mo><msub is="true"><mrow is="true"><mi is="true">ν</mi></mrow><mrow is="true"><mn is="true">1</mn></mrow></msub><mtext is="true">,</mtext><msub is="true"><mrow is="true"><mi is="true">ν</mi></mrow><mrow is="true"><mn is="true">2</mn></mrow></msub><mtext is="true">,</mtext><mo is="true">…</mo><mtext is="true">,</mtext><msub is="true"><mrow is="true"><mi is="true">ν</mi></mrow><mrow is="true"><mi is="true">j</mi><mo is="true">=</mo><mn is="true">71</mn></mrow></msub><mo stretchy="false" is="true">}</mo></mrow></math> of variable ratings that provides coder ratings for each CAV νj in Vi<math><mrow is="true"><msub is="true"><mrow is="true"><mi mathvariant="script" is="true">V</mi></mrow><mrow is="true"><mi is="true">i</mi></mrow></msub></mrow></math>. Now, for every article αi∈A<math><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">α</mi></mrow><mrow is="true"><mi is="true">i</mi></mrow></msub><mo is="true">∈</mo><mi mathvariant="script" is="true">A</mi></mrow></math>, a 71 × 71 adjacency matrix Mi of all content analytic variables νj∈Vi<math><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">ν</mi></mrow><mrow is="true"><mi is="true">j</mi></mrow></msub><mo is="true">∈</mo><msub is="true"><mrow is="true"><mi mathvariant="script" is="true">V</mi></mrow><mrow is="true"><mi is="true">i</mi></mrow></msub></mrow></math> is constructed that represents the connectivity of vertices of the weighted graph Gi(Vi,Ei)<math><mrow is="true"><msub is="true"><mrow is="true"><mi mathvariant="script" is="true">G</mi></mrow><mrow is="true"><mi is="true">i</mi></mrow></msub><mo stretchy="false" is="true">(</mo><mi is="true">V</mi><msub is="true"><mrow is="true"><mspace width="0.35em" height="0.8ex" is="true"></mspace></mrow><mrow is="true"><mi is="true">i</mi></mrow></msub><mtext is="true">,</mtext><msub is="true"><mrow is="true"><mi is="true">E</mi></mrow><mrow is="true"><mi is="true">i</mi></mrow></msub><mo stretchy="false" is="true">)</mo></mrow></math>, where Ei = {ekl} is the set of all edges or links in the network and Vi is the set of all nodes representing all 71 analytic variables Vi≡{ν1,ν2,…,νj=65}<math><mrow is="true"><msub is="true"><mrow is="true"><mi mathvariant="script" is="true">V</mi></mrow><mrow is="true"><mi is="true">i</mi></mrow></msub><mo is="true">≡</mo><mo stretchy="false" is="true">{</mo><msub is="true"><mrow is="true"><mi is="true">ν</mi></mrow><mrow is="true"><mn is="true">1</mn></mrow></msub><mtext is="true">,</mtext><msub is="true"><mrow is="true"><mi is="true">ν</mi></mrow><mrow is="true"><mn is="true">2</mn></mrow></msub><mtext is="true">,</mtext><mo is="true">…</mo><mtext is="true">,</mtext><msub is="true"><mrow is="true"><mi is="true">ν</mi></mrow><mrow is="true"><mi is="true">j</mi><mo is="true">=</mo><mn is="true">65</mn></mrow></msub><mo stretchy="false" is="true">}</mo></mrow></math> in the study. Mi is a symmetric (0,1)-matrix with diagonal entries mkk = 0 since Gi<math><mrow is="true"><msub is="true"><mrow is="true"><mi mathvariant="script" is="true">G</mi></mrow><mrow is="true"><mi is="true">i</mi></mrow></msub></mrow></math> is an unweighted undirected graph with no self-loops. In Mi, mkl = 1.0 if content analytic variables νk and νl are rated 1.0 together in article αi, mkl = 0 otherwise. To illustrate, we utilize the schematic coding in Table 7 to construct three networks, one for each article αi (see Fig. 1). For every Gi<math><mrow is="true"><msub is="true"><mrow is="true"><mi mathvariant="script" is="true">G</mi></mrow><mrow is="true"><mi is="true">i</mi></mrow></msub></mrow></math>, a maximum clique Ci,max, which is a subset of Vi exists such that for every two vertices νk and νl ∈ Ci,max an edge ekl ∈ Ei exists. In Fig. 1, Article 1 has maximum clique C1 = {ν1, ν3, ν4, ν7}. The clique vertices show all content analytic variables rated 1.0 together in sample article α1.
Fig. 2 shows an empirical maximum clique C0,max⊂G0<math><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">C</mi></mrow><mrow is="true"><mn is="true">0</mn><mtext is="true">,</mtext><mi mathvariant="normal" is="true">max</mi></mrow></msub><mo is="true">⊂</mo><msub is="true"><mrow is="true"><mi mathvariant="script" is="true">G</mi></mrow><mrow is="true"><mn is="true">0</mn></mrow></msub></mrow></math> extracted from one of the sample documents in the corpus. In the figure, isolated vertices are removed for a better illustration, thereby leaving a fully-connected network. Constructing all maximum cliques across 346 articles, it was found that the average clique number ω¯(Gi)<math><mrow is="true"><mover accent="true" is="true"><mrow is="true"><mi is="true">ω</mi></mrow><mrow is="true"><mo is="true">¯</mo></mrow></mover><mo stretchy="false" is="true">(</mo><msub is="true"><mrow is="true"><mi mathvariant="script" is="true">G</mi></mrow><mrow is="true"><mi is="true">i</mi></mrow></msub><mo stretchy="false" is="true">)</mo></mrow></math> is 11.
Finally, a weighted graph G(V, E) was constructed from the individual Gi<math><mrow is="true"><msub is="true"><mrow is="true"><mi mathvariant="script" is="true">G</mi></mrow><mrow is="true"><mi is="true">i</mi></mrow></msub></mrow></math>’s where, this time, E(G) = {ekl} is the set of all weighted edges wkl∈{Z+}<math><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">w</mi></mrow><mrow is="true"><mi mathvariant="italic" is="true">kl</mi></mrow></msub><mo is="true">∈</mo><mo stretchy="false" is="true">{</mo><msup is="true"><mrow is="true"><mi mathvariant="double-struck" is="true">Z</mi></mrow><mrow is="true"><mo is="true">+</mo></mrow></msup><mo stretchy="false" is="true">}</mo></mrow></math>. In terms of the adjacency matrix representation as discussed previously,(1)MG=∑i=1346Mi.<math><msub is="true"><mrow is="true"><mi mathvariant="bold" is="true">M</mi></mrow><mrow is="true"><mi is="true">G</mi></mrow></msub><mo is="true">=</mo><mstyle displaystyle="true" is="true"><munderover is="true"><mrow is="true"><mo is="true">∑</mo></mrow><mrow is="true"><mi is="true">i</mi><mo is="true">=</mo><mn is="true">1</mn></mrow><mrow is="true"><mn is="true">346</mn></mrow></munderover></mstyle><msub is="true"><mrow is="true"><mtext is="true">M</mtext></mrow><mrow is="true"><mi is="true">i</mi></mrow></msub><mtext is="true">.</mtext></math>
The final weighted network G(V, E) is shown in Fig. 3.
The method of community detection was then applied on graph G(V, E) to reveal grouping patterns among CAVs. A community, in the context of complex network theory, is the “existence of the networks’ structural subunits that are associated with more highly interconnected parts.” Palla, Dernyi, Farkas, and Vicsek (2005) Essentially, natural partitions are identified and extracted within the network through non-homogeneous connectivities. A modularity optimization algorithm introduced by Blondel et al. was utilized (1) because of its capability to return high-quality partitions, which are quantified by the modularity function of the communities; and (2) for fast community detection, which was shown to be superior in terms of computation time when compared to other existing algorithms (Blondel, Guillaume, Lambiotte, & Lefebvre, 2008). The modularity Q of a partition evaluates the density of edges within communities as compared to edges between communities (Newman, 2006, Newman and Girvan, 2004). The value lies in the range [−1,1]. Mathematically, it is defined as(2)Q=12m∑k,lwkl-sksl2mδ(ck,cl),<math><mi is="true">Q</mi><mo is="true">=</mo><mfrac is="true"><mrow is="true"><mn is="true">1</mn></mrow><mrow is="true"><mn is="true">2</mn><mi is="true">m</mi></mrow></mfrac><mstyle displaystyle="true" is="true"><munder is="true"><mrow is="true"><mo is="true">∑</mo></mrow><mrow is="true"><mi is="true">k</mi><mtext is="true">,</mtext><mi is="true">l</mi></mrow></munder></mstyle><mrow is="true"><mfenced open="[" close="]" is="true"><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">w</mi></mrow><mrow is="true"><mi mathvariant="italic" is="true">kl</mi></mrow></msub><mo is="true">-</mo><mfrac is="true"><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">s</mi></mrow><mrow is="true"><mi is="true">k</mi></mrow></msub><msub is="true"><mrow is="true"><mi is="true">s</mi></mrow><mrow is="true"><mi is="true">l</mi></mrow></msub></mrow><mrow is="true"><mn is="true">2</mn><mi is="true">m</mi></mrow></mfrac></mrow></mfenced></mrow><mi is="true">δ</mi><mo stretchy="false" is="true">(</mo><msub is="true"><mrow is="true"><mi is="true">c</mi></mrow><mrow is="true"><mi is="true">k</mi></mrow></msub><mtext is="true">,</mtext><msub is="true"><mrow is="true"><mi is="true">c</mi></mrow><mrow is="true"><mi is="true">l</mi></mrow></msub><mo stretchy="false" is="true">)</mo><mtext is="true">,</mtext></math>for weighted networks where wkl represents the edge weight between vertices k and l, sk=∑lwkl<math><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">s</mi></mrow><mrow is="true"><mi is="true">k</mi></mrow></msub><mo is="true">=</mo><msub is="true"><mrow is="true"><mo is="true">∑</mo></mrow><mrow is="true"><mi is="true">l</mi></mrow></msub><msub is="true"><mrow is="true"><mi is="true">w</mi></mrow><mrow is="true"><mi mathvariant="italic" is="true">kl</mi></mrow></msub></mrow></math> is the sum of all the edge weights connected to vertex k, ck is the community to which vertex k is assigned, the δ(ck = cl) = 1 if ck = cl and 0 otherwise and W=12∑klwkl<math><mrow is="true"><mi is="true">W</mi><mo is="true">=</mo><mfrac is="true"><mrow is="true"><mn is="true">1</mn></mrow><mrow is="true"><mn is="true">2</mn></mrow></mfrac><msub is="true"><mrow is="true"><mo is="true">∑</mo></mrow><mrow is="true"><mi mathvariant="italic" is="true">kl</mi></mrow></msub><msub is="true"><mrow is="true"><mi is="true">w</mi></mrow><mrow is="true"><mi mathvariant="italic" is="true">kl</mi></mrow></msub></mrow></math> (Newman & Girvan, 2004).
The greedy-algorithm introduced by Blondel et al. is iterative and involves two general steps. First, it goes through all vertices in sequence. It starts, for example, at vertex k. It then calculates for the weighted modularity Q using Eq. (2) every time vertex k is placed in the community of its neighbor l. It goes through all the neighbors l and calculates for Q. It then picks out the community of l that returns the highest increase in Q, if and only if it is positive. This process results to a first level partition. In the second step, the extracted communities are substituted with dummy vertices called “supervertices”. This virtually reduces the network size. Two “supervertices” are then linked together if there exists at least an edge between vertices of the respective communities at the lower level. The edges between these “supervertices” are weighted by adding the weights of the represented partitions at the lower level. The algorithm is described in detail in reference (Blondel et al., 2008).
Finally, we have chosen this particular method over other more traditional clustering algorithms because it automatically returns the optimal number of communities that results to maximum modularity, i.e. the number of partitions are not pre-defined unlike in other clustering methods where one has to indicate the number of partitions beforehand (e.g. k-clustering). In terms of maximizing the reliability of framing analysis, analysts need not impose the number of clusters that is expected from the collection; therefore, it is more objective in nature. Another advantage of this algorithm is that there is no unnecessary removal of information caused by the deletion of weak links in the analysis as opposed to other methods where cutoffs have to be set to gain more defined results (Matthes & Kohring, 2008).
To demonstrate the superiority of the method over other clustering methods, we perform latent class analysis (LCA), which is regarded by framing scholars as the ”most advanced clustering technique” (Personal communication) that gives a clear criteria for the number of clusters of frame elements in the analysis. LCA is especially superior in explorative clustering analysis where no information about the theoretical number of clusters is indicated. The basic latent class model is a finite mixture model (Lazarsfeld, 1950, Lewis and Linzer, 2011) that links a series of manifest variables to a group of latent classes. In this research, LCA was implemented in R using the polytomous variable latent class analysis (poLCA) R package developed by Lewis and Linzer (2011) where expectation–maximization and Newton–Raphson algorithms were utilized to find maximum-likelihood estimates of the manifest variables.
In LCA, the two most commonly used measures that determine the best-fitting model in a system are the Bayesian information criterion (BIC) (Schwartz, 1978) and the Aikaike information criterion (AIC) (Akaike, 1973). The best-fitting model is the one that minimizes the criteria. Without loss of generality, we used the BIC (Forster, 2000, Lin and Dayton, 1997), which is given by(3)BIC=-2Γ+ΦlnN,<math><mi mathvariant="monospace" is="true">BIC</mi><mo is="true">=</mo><mo is="true">-</mo><mn is="true">2</mn><mi mathvariant="normal" is="true">Γ</mi><mo is="true">+</mo><mi mathvariant="normal" is="true">Φ</mi><mi mathvariant="normal" is="true">ln</mi><mi is="true">N</mi><mtext is="true">,</mtext></math>where Γ is the maximum log-likelihood of the model and Φ the number of evaluated variables.
We did several runs (500) for various classes (k = 2 to 7) in the LCA and calculated for the respective mean and minimum BIC values. Fig. 4 plots the different BIC values obtained, highlighting both the mean (hollow) and minimum (filled) BICs for each class k. The plot indicates that if the minimum BIC is utilized as an indicator, the best model gives four clusters (4 frames). However, if the mean BIC is used, the best model results to three culsters (3 frames). Looking closer into the three (3) and four (4) classification models, respectively, we have Fig. 5(a) and (b). The two graphs indicate the population shares of the classes and the outcome probabilities (strength) of the manifest variables. In the four-class system (Fig. 5(b)), it can be noted that one of the classes has a population share of less than 0.50% of the entire corpus of articles. This partitioning could just as well be a three-class system (Fig. 5(a)) since a share of less than 0.50% is less than the standard deviation of the population distributions across runs.
The results using the community detection algorithm (CDA) indicate that the most optimal partition would be to group the articles into three (3) communities (see Table 8), with Q = 0.1550 for several runs, which indicates that the number of edges within groups exceeds the number expected on the basis of chance. These patterns essentially descirbe the co-occurrences and interconnectivity of the binary variables in the corpus. Moreover, since frames consist of such patterns, the three communities indicate that three dominant frames exist in the population and family planning issue.
Scrutinizing the extracted communities of variables reveals a solid framing rationale. In addition, all partitions have at least one representative variable for all frame elements, which have been enumerated in Entman’s definition of frame (topic, actor, benefit or risk, solution, and proponent), which means that the key ingredients in defining a frame are in each of the three communities. After a careful investigation of the collection of variables in each community, experts were able to define these three frames: the population growth and development frame (Community 1, C1), the reproductive health frame (Community 2, C2), and the family planning/population management threatens moral values frame (Community 3, C3). A more comprehensive argument regarding how these frames were defined are discussed elsewhere (David, Atun, Legara, & Monterola, 2011). It is important to highlight that the result here is in high agreement with the result obtained by (Legara et al., 2010) using syntactic network analysis where three frame themes were identified: Development Frame, Maternal Health Frame, and Framing by the Catholic Church (Legara et al., 2010). Table 9 shows a side-by-side tablet comparison of all three differing methods.
In this section, we compare the validity and reliability of the results obtained using the two methods singular holistic approach (SHA) in Section 3 and community detection approach (CDA) in Section 4. In Section 3, the SHA resulted to six (6) pre-defined frames: the population and development frame (F1), the family planning as conflict between government and church frame (F2), the women’s and reproductive health frame (F3), the population management threatens morals and values frame (F4), the population growth and demographic trends frame (F5), and others while in the community detection approach, the computer-assisted algorithm returned three: the population growth and development frame (C1), the reproductive health frame (C2), and the family planning/population management threatens moral values frame (C3).
To quantify the extent of difference and/or similarity of the results, a clique detection method was employed on the corpus together with the SHA results. To do so, we utilized network G(V, E) and added six more nodes or vertices in the network that represent the six categorical variables (frame1, frame2, …, frame6). Consider that on top of filling-out the “code sheets”, the coders were also asked to categorize each article αi to a dominant frame based on their understanding of the subject matter after a perusal of the text. Including the six categorical variables (CV), a “code sheet” now looks like Table 10. The method for adding the edges connected to the joined categorical variables is the same as in the procedure discussed above. When an article αi is rated 1.0 in a categorical variable, then that variable has an edge that connects it to all other CAVs that are rated 1.0 in αi. Needless to say, the categorical variables are mutually exclusive and that the final edges are weighted.
All sets of maximal cliques containing a given CV were then extracted. From a sociological perspective, a clique is a small group of individuals with shared interests, patterns of behavior, or other attributes or qualities in common (Jones & Gerard, 1967). In the same light, by calculating all cliques linked to the mutually exclusive CVs, we get to extract other variables (the CAVs) that are “similar” to them. It is conjectured that this commonality or “shared interest” among content analytic variables is associative to the frames that they describe, respectively. Since we are only focused on relationships between variables, we introduced a cutoff edge-weight wcutoff = 20, which is approximately 5% of the total number of articles, whereby all wkl < wcutoff, ekl is removed from E(G). What this cutoff means is that we only consider co-occurrence of two variables k and l if and only if they have been rated 1.0 together in at least 20 of the news articles. This gives us a more reliable and stronger vertex–vertex connection. The stronger the links between the variables are, the more reliable the relationships and therefore, the patterns. Without loss of generality, this process just increases the resolution of the analysis. The resulting network (with both the content analytic variables and the categorical ones) is shown in Fig. 6. For a much easier visual representation of the resulting network, Fig. 7 shows a Venn diagram of the “frame sets”.
The obtained cliques in this reduced network are quite distinct albeit there are certain content analytic variables that belong to more than one set (see Fig. 7). Clearly, the frames are not mutually exclusive (due to the overlaps) to each other. This result is rather intuitive.
Increasing the cut-off variable further to 25, wcutoff = 25, more distinct groupings (lesser overlaps) appear (see Fig. 8). The method used also showed that a few variables (ttgov, positive, sfplan) are present in all the cliques identified. Since these elements do not seem to contribute in the uniqueness of frames, we removed them in the subsequent analysis, including the categorical variable frame6.
The clique detection method reveals that although there are six (6) predefined frames, three of these are subsets of at least one of the other frame sets. In fact, results show that there are three dominant sets that are mutually exclusive of each other when the variables ttgov, positive, sfplan are removed: F1, F2, and F3. Moreover, F5 ⊂ F1, F4 ⊂ F2 and finally F6 ⊂ F1, F2, and F3. By simplifying the six pre-defined frame sets to three exclusive ones, results show that the two methods are now in perfect agreement. It is also important to highlight that the results obtained here agree very well with the results recently published that enumerated framing themes surrounding the population issue using syntactic network analysis (Legara et al., 2010).
In conclusion, we performed framing analysis on a corpus of news texts on the population and family planning issue in the Philippines using two distinct approaches. A more traditional singular holistic procedure was initially implemented where coders classified each news text to a specific pre-defined frame. Then, we demonstrated a new framing approach that casts the resulting codings as a network of content analytic variables (CAVs). Here, frames were treated as a collection of elements forming patterns in the CAV network. We showed that both procedures are consistent with the results derived using syntactic network analysis (Legara et al., 2010). Finally, we note that the method illustrated here can be utilized to address the clustering issue that plagued framing scholars in their quantitative exploration of news frames in texts.
The authors acknowledge help of J.M. Atun in the data collection and coding process. C.M. and E.F.L are supported by Singapore A∗STAR SERC Complex Systems Programme’s research grant (1224504056).