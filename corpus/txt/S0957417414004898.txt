In the information explosion era, web directory greatly reduces the number of returned webpages pushed by keyword search. This task is realized by classifying the webpages based on the semantic content. However, it is faced with great challenge resulted from the tremendous amount of web information. Besides, the webpages usually consist of textual information, images, audios, etc. All the information is unstructured and sets obstacles for computers to catch the semantic themes of the webpages. One good method to handle the unstructured data is tagging. It abstracts structured tags from unstructured content in webpages. Nowadays, a number of prominent web sites feature collaborative tagging which allows users to tag and share content publicly (Golder & Huberman, 2012). Tagging has been regarded as a possible solution to improve the searching of networked resources, as well as a means to support the personalized use (Guy and Tonkin, 2006, Trant, 2009, Ñanculef et al., 2014).
However, the cold reality is that, a large number of infrequently requested websites exist on the Internet (Kumar, Norris, & Sun, 2009). These webpages get sparse tags, leading to the ambiguity of their classification. In this paper, the less popular and sparsely tagged webpages are called hesitant webpages. These webpages share some common points with the tail data (Anderson, 2006). Though the tail resources are less popular, they might begin to show their power (Anderson & Andersson, 2007). Under this circumstance, classifying hesitant webpages properly has profound meaning in promoting information utilization and retrieval in networks.
Traditional classification methods cannot deal with the hesitant webpages properly. Partition-based methods, like the k-means (MacQueen, 1967), and density-based methods, like the DBSCAN (Ester, Kriegel, Sander, & Xu, 1996), tend to treat hesitant webpages as noises or outliers. Recently, Huang et al. proposed DenShrink (Huang, Sun, Han, & Feng, 2011). It efficiently reveals the embedded hierarchical community structure (Hastie, Tibshirani, & Friedman, 2001) and identifies hubs and outliers. But we found that it simply treats hesitant webpages as hubs and ignores the classification of them.
In this paper, a classification approach for hesitant webpages is proposed. Firstly, the hesitant webpages are refined into three concrete types: bridges, hubs and attached webpages. Bridges and hubs are the overlapping portions and junctions of different categories while attached webpages are later classified. Secondly, considering the scarce tags of attached webpages, the tacit information of attached webpages is fully excavated in two perspectives. One is applying the latent semantic analysis (LSA) (Deerwester, Dumais, Landauer, Furnas, & Harshman, 1990) to the tags of all the webpages. By doing this, webpages which are semantically close with the attached webpage can be more clearly identified. The other perspective is the density-relation-based rough set model. It is built to measure the affiliation degree of attached webpage in different categories. This measurement takes not only the attached webpage’s neighbors but also the dense pairs (Huang et al., 2011) of the neighbors into consideration. Experiment of real data shows that these two measures help to find semantically related categories for hesitant webpages and also enhance a classification measurement, the similarity based modularity (Feng, Xu, Yuruk, & Schweiger, 2007).
In this section, we will introduce the relation between the LSA and the classification of webpages, DenShrink clustering method and its limitation, and the rough set theory.
In the tagging systems, a webpage numbered i can be denoted by its tag set using the vector pi = (ti1, ti2, … , tim). Wherein, m is the number of tags appearing in all the webpages. tij presents that a webpage i has a tag numbered j and the tagging frequency is tij. Since there might be zero, one or more users tagging webpage i with tag j, the tagging frequency is a non-negative integer. We adopt the vector space model to represent all the webpages with the tag-webpage matrix P. Wherein, n is the number of webpages.P=p1p2p3⋮pn=t11t12⋯t1mt21t22⋯t2m⋮⋮⋮tn1tn2⋯tnm<math><mtext is="true">P</mtext><mo is="true">=</mo><mrow is="true"><mfenced open="[" close="]" is="true"><mrow is="true"><mtable is="true"><mtr is="true"><mtd columnalign="center" is="true"><msub is="true"><mrow is="true"><mi is="true">p</mi></mrow><mrow is="true"><mn is="true">1</mn></mrow></msub></mtd></mtr><mtr is="true"><mtd columnalign="center" is="true"><msub is="true"><mrow is="true"><mi is="true">p</mi></mrow><mrow is="true"><mn is="true">2</mn></mrow></msub></mtd></mtr><mtr is="true"><mtd columnalign="center" is="true"><msub is="true"><mrow is="true"><mi is="true">p</mi></mrow><mrow is="true"><mn is="true">3</mn></mrow></msub></mtd></mtr><mtr is="true"><mtd columnalign="center" is="true"><mo is="true">⋮</mo></mtd></mtr><mtr is="true"><mtd columnalign="center" is="true"><msub is="true"><mrow is="true"><mi is="true">p</mi></mrow><mrow is="true"><mi is="true">n</mi></mrow></msub></mtd></mtr><mtr is="true"><mtd columnalign="center" is="true"></mtd></mtr></mtable></mrow></mfenced></mrow><mo is="true">=</mo><mrow is="true"><mfenced open="[" close="]" is="true"><mrow is="true"><mtable is="true"><mtr is="true"><mtd columnalign="center" is="true"><msub is="true"><mrow is="true"><mi is="true">t</mi></mrow><mrow is="true"><mn is="true">11</mn></mrow></msub></mtd><mtd columnalign="center" is="true"><msub is="true"><mrow is="true"><mi is="true">t</mi></mrow><mrow is="true"><mn is="true">12</mn></mrow></msub></mtd><mtd columnalign="center" is="true"><mo is="true">⋯</mo></mtd><mtd columnalign="center" is="true"><msub is="true"><mrow is="true"><mi is="true">t</mi></mrow><mrow is="true"><mn is="true">1</mn><mi is="true">m</mi></mrow></msub></mtd></mtr><mtr is="true"><mtd columnalign="center" is="true"><msub is="true"><mrow is="true"><mi is="true">t</mi></mrow><mrow is="true"><mn is="true">21</mn></mrow></msub></mtd><mtd columnalign="center" is="true"><msub is="true"><mrow is="true"><mi is="true">t</mi></mrow><mrow is="true"><mn is="true">22</mn></mrow></msub></mtd><mtd columnalign="center" is="true"><mo is="true">⋯</mo></mtd><mtd columnalign="center" is="true"><msub is="true"><mrow is="true"><mi is="true">t</mi></mrow><mrow is="true"><mn is="true">2</mn><mi is="true">m</mi></mrow></msub></mtd></mtr><mtr is="true"><mtd columnalign="center" is="true"><mo is="true">⋮</mo></mtd><mtd columnalign="center" is="true"><mo is="true">⋮</mo></mtd><mtd columnalign="center" is="true"></mtd><mtd columnalign="center" is="true"><mo is="true">⋮</mo></mtd></mtr><mtr is="true"><mtd columnalign="center" is="true"><msub is="true"><mrow is="true"><mi is="true">t</mi></mrow><mrow is="true"><mi is="true">n</mi><mn is="true">1</mn></mrow></msub></mtd><mtd columnalign="center" is="true"><msub is="true"><mrow is="true"><mi is="true">t</mi></mrow><mrow is="true"><mi is="true">n</mi><mn is="true">2</mn></mrow></msub></mtd><mtd columnalign="center" is="true"><mo is="true">⋯</mo></mtd><mtd columnalign="center" is="true"><msub is="true"><mrow is="true"><mi is="true">t</mi></mrow><mrow is="true"><mi mathvariant="italic" is="true">nm</mi></mrow></msub></mtd></mtr></mtable></mrow></mfenced></mrow></math>
The key idea in latent semantic analysis (LSA) is to map high-dimensional vector space representation of text webpages, to a lower dimensional semantic space representation (Hofmann, 2001). This process can be realized through the singular value decomposition (SVD) on matrix P by retaining a certain number of the largest characteristic values and eliminating the noises of matrix P. With this method, the refactored P describes the semantic relation between the tags and the webpages more exactly. Let us denote the refactored P with P′. Then pi′<math><mrow is="true"><msubsup is="true"><mrow is="true"><mi is="true">p</mi></mrow><mrow is="true"><mi is="true">i</mi></mrow><mrow is="true"><mo is="true">′</mo></mrow></msubsup></mrow></math> and pj′<math><mrow is="true"><msubsup is="true"><mrow is="true"><mi is="true">p</mi></mrow><mrow is="true"><mi is="true">j</mi></mrow><mrow is="true"><mo is="true">′</mo></mrow></msubsup></mrow></math> in matrix P′ are used to compute the cosine similarity between webpage i and j.
LSA is meaningful for hesitant webpage classification. It fully excavates of the sparse tag set of hesitant webpage by mining the semantic similarity between tags on a global scale. Let hesitant webpage hp be a film review webpage infrequently tagged with merely four tags – Renaissance, Opera, Aesthetics and Legend Story. With traditional vector analysis, it would be difficult to find webpages which get high similarity with hp because of the sparse tags and some of the rarely used tags like “Renaissance” and “Aesthetics”. With the application of LSA to the tag sets of large amounts of webpages, we are able to find more tags semantically close to the existing sparse tag set, such as “Drama”, “Art” and “the 16th century && Europe”, similar to “Opera”, “Aesthetics” and “Renaissance” respectively. By doing this, the tag set of hp is potentially extended and it is more possible to find semantically similar webpages.
DenShrink is proposed by Huang et al. The main process of DenShrink can be divided into two phases. First, the micro-cluster which consists of two or more densely connected nodes (or super-nodes) is detected. Then the micro-cluster whose mergence increases the similarity based modularity measure is merged and becomes a super-node. The two steps are repeated iteratively until no micro-cluster can merge to increase the modularity.
In DenShrink, all the remaining isolate nodes which have not been merged till the last iteration and connect with multiple clusters are considered as hubs. However, our essential analysis of DenShrink reveals that some of the isolated nodes are unqualified hubs. These webpages are remained isolate because of the low similarity with other webpages, rather than acting as the hub among different categories. If consider the centrality degree (Borgatti, 2005) and the predicted trust of the information distribution path (Chen et al., 2012, Kim and Song, 2011, Nocera and Ursino, 2012) through them, they are unqualified hubs. In our research, they are named hesitant webpages. An advanced approach is proposed to classify the hesitant webpages.
The classical rough set theory, first proposed by Pawlak (1982), attracted great attention for its fundamental role in rule extraction and classification problems (Chu et al., 2010, Kaya et al., 2013). One of the key definitions of the classical rough set theory is the indiscernibility relation. Later, various extended rough set models relaxed the establishment conditions of the relations in different degree (Kryszkiewicz, 1998, Stefanowski and Tsoukiàs, 1999).
Kryszkiewicz (1998) proposed the tolerance relation based rough set model in incomplete information system. The tolerance relation is a binary relation. Rather than the classical indiscernibility relation which is an equivalence relation, it is reflexive and symmetric but not imposed to be transitive. For example, let X denote a set {x1, x2, x3, x4, x5}. Wherein, x1 = 210, x2 = 234, x3 = 765, x4 = 297, x5 = 739, and R = {〈x, y〉| x ∊ X ∧ y ∊ X ∧ x and y share one or more numbers}. It can be seen that x1 and x2 share the number “2”, which we denote as x1Rx2. In a similar way, there is x2Rx3 but not x1Rx3. It is obvious that R is reflexive and symmetric but not transitive, thus R is a tolerance relation.
Based on the tolerance relation, the related definitions of tolerance relation based rough set model are as the following.

Definition 1 Tolerance Class

Let X denote the domain of discourse and R be a tolerance relation. For any x ∊ X, T(x) = {y ∊ X|xTy} is the tolerance class of x. Particularly, for any x ∊ X, there is x ∊ T (x).
Let X denote the domain of discourse and R be a tolerance relation. For any x ∊ X, T(x) = {y ∊ X|xTy} is the tolerance class of x. Particularly, for any x ∊ X, there is x ∊ T (x).
T(x) presents the set of all objects inXwhose relationship withxsatisfy R. In the above example, the tolerance class ofx1relating to relation R isT(x1) = {x1, x2, x4}.

Definition 2 Upper Approximation

Let X denote the domain of discourse and R be a tolerance relation. For any subset X′ ⊆ X, iff X′‾=∪{T(x)|x∈X′}<math><mrow is="true"><mover accent="true" is="true"><mrow is="true"><msup is="true"><mrow is="true"><mi is="true">X</mi></mrow><mrow is="true"><mo is="true">′</mo></mrow></msup></mrow><mrow is="true"><mo stretchy="true" is="true">‾</mo></mrow></mover><mo is="true">=</mo><mo is="true">∪</mo><mo stretchy="false" is="true">{</mo><mtext is="true">T</mtext><mo stretchy="false" is="true">(</mo><mi is="true">x</mi><mo stretchy="false" is="true">)</mo><mo stretchy="false" is="true">|</mo><mi is="true">x</mi><mo is="true">∈</mo><msup is="true"><mrow is="true"><mi is="true">X</mi></mrow><mrow is="true"><mo is="true">′</mo></mrow></msup><mo stretchy="false" is="true">}</mo></mrow></math>, X′‾<math><mrow is="true"><mover accent="true" is="true"><mrow is="true"><msup is="true"><mrow is="true"><mi is="true">X</mi></mrow><mrow is="true"><mo is="true">′</mo></mrow></msup></mrow><mrow is="true"><mo stretchy="true" is="true">‾</mo></mrow></mover></mrow></math> is upper approximation of X′.
Let X denote the domain of discourse and R be a tolerance relation. For any subset X′ ⊆ X, iff X′‾=∪{T(x)|x∈X′}<math><mrow is="true"><mover accent="true" is="true"><mrow is="true"><msup is="true"><mrow is="true"><mi is="true">X</mi></mrow><mrow is="true"><mo is="true">′</mo></mrow></msup></mrow><mrow is="true"><mo stretchy="true" is="true">‾</mo></mrow></mover><mo is="true">=</mo><mo is="true">∪</mo><mo stretchy="false" is="true">{</mo><mtext is="true">T</mtext><mo stretchy="false" is="true">(</mo><mi is="true">x</mi><mo stretchy="false" is="true">)</mo><mo stretchy="false" is="true">|</mo><mi is="true">x</mi><mo is="true">∈</mo><msup is="true"><mrow is="true"><mi is="true">X</mi></mrow><mrow is="true"><mo is="true">′</mo></mrow></msup><mo stretchy="false" is="true">}</mo></mrow></math>, X′‾<math><mrow is="true"><mover accent="true" is="true"><mrow is="true"><msup is="true"><mrow is="true"><mi is="true">X</mi></mrow><mrow is="true"><mo is="true">′</mo></mrow></msup></mrow><mrow is="true"><mo stretchy="true" is="true">‾</mo></mrow></mover></mrow></math> is upper approximation of X′.
The meaning of upper approximation can be intuitively understood. With any element in set X′ certainly belonging to X′, any object in X′‾<math><mrow is="true"><mover accent="true" is="true"><mrow is="true"><msup is="true"><mrow is="true"><mi is="true">X</mi></mrow><mrow is="true"><mo is="true">′</mo></mrow></msup></mrow><mrow is="true"><mo stretchy="true" is="true">‾</mo></mrow></mover></mrow></math> is possible belonging to X′ since there exists a certain element in X′ which is tolerantly the same with this object in terms of relation R. For any X′ ⊆ X, there is X′⊆X′‾<math><mrow is="true"><msup is="true"><mrow is="true"><mi is="true">X</mi></mrow><mrow is="true"><mo is="true">′</mo></mrow></msup><mo is="true">⊆</mo><mover accent="true" is="true"><mrow is="true"><msup is="true"><mrow is="true"><mi is="true">X</mi></mrow><mrow is="true"><mo is="true">′</mo></mrow></msup></mrow><mrow is="true"><mo stretchy="true" is="true">‾</mo></mrow></mover></mrow></math>. To make an illustration, let X′ = {x1, x2}, then in the above example, there is X′‾=T(x1)∪T(x2)={x1,x2,x4}∪{x1,x2,x4,x5}={x1,x2,x4,x5}<math><mrow is="true"><mover accent="true" is="true"><mrow is="true"><msup is="true"><mrow is="true"><mi is="true">X</mi></mrow><mrow is="true"><mo is="true">′</mo></mrow></msup></mrow><mrow is="true"><mo stretchy="true" is="true">‾</mo></mrow></mover><mo is="true">=</mo><mi is="true">T</mi><mo stretchy="false" is="true">(</mo><msub is="true"><mrow is="true"><mi is="true">x</mi></mrow><mrow is="true"><mn is="true">1</mn></mrow></msub><mo stretchy="false" is="true">)</mo><mo is="true">∪</mo><mi is="true">T</mi><mo stretchy="false" is="true">(</mo><msub is="true"><mrow is="true"><mi is="true">x</mi></mrow><mrow is="true"><mn is="true">2</mn></mrow></msub><mo stretchy="false" is="true">)</mo><mo is="true">=</mo><mo stretchy="false" is="true">{</mo><msub is="true"><mrow is="true"><mi is="true">x</mi></mrow><mrow is="true"><mn is="true">1</mn></mrow></msub><mtext is="true">,</mtext><msub is="true"><mrow is="true"><mi is="true">x</mi></mrow><mrow is="true"><mn is="true">2</mn></mrow></msub><mtext is="true">,</mtext><msub is="true"><mrow is="true"><mi is="true">x</mi></mrow><mrow is="true"><mn is="true">4</mn></mrow></msub><mo stretchy="false" is="true">}</mo><mo is="true">∪</mo><mo stretchy="false" is="true">{</mo><msub is="true"><mrow is="true"><mi is="true">x</mi></mrow><mrow is="true"><mn is="true">1</mn></mrow></msub><mtext is="true">,</mtext><msub is="true"><mrow is="true"><mi is="true">x</mi></mrow><mrow is="true"><mn is="true">2</mn></mrow></msub><mtext is="true">,</mtext><msub is="true"><mrow is="true"><mi is="true">x</mi></mrow><mrow is="true"><mn is="true">4</mn></mrow></msub><mtext is="true">,</mtext><msub is="true"><mrow is="true"><mi is="true">x</mi></mrow><mrow is="true"><mn is="true">5</mn></mrow></msub><mo stretchy="false" is="true">}</mo><mo is="true">=</mo><mo stretchy="false" is="true">{</mo><msub is="true"><mrow is="true"><mi is="true">x</mi></mrow><mrow is="true"><mn is="true">1</mn></mrow></msub><mtext is="true">,</mtext><msub is="true"><mrow is="true"><mi is="true">x</mi></mrow><mrow is="true"><mn is="true">2</mn></mrow></msub><mtext is="true">,</mtext><msub is="true"><mrow is="true"><mi is="true">x</mi></mrow><mrow is="true"><mn is="true">4</mn></mrow></msub><mtext is="true">,</mtext><msub is="true"><mrow is="true"><mi is="true">x</mi></mrow><mrow is="true"><mn is="true">5</mn></mrow></msub><mo stretchy="false" is="true">}</mo></mrow></math>.
In this paper, the density relation is proposed as a kind of tolerance relation and then the density relation based rough set is proposed with the definition of density relation.
On the basis of the clusters or categories detected by DenShrink method, we set several steps to refine the hesitant webpages into three concrete types: the hub, the bridge and the attached webpage. Then we classify the attached webpages into corresponding clusters according to the affiliation degree which is computed based on the density-relation-based rough set model. In this section, the refinement process, the density-relation-based rough set model and the computation of affiliation degree are introduced.
The hesitant webpages are refined into three concrete types: bridges, hubs and attached webpages according to their different roles in webpage network. The classification process is accompanied with an example, as shown in Fig. 1. The webpages are studied as the weighted undirected graph. Each webpage can be presented as a node. If two webpages share one or more tags, they are called adjacent nodes or the neighbor with each other and are connected with an edge. The weight of the edge connecting two nodes is the cosine similarity of the corresponding webpages. Then there is G = 〈V, E, ω〉. Wherein, V is the set of nodes in network G. E is the set of edges connecting adjacent nodes. ω(e) is the weight of edge e ∊ E. In the graph of Fig. 1, five clusters C1, C2, C3, C4 and C5 are detected by DenShrink with nodes h1, h2, h3, h4, b, ap1, ap2, ap3 left isolate. They are hesitant webpages. Any two nodes (or super-nodes) satisfying the density relation are connected with red edges.
Scouting hubs. Among the isolated nodes, we regard nodes h1, h2, h3, h4 (marked with yellow hexagrams) as qualified hubs because they keep density relation with certain categories (super-nodes). Take the h1 for example. Since it gets density relation with C5, it acts as the effective junctions between C5 and the other categories it connects to (C1 and C2).
Scouting bridges. Node b (blue rectangle) does not belong to any category, but it is the bridge (Chou & Suzuki, 2010) since it is the only join point between C3 and C4.
Scouting attached webpages. After filtering out the hubs and bridges, the rest nodes ap1, ap2, ap3 (purple triangle) neither get density relation with any of their adjacent categories nor play the role as bridges. They are set as attached webpages which should be classified into certain categories.
The density-relation-based rough set model is defined on the basis of the dense pair (Huang et al., 2011) and the tolerance relation based rough set model (Kryszkiewicz, 1998).

Definition 3 Density Relation

Given a weighted undirected graph G = 〈V, E, ω〉. For u, v ∊ V, if u and v have the largest similarity with each other, namely they are the dense pair, then node u and v satisfy density relation, denoted by uRv. On this condition, u and v are the dense neighbor of each other.
Given a weighted undirected graph G = 〈V, E, ω〉. For u, v ∊ V, if u and v have the largest similarity with each other, namely they are the dense pair, then node u and v satisfy density relation, denoted by uRv. On this condition, u and v are the dense neighbor of each other.
The density relation is a binary relation and has reflexivity and symmetry but not transitivity. It is a kind of tolerance relation. Fig. 2 is an example of a simple webpage network. We can see that webpage 1 and 2 get the highest similarity 0.8 with each other. Then we have P1RP2. Similarly, there is P1RP5, P3RP5 and P2RP3. However, since density relation is not imposed to be transitive, we cannot deduce P2RP5 from P2RP3 and P3RP5.
Based on density relation, density class and density based upper approximation are defined.

Definition 4 Density Class

Given a weighted undirected graph G = 〈V, E, ω〉. For any u ∊ V, iff τ(u) = {v ∊ V|uRv}, τ(u) is the density class of u.
Given a weighted undirected graph G = 〈V, E, ω〉. For any u ∊ V, iff τ(u) = {v ∊ V|uRv}, τ(u) is the density class of u.
All the nodes inτ(u) have density relation withu. Particularly, for anyu ∊ V, there isu ∊ τ(u). InFig. 2, the density class ofP1is {P1, P2, P5} since there areP1RP1,P1RP2,P1RP5.

Definition 5 Density Based Upper Approximation

Given a weighted undirected graph G = 〈V, E, ω〉. For any subset V′ ⊆ V, iff V′‾=∪{τ(u)|u∈V′}<math><mrow is="true"><mover accent="true" is="true"><mrow is="true"><msup is="true"><mrow is="true"><mi is="true">V</mi></mrow><mrow is="true"><mo is="true">′</mo></mrow></msup></mrow><mrow is="true"><mo stretchy="true" is="true">‾</mo></mrow></mover><mo is="true">=</mo><mo is="true">∪</mo><mo stretchy="false" is="true">{</mo><mi is="true">τ</mi><mo stretchy="false" is="true">(</mo><mi is="true">u</mi><mo stretchy="false" is="true">)</mo><mo stretchy="false" is="true">|</mo><mi is="true">u</mi><mo is="true">∈</mo><msup is="true"><mrow is="true"><mi is="true">V</mi></mrow><mrow is="true"><mo is="true">′</mo></mrow></msup><mo stretchy="false" is="true">}</mo></mrow></math>, V‾′<math><mrow is="true"><msup is="true"><mrow is="true"><mover accent="true" is="true"><mrow is="true"><mi is="true">V</mi></mrow><mrow is="true"><mo stretchy="true" is="true">‾</mo></mrow></mover></mrow><mrow is="true"><mo is="true">′</mo></mrow></msup></mrow></math> is density based upper approximation of V′.
Given a weighted undirected graph G = 〈V, E, ω〉. For any subset V′ ⊆ V, iff V′‾=∪{τ(u)|u∈V′}<math><mrow is="true"><mover accent="true" is="true"><mrow is="true"><msup is="true"><mrow is="true"><mi is="true">V</mi></mrow><mrow is="true"><mo is="true">′</mo></mrow></msup></mrow><mrow is="true"><mo stretchy="true" is="true">‾</mo></mrow></mover><mo is="true">=</mo><mo is="true">∪</mo><mo stretchy="false" is="true">{</mo><mi is="true">τ</mi><mo stretchy="false" is="true">(</mo><mi is="true">u</mi><mo stretchy="false" is="true">)</mo><mo stretchy="false" is="true">|</mo><mi is="true">u</mi><mo is="true">∈</mo><msup is="true"><mrow is="true"><mi is="true">V</mi></mrow><mrow is="true"><mo is="true">′</mo></mrow></msup><mo stretchy="false" is="true">}</mo></mrow></math>, V‾′<math><mrow is="true"><msup is="true"><mrow is="true"><mover accent="true" is="true"><mrow is="true"><mi is="true">V</mi></mrow><mrow is="true"><mo stretchy="true" is="true">‾</mo></mrow></mover></mrow><mrow is="true"><mo is="true">′</mo></mrow></msup></mrow></math> is density based upper approximation of V′.
In Fig. 2, let V′ = {P1, P2}, then V′‾=τ(P1)∪τ(P2)={P1,P2,P5}∪{P1,P2,P3}={P1,P2,P3,P5}<math><mrow is="true"><mover accent="true" is="true"><mrow is="true"><msup is="true"><mrow is="true"><mi is="true">V</mi></mrow><mrow is="true"><mo is="true">′</mo></mrow></msup></mrow><mrow is="true"><mo stretchy="true" is="true">‾</mo></mrow></mover><mo is="true">=</mo><mi is="true">τ</mi><mo stretchy="false" is="true">(</mo><msub is="true"><mrow is="true"><mi is="true">P</mi></mrow><mrow is="true"><mn is="true">1</mn></mrow></msub><mo stretchy="false" is="true">)</mo><mo is="true">∪</mo><mi is="true">τ</mi><mo stretchy="false" is="true">(</mo><msub is="true"><mrow is="true"><mi is="true">P</mi></mrow><mrow is="true"><mn is="true">2</mn></mrow></msub><mo stretchy="false" is="true">)</mo><mo is="true">=</mo><mo stretchy="false" is="true">{</mo><msub is="true"><mrow is="true"><mi is="true">P</mi></mrow><mrow is="true"><mn is="true">1</mn></mrow></msub><mtext is="true">,</mtext><msub is="true"><mrow is="true"><mi is="true">P</mi></mrow><mrow is="true"><mn is="true">2</mn></mrow></msub><mtext is="true">,</mtext><msub is="true"><mrow is="true"><mi is="true">P</mi></mrow><mrow is="true"><mn is="true">5</mn></mrow></msub><mo stretchy="false" is="true">}</mo><mo is="true">∪</mo><mo stretchy="false" is="true">{</mo><msub is="true"><mrow is="true"><mi is="true">P</mi></mrow><mrow is="true"><mn is="true">1</mn></mrow></msub><mtext is="true">,</mtext><msub is="true"><mrow is="true"><mi is="true">P</mi></mrow><mrow is="true"><mn is="true">2</mn></mrow></msub><mtext is="true">,</mtext><msub is="true"><mrow is="true"><mi is="true">P</mi></mrow><mrow is="true"><mn is="true">3</mn></mrow></msub><mo stretchy="false" is="true">}</mo><mo is="true">=</mo><mo stretchy="false" is="true">{</mo><msub is="true"><mrow is="true"><mi is="true">P</mi></mrow><mrow is="true"><mn is="true">1</mn></mrow></msub><mtext is="true">,</mtext><msub is="true"><mrow is="true"><mi is="true">P</mi></mrow><mrow is="true"><mn is="true">2</mn></mrow></msub><mtext is="true">,</mtext><msub is="true"><mrow is="true"><mi is="true">P</mi></mrow><mrow is="true"><mn is="true">3</mn></mrow></msub><mtext is="true">,</mtext><msub is="true"><mrow is="true"><mi is="true">P</mi></mrow><mrow is="true"><mn is="true">5</mn></mrow></msub><mo stretchy="false" is="true">}</mo></mrow></math>. As mentioned in definition 2, elements in V′‾<math><mrow is="true"><mover accent="true" is="true"><mrow is="true"><msup is="true"><mrow is="true"><mi is="true">V</mi></mrow><mrow is="true"><mo is="true">′</mo></mrow></msup></mrow><mrow is="true"><mo stretchy="true" is="true">‾</mo></mrow></mover></mrow></math> are possible sharing certain characteristics with elements in V′.
Affiliation Degree is the quantized measurement of attached webpage classification. In the computation of affiliation degree, it is the upper approximation of the neighbors of the attached webpage rather than the attached webpage itself that is analyzed. This aims to fully excavate and extend the information of the attached webpage.
The attached webpage is denoted withapi. The category or cluster which possesses at least one ofapi’s neighbors is called its adjacent category or cluster. An attached webpageapikeeps different affiliation degree in its different adjacent categories and is classified into the category in which it has the largest affiliation degree. The affiliation degree is defined as below.

Definition 6 Affiliation Degree

Given a network G = 〈V, E, ω〉 and an attached webpage api. Cj is an adjacent category of api. The affiliation degree of api in Cj is AD(i, j):

(1)AD(i,j)=|Γ(api)∩Cj‾|=∑pk∈Cj∧δ(i,k)≠0|τ(pk)|<math><mi mathvariant="italic" is="true">AD</mi><mo stretchy="false" is="true">(</mo><mi is="true">i</mi><mtext is="true">,</mtext><mi is="true">j</mi><mo stretchy="false" is="true">)</mo><mo is="true">=</mo><mo stretchy="false" is="true">|</mo><mover accent="true" is="true"><mrow is="true"><mi mathvariant="normal" is="true">Γ</mi><mo stretchy="false" is="true">(</mo><msub is="true"><mrow is="true"><mi mathvariant="italic" is="true">ap</mi></mrow><mrow is="true"><mi is="true">i</mi></mrow></msub><mo stretchy="false" is="true">)</mo><mrow is="true"><mo is="true">∩</mo></mrow><msub is="true"><mrow is="true"><mi is="true">C</mi></mrow><mrow is="true"><mi is="true">j</mi></mrow></msub></mrow><mrow is="true"><mo stretchy="true" is="true">‾</mo></mrow></mover><mo stretchy="false" is="true">|</mo><mo is="true">=</mo><mstyle displaystyle="true" is="true"><munder is="true"><mrow is="true"><mo is="true">∑</mo></mrow><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">p</mi></mrow><mrow is="true"><mi is="true">k</mi></mrow></msub><mo is="true">∈</mo><msub is="true"><mrow is="true"><mi is="true">C</mi></mrow><mrow is="true"><mi is="true">j</mi></mrow></msub><mo is="true">∧</mo><mi is="true">δ</mi><mo stretchy="false" is="true">(</mo><mi is="true">i</mi><mtext is="true">,</mtext><mi is="true">k</mi><mo stretchy="false" is="true">)</mo><mo is="true">≠</mo><mn is="true">0</mn></mrow></munder></mstyle><mo stretchy="false" is="true">|</mo><mi is="true">τ</mi><mo stretchy="false" is="true">(</mo><msub is="true"><mrow is="true"><mi is="true">p</mi></mrow><mrow is="true"><mi is="true">k</mi></mrow></msub><mo stretchy="false" is="true">)</mo><mo stretchy="false" is="true">|</mo></math>Wherein, Γ(api) is the set of neighbors ofapi.Γ(api)∩Cj‾<math><mrow is="true"><mover accent="true" is="true"><mrow is="true"><mi mathvariant="normal" is="true">Γ</mi><mo stretchy="false" is="true">(</mo><msub is="true"><mrow is="true"><mi mathvariant="italic" is="true">ap</mi></mrow><mrow is="true"><mi is="true">i</mi></mrow></msub><mo stretchy="false" is="true">)</mo><mrow is="true"><mo is="true">∩</mo></mrow><msub is="true"><mrow is="true"><mi is="true">C</mi></mrow><mrow is="true"><mi is="true">j</mi></mrow></msub></mrow><mrow is="true"><mo stretchy="true" is="true">‾</mo></mrow></mover></mrow></math>denotes the upper approximation of setΓ(api)∩Cj<math><mrow is="true"><mi mathvariant="normal" is="true">Γ</mi><mo stretchy="false" is="true">(</mo><msub is="true"><mrow is="true"><mi mathvariant="italic" is="true">ap</mi></mrow><mrow is="true"><mi is="true">i</mi></mrow></msub><mo stretchy="false" is="true">)</mo><mrow is="true"><mo is="true">∩</mo></mrow><msub is="true"><mrow is="true"><mi is="true">C</mi></mrow><mrow is="true"><mi is="true">j</mi></mrow></msub></mrow></math>. δ(i,k) is the cosine similarity between hesitant webpageapiand the ordinary webpagepk.τ(pk) is the density class ofpk. The absolute value sign “| |” presents the cardinality.
Given a network G = 〈V, E, ω〉 and an attached webpage api. Cj is an adjacent category of api. The affiliation degree of api in Cj is AD(i, j):
It is worth noting that AD(i, j) extends the classification information of api by considering all the api’s neighbors in Cj and only the neighbors’ dense neighbors in Cj. In this way, the extension of the classification information is controlled in a degree. The degree, more importantly, is reflected by upper approximation. With the understanding of upper approximation in definition 2, elements in the upper approximation of set Γ(api)∩Cj<math><mrow is="true"><mi mathvariant="normal" is="true">Γ</mi><mo stretchy="false" is="true">(</mo><msub is="true"><mrow is="true"><mi mathvariant="italic" is="true">ap</mi></mrow><mrow is="true"><mi is="true">i</mi></mrow></msub><mo stretchy="false" is="true">)</mo><mrow is="true"><mo is="true">∩</mo></mrow><msub is="true"><mrow is="true"><mi is="true">C</mi></mrow><mrow is="true"><mi is="true">j</mi></mrow></msub></mrow></math> are possible sharing certain characteristics with the api’s neighbors in Cj. Besides, upper approximation is based on density relation with relatively strong similarity. The stronger the trust paths are, the more important they are for predicting the level of trust (Golbeck, 2005). For the reasons given above, elements in Γ(api)∩Cj‾<math><mrow is="true"><mover accent="true" is="true"><mrow is="true"><mi mathvariant="normal" is="true">Γ</mi><mo stretchy="false" is="true">(</mo><msub is="true"><mrow is="true"><mi mathvariant="italic" is="true">ap</mi></mrow><mrow is="true"><mi is="true">i</mi></mrow></msub><mo stretchy="false" is="true">)</mo><mrow is="true"><mo is="true">∩</mo></mrow><msub is="true"><mrow is="true"><mi is="true">C</mi></mrow><mrow is="true"><mi is="true">j</mi></mrow></msub></mrow><mrow is="true"><mo stretchy="true" is="true">‾</mo></mrow></mover></mrow></math> are taken into account in the computation of AD(i,j).
Besides, a further effort is made to consider the similarity between api and each of its neighbors in the computation of affiliation degree, and then there is the modified formula of AD(i,j):(2)AD(i,j)=∑pk∈Cj∧δ(i,k)≠0δ(i,k)×|τ(pk)|<math><mi mathvariant="italic" is="true">AD</mi><mo stretchy="false" is="true">(</mo><mi is="true">i</mi><mtext is="true">,</mtext><mi is="true">j</mi><mo stretchy="false" is="true">)</mo><mo is="true">=</mo><mstyle displaystyle="true" is="true"><munder is="true"><mrow is="true"><mo is="true">∑</mo></mrow><mrow is="true"><msub is="true"><mrow is="true"><mi is="true">p</mi></mrow><mrow is="true"><mi is="true">k</mi></mrow></msub><mo is="true">∈</mo><msub is="true"><mrow is="true"><mi is="true">C</mi></mrow><mrow is="true"><mi is="true">j</mi></mrow></msub><mo is="true">∧</mo><mi is="true">δ</mi><mo stretchy="false" is="true">(</mo><mi is="true">i</mi><mtext is="true">,</mtext><mi is="true">k</mi><mo stretchy="false" is="true">)</mo><mo is="true">≠</mo><mn is="true">0</mn></mrow></munder></mstyle><mi is="true">δ</mi><mo stretchy="false" is="true">(</mo><mi is="true">i</mi><mtext is="true">,</mtext><mi is="true">k</mi><mo stretchy="false" is="true">)</mo><mo is="true">×</mo><mo stretchy="false" is="true">|</mo><mi is="true">τ</mi><mo stretchy="false" is="true">(</mo><msub is="true"><mrow is="true"><mi is="true">p</mi></mrow><mrow is="true"><mi is="true">k</mi></mrow></msub><mo stretchy="false" is="true">)</mo><mo stretchy="false" is="true">|</mo></math>Let us take the computation of affiliation degree of ap2 in Fig. 1 as an example. Fig. 3 shows ap2 and its adjacent categories C2 and C3.
In categories C2, nodes P1, P2, P3 are adjacent to ap2. With τ(P1) = {P1, P4}, τ(P2) = {P2, P4}, τ(P3) = {P3}, there are |τ(P1)| = 2, |τ(P2)| = 2, |τ(P3)| = 1. According to formula (2), AD(2, 2) = 0.3714 × 2 + 0.2861 × 2 + 0.3714 × 1 = 1.6864. In the computation of AD(2, 2), elements in Γ(ap2)∩C2‾={P1,P2,P3,P4}<math><mrow is="true"><mover accent="true" is="true"><mrow is="true"><mi mathvariant="normal" is="true">Γ</mi><mo stretchy="false" is="true">(</mo><msub is="true"><mrow is="true"><mi mathvariant="italic" is="true">ap</mi></mrow><mrow is="true"><mn is="true">2</mn></mrow></msub><mo stretchy="false" is="true">)</mo><mrow is="true"><mo is="true">∩</mo></mrow><msub is="true"><mrow is="true"><mn is="true">C</mn></mrow><mrow is="true"><mi is="true">2</mi></mrow></msub></mrow><mrow is="true"><mo stretchy="true" is="true">‾</mo></mrow></mover><mo is="true">=</mo><mo stretchy="false" is="true">{</mo><msub is="true"><mrow is="true"><mi is="true">P</mi></mrow><mrow is="true"><mn is="true">1</mn></mrow></msub><mtext is="true">,</mtext><msub is="true"><mrow is="true"><mi is="true">P</mi></mrow><mrow is="true"><mn is="true">2</mn></mrow></msub><mtext is="true">,</mtext><msub is="true"><mrow is="true"><mi is="true">P</mi></mrow><mrow is="true"><mn is="true">3</mn></mrow></msub><mtext is="true">,</mtext><msub is="true"><mrow is="true"><mi is="true">P</mi></mrow><mrow is="true"><mn is="true">4</mn></mrow></msub><mo stretchy="false" is="true">}</mo></mrow></math> are analyzed. P1 and P2 are similar to ap2 directly with similarity δ(2, 1) and δ(2, 2) respectively. Since P4 is similar to ap2 through node P1 and P2, adding the weight of δ(2, 1) and δ(2, 2), there are 0.3714 × 2 and 0.2861 × 2. P3 is similar to ap2 directly with no dense neighbor, thus there is δ(2, 3) × 1.Similarly, AD(2, 3) = 0.4714 × 3 + 0.3158 × 2 = 2.0458. AD(2, 3) is bigger than AD(2, 2), thus ap2 is classified to C3.
The experiment data come from a database website (www.datatang.com). The data set obtains 3315 URLs of tagging information of Chinese book reviews on the network of Douban (http://book.douban.com/). The Douban book site is one of the largest and most famous book sites in China. We number the URL according to the tagging frequency of the pages from high to low. Fig. 4 shows the tagging frequency distribution of the pages. It can be shown that most of the pages get sparse tags. Merely 7.42% webpages are tagged more than 1 × 104 times.
In this experiment, 1100 pages of all the samples are randomly chosen to be clustered according to DenShrink clustering method. For k-means, the average silhouette values are relatively high (>0.6) only when the number of categories ranges from 2 to 6, which can be represented in Fig. 5. However, the categories of the book involved in the webpages are far more than six.
With DenShrink algorithm, the webpages are classified into 23 categories. In Fig. 6, different categories are marked with different colors. The distance of the nodes is inversely proportional to the cosine similarity computed based on the LSA. Although the clusters in Fig. 6 are not appearing apparently, DenShrink is able to detect the categories of webpages. However, statistics indicate that, DenShrink ignores the classification of 277 hesitant webpages. The hesitant webpages usually keep relatively low similarity with their neighbors compared with the ordinary webpages, thus they are remained unclassified by DenShrink. Fig. 7 presents the largest similarity between hesitant webpages, ordinary webpages and their corresponding neighbors.
According to the refinement process in section 3.1, 51 hubs, 3 bridges and 223 attached webpages are scouted among the unclassified 277 hesitant webpages. Wherein, the attached webpages are classified based on the affiliation degree. Fig. 8 records the increase of the similarity based modularity Qs (Feng et al., 2007) during the DenShrink clustering and the classification of attached webpages. Given the set of categories {C1, C2, … , Ck } in network G = 〈V, E, ω〉, the function Qs is as bellow. Wherein k is the number of categories, ISj=∑u,v∈Cjδ(u,v)<math><mrow is="true"><msub is="true"><mrow is="true"><mi mathvariant="italic" is="true">IS</mi></mrow><mrow is="true"><mi is="true">j</mi></mrow></msub><mo is="true">=</mo><msub is="true"><mrow is="true"><mo is="true">∑</mo></mrow><mrow is="true"><mi is="true">u</mi><mtext is="true">,</mtext><mi is="true">v</mi><mo is="true">∈</mo><msub is="true"><mrow is="true"><mi is="true">C</mi></mrow><mrow is="true"><mi is="true">j</mi></mrow></msub></mrow></msub><mi is="true">δ</mi><mo stretchy="false" is="true">(</mo><mi is="true">u</mi><mtext is="true">,</mtext><mi is="true">v</mi><mo stretchy="false" is="true">)</mo></mrow></math> is the total similarity of nodes within category Cj, DSj=∑u∈Cj,v∈Vδ(u,v)<math><mrow is="true"><msub is="true"><mrow is="true"><mi mathvariant="italic" is="true">DS</mi></mrow><mrow is="true"><mi is="true">j</mi></mrow></msub><mo is="true">=</mo><msub is="true"><mrow is="true"><mo is="true">∑</mo></mrow><mrow is="true"><mi is="true">u</mi><mo is="true">∈</mo><msub is="true"><mrow is="true"><mi is="true">C</mi></mrow><mrow is="true"><mi is="true">j</mi></mrow></msub><mtext is="true">,</mtext><mi is="true">v</mi><mo is="true">∈</mo><mi is="true">V</mi></mrow></msub><mi is="true">δ</mi><mo stretchy="false" is="true">(</mo><mi is="true">u</mi><mtext is="true">,</mtext><mi is="true">v</mi><mo stretchy="false" is="true">)</mo></mrow></math> is the total similarity between nodes in category Cj and any node in the network, and TS = ∑u,v∈V<math><mrow is="true"><msub is="true"><mrow is="true"><mo is="true">∑</mo></mrow><mrow is="true"><mi is="true">u</mi><mtext is="true">,</mtext><mi is="true">v</mi><mo is="true">∈</mo><mi is="true">V</mi></mrow></msub></mrow></math>δ(u, v) is the total similarity between any two nodes in the network.Qs=∑j=1kISjTS-DSjTS2<math><msub is="true"><mrow is="true"><mi is="true">Q</mi></mrow><mrow is="true"><mi is="true">s</mi></mrow></msub><mo is="true">=</mo><mstyle displaystyle="true" is="true"><munderover is="true"><mrow is="true"><mo is="true">∑</mo></mrow><mrow is="true"><mi is="true">j</mi><mo is="true">=</mo><mn is="true">1</mn></mrow><mrow is="true"><mi is="true">k</mi></mrow></munderover></mstyle><mrow is="true"><mfenced open="[" close="]" is="true"><mrow is="true"><mfrac is="true"><mrow is="true"><msub is="true"><mrow is="true"><mi mathvariant="italic" is="true">IS</mi></mrow><mrow is="true"><mi is="true">j</mi></mrow></msub></mrow><mrow is="true"><mi mathvariant="italic" is="true">TS</mi></mrow></mfrac><mo is="true">-</mo><msup is="true"><mrow is="true"><mfenced open="(" close=")" is="true"><mrow is="true"><mfrac is="true"><mrow is="true"><msub is="true"><mrow is="true"><mi mathvariant="italic" is="true">DS</mi></mrow><mrow is="true"><mi is="true">j</mi></mrow></msub></mrow><mrow is="true"><mi mathvariant="italic" is="true">TS</mi></mrow></mfrac></mrow></mfenced></mrow><mrow is="true"><mn is="true">2</mn></mrow></msup></mrow></mfenced></mrow></math>The classification of each nodes (or super-nodes) contributes to the modularity increase. In the whole process, there are 842 times of node (or super-node) classification. The curve above the interval of [0, 619] reflects the modularity gain during DenShrink process while the right part above interval of [619, 842] reflects the modularity gain of the attached webpage classification.
It can be seen that the Qs curve in the right is not as steep as the curve in the left side. There are two reasons explaining this. One is that, in DenShrink clustering, each time of the increase of modularity results from classifying the super-node which usually contains two or more ordinary nodes, while each point on the Qs curve in the right part corresponds to the classification of one attached node. The other reason is that the attached webpage keeps relatively low similarity with its neighbors thus Qs does not gain sharply during the classification. Still, the attached webpages making up 20.3% of the experimental data make contribution to 18.4% of the increase of modularity, indicating the correctness of the classification in terms of modularity measurement.
In semantic perspective, the proposed rough set model finds the semantically close categories for attached webpages. Due to the limited space, we present four categories and list five ordinary webpages along with four hesitant webpages in Table 1. The size of category is labeled below the category name which shows that hesitant nodes can be classified into both generic (“History” up to 63 webpages) and specific (“Psychology” down to 21 webpages) categories. The hub and the bridge are marked with pentagram and square respectively which indicates that they involve in multiple fields. For example, “Foreign gardening” is also about “Artistic Designing”. “Trip to Taiwan fruit—sure good enough” also relates to “Travel”.
The 11 out of 12 attached webpages in Table 1 are correctly classified. However DenShrink, treat all of the webpages as hubs. Actually, they have their solid themes and can be properly classified. One book named “One piece” marked with diamond is improperly classified. Deeper analysis discovers the basic reason. “One piece” is a famous Japanese cartoon. However, among all the choose experiment data, only the “One piece” relates to cartoon, thus there exists no corresponding cluster for this webpage. Besides, one of its tags “Japan” is of high similarity with “food” (more than one third books on “Food Culture” are written by Japanese writers), thus the “One Piece” is classified into the “Food Culture” category. From here we can see that the correctness of the classification of hesitant is based on the previously detected clusters.
Table 2 presents the detailed information of the “computer programming” category. Five ordinary webpages, three attached webpages labeled by △ and a hub labeled by ☆☆<math><mrow is="true"><mi is="true">☆</mi></mrow></math> with their tagging information are listed. The tagging frequency of attached webpages and hubs is relatively low and some of the tags are rarely used, both of which add the difficulty in their classification. Table 3 shows their affiliation degree in several categories. Let us take the “Visual data” as an example. Although it is similar to books in “Mathematical Analysis” and “Artistic Designing” because of tags “data mining” and “visualization” respectively, its affiliation degree in “computer programming” is amplified since its neighbors such as “Hackers and painters” and “The art of readable code” are more typical. By comparing the affiliation degree, it is classified into “computer programming”.
The experiment in this section shows that the hesitant webpage can be well classified based on LSA and density-relation based rough set model.
In today’s information age, tagging attracts abundant attention in web resource classification. However, this paper pinpoints the issue of the classification of less popular webpages whose tags are sparse and rarely used. Less popular webpages might possess special-interest or they are newly generated and experiencing the initial dissemination. With the personalized needs of users and the explosion of network resource, the classification of less popular webpages gets great practical significance in information management and network resource retrieval.
In this paper, the less popular webpages are called hesitant webpages, their categories cannot be explicitly identified. Two instruments, the LSA and the density-based-rough-set model, are employed to enrich and excavate the information of hesitant webpages. Particularly, the density-based-rough-set model is an extension of the rough set theory. In the classic rough set model, the attribute is always the characteristic of a single object, while in the density-based-rough-set model, the attribute is the similarity between two adjacent nodes. In this way, this paper finds the new application field of rough set model in complex network analysis. Besides, since the density-based-rough-set model only needs the local information of the hesitant webpages, it gets the extensibility to deal with the growing number of hesitant webpages.
One of the limitations of the approach is that the classification of the less popular webpages should be based on formerly detected categories. However, with the maturity of numerous clustering algorithms, this issue can be alleviated. Further research aims to find the suitable clustering method which efficiently cooperates with the classification approach for hesitant webpages. Besides, the classification of attached nodes depends on the understanding of the upper approximation that elements in the upper approximation are possible to be similar with the elements in the original collection. Although the correctness of the classification in the experiment supports this idea, more empirical research in various application backgrounds are needed to justify this principle. Finally, the “hesitant” should be accurately defined and its characteristics need to be uncovered, so that the proposed classification approach can be applied to more fields such as the detection and classification of “hesitant” members in virtual collaborative communities of corporations or universities and the expert recommendation to “hesitant ” members.
The work described in this paper was fully supported by the National Natural Science Foundation of China under Grant No. 71271018.